---
title: "The real option value of multistage agricultural research for development"
author:
  - name: Benjamin Schiek
    email: b.schiek@cgiar.org
    affiliation: CIAT
    correspondingauthor: true
address:
  - code: CIAT
    address: Performance, Innovation, and Strategic Analysis for Impact (PISA4Impact), Alliance of Bioversity International and CIAT, Km 17 Recta Cali-Palmira, Palmira, 763537
abstract: |
  Agricultural research for development (AR4D) donors face increasingly austere fiscal outlooks that restrict their ability to commit to high impact, high risk, agricultural research projects with long time horizons. This results in a series of short-term, piecemeal funding arrangements that inhibit the AR4D community's ability to conduct the disruptive research necessary to meet the Sustainable Development Goals. Real option valuation (ROV) presents a potential mechanism offering donors the flexibility they require to justify long term research funding commitments. However, adaptation of existing ROV methods to the AR4D context is complicated by the financial and corporate underpinnings of these methods, which are inconsistent with the non-market character of most AR4D projects. Adaptation is also complicated by the multistage structure of most AR4D projects, since existing ROV methods are mostly limited to single stage projects. Here we present a multistage ROV method derived from novel theoretical underpinnings that are consistent with the AR4D context. As an illustrative example, we apply the derived model to evaluate a real, four stage potato research project.
keywords: 
  - Real option value
  - Agricultural research for development
  - Risk neutral valuation
#  - Far-from-market
journal: "European Journal of Operational Research"
date: "`r Sys.Date()`"
classoption: preprint, 3p, authoryear
bibliography: AR4Drealoptions.bib
linenumbers: false
numbersections: true
# Use a CSL with `citation_package = "default"`
# csl: https://www.zotero.org/styles/elsevier-harvard
output: 
  rticles::elsevier_article:
    keep_tex: true
    citation_package: natbib
header-includes:
  - \numberwithin{equation}{section}
  - \usepackage{float}
  #- \usepackage[nomarkers,tablesonly]{endfloat}
  #- \usepackage[printfigures]{figcaps}
  - \floatplacement{figure}{h}
#  - \usepackage[section]{placeins}
#  - \usepackage[nolists]{endfloat}
  - \usepackage{caption}
---
<!-- Funding for agricultural research for development (AR4D) projects is set up in stages, such that the funding of any single stage can only move forward upon successful completion of the prior stages. When the project donor agrees to fund a research stage, then, they effectively buy the option, but not the obligation, to fund the subsequent stage. The donor’s investment therefore has option value, which can be considerable if there is high uncertainty (risk) surrounding the expected impact of the research. Conventional methods of AR4D project appraisal fail to account for option value, effectively underestimating the value of risky projects. Real option valuation (ROV) is a potential mechanism by which to price in option value, but adaptation of ROV to the AR4D context is complicated by the multistage, far-from-market-nature of AR4D projects. Here I address these challenges to develop a closed form, multistage ROV model. (I also introduce an elementary extension to account for abandonment value.) By explicitly accounting for risk and the option to abandon, the proposed model offers a more complete picture of AR4D project value as compared to conventional appraisal methods--potentially facilitating donor commitment to the long time horizons of agricultural research. -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      #fig.pos = 'H',
                      dev = c("png", "tiff"),
                      dpi = 300)
library(tidyverse)
library(flextable)
library(patchwork)
library(kableExtra)

label_size <- 2.5
smallLabel_size <- 2
title_size <- 8
subtitle_size <- 7
legendText_size <- 6
axisText_size <- 6
axisTitle_size <- 7
facetTitle_size <- 7

```

# Introduction

Agricultural research for development (AR4D) projects tend to be high reward, but also high risk, propositions with long time horizons. Donors are attracted by the high potential payoff of such projects, but face increasingly austere fiscal outlooks that restrict their ability to engage in long term, risky commitments. For researchers, the resulting uncertainty in the long term funding outlook incentivizes work in the direction of low risk, modest objectives that are achievable in the near term. Such research has its place; but the Sustainable Development Goals (SDGs) call for higher impact, riskier, longer term research as well. Real options valuation, a method of project appraisal adapted from financial analysis, presents a potential enabling mechanism by which to secure long term funding for disruptive research while also guaranteeing donors the fiscal flexibility they require to justify such commitments.

The notion of a real option, first introduced by Myers [-@myers1977determinants], is born of the analogous concept of a type of financial option known as the European call option. The holder of a European call option on an underlying security (a stock, for example) has the right, but not the obligation, to purchase the security for a predetermined price---called the "strike" or "exercise" price---at the end of a certain time period. Analogously, donors who "buy" a real option on an underlying project commit to funding the project for a certain time period, at the end of which they have the right, but not the obligation, to continue funding the subsequent stage of the project. In the case of research projects, for example, the subsequent stage at the end of time period $T_0$ might be the release and outscaling of a new crop variety developed during the main research stage. The value of such a real option (ROV), as evaluated at the time of the investment decision ($t = 0$), may be expressed mathematically as follows.

\begin{equation}
ROV_1(t)|_{t = 0} = e^{-r T_0} E[\max(x(T_0) - K_0, 0)]|_{t = 0}
\label{eq:basic}
\end{equation}

Where $x(T_0)$ is project net present value (NPV) at the end of the research period $T_0$, $K_0$ is the cost of funding the subsequent project stage (e.g., release and outscaling of the finished research product), and $r$ is the discount rate. By contrast, the comparable conventional appraisal of the project is calculated as

\begin{equation}
e^{-r T_0} (E[x(T_0)]|_{t = 0} - K_0)
\label{eq:conv}
\end{equation}

To characterize this as the conventional "NPV approach", as is sometimes done in the ROV literature [e.g., @koppl2013real], can be confusing since $x(t)$ is already defined as project NPV at any time $t$ (net of $K_0$), and appears in the calculation of ROV. To be clear, then, in the present article, the conventional manner of project appraisal in Equation \ref{eq:conv} is referred to as the "CBA approach" or "CBA basis"; whereas "project NPV", denoted $x(t)$, refers to the expected value at time $t$ of the net benefit stream resulting from release and outscaling of the research product after time $T_0$, net of any costs incurred at or prior to time $T_0$.

On an ROV basis, the investment $K_1$ required to implement the research is justified if

\begin{equation}
e^{-r T_0} E[\max(x(T_0) - K_0, 0)]|_{t = 0} > K_1
\end{equation}

On the CBA basis, the criterion is

\begin{equation}
e^{-rT_0} (E[x(T_0)]|_{t = 0} - K_0) > K_1 \:\: \rightarrow \:\: \text{invest in project}
\end{equation}

ROV is typically higher than the value $e^{-rT_0} (E[x(T_0)]|_{t = 0} - K_0)$, such that a project that would normally be rejected on the conventional CBA basis could be accepted on an ROV basis. This is especially true in the case of high risk, high reward projects. A comprehensive introduction to ROV and the main developments since its inception is given by Trigeorgis [-@trigeorgis1999real]. For an introduction to ROV in R&D contexts specifically, see Doctor et al. [-@doctor2001managing], and Newton et al. [-@newton2004real]. Köppl-Turyna and Köppl [-@koppl2013real] survey the scant literature on ROV approaches to (non-research) agricultural investments.

Real options contracts potentially bridge the divide between donor risk aversion and the risk tolerance required to achieve high impact AR4D because they are mutually beneficial for both donors and researchers alike. From the donor's perspective, a real option contract is a way to tentatively lay claim to promising, but distant and uncertain, research results, while at the same time guaranteeing easy extraction from underperforming projects. The resulting fiscal agility then translates into longer term funding commitments, which is music to the ears of the research community.

It is worth noting, moreover, that many donors already acquire an unacknowledged option value in their conventional research funding arrangements. That is to say, nowadays, most AR4D contracts are signed for no more than 1-5 years, at the end of which the contract comes up for renewal or cancellation, pending progress up to that point. By reserving the right to discontinue funding at specific time intervals, the donor effectively acquires option value. The introduction of ROV would thus merely formalize an already existing practice, and more accurately appraise the real value acquired by the donor in exchange for their investment. By the same token, the default methods of cost benefit analysis currently in place neglect to price in the donor's option value, and thus understate the real value acquired by the donor.

ROV methods have so far developed primarily in the context of corporate projects. A simple extension of this work to the AR4D context is complicated, if not made impossible, by the fundamental difference between the two contexts: corporate projects unfold in market or near market settings, where much of the original option value theory developed in finance may be invoked. AR4D projects, on the other hand, typically unfold in the midst of market failures, where the underlying assumptions of such theory do not apply. In particular,

1) AR4D project NPV is not well approximated by a linear combination of price movements (the "replicating portfolios" assumption)

2) AR4D project risk cannot be hedged away by trading securities (the "complete markets" assumption)

3) AR4D donors are not willing to take on any level of risk for a given expected return ("risk neutral valuation").
<!-- 4) Since AR4D project NPV is uncorrelated with markets, the capital asset pricing model (CAPM) is irrelevant. (The AR4D beta is zero, if you like.) -->
<!-- 5) AR4D projects do not pay dividends. [worth talking about only if gonna critique Dixit and Pindyck]-->

Extension of existing ROV methods to the AR4D context is also complicated by the multistage nature of most AR4D projects. For example, many AR4D plant breeding projects involve a preliminary greenhouse and/or minimal field trial stage, followed by larger multi-location, multi-season field trials [@covarrubias2022breeding]. In transgenic projects, additional toxicological testing is required, followed by the compilation of a regulatory dossier and application for deregulation before the national competent authority in the target countries where the new technology is to be released [@schiek2016demys]. Finally, there is the release, distribution, and outscaling stage, which involves careful orchestration of complex networks of stakeholders and public-private partnerships.

Donors invest in each of these stages one at a time, consecutively, with investment in the subsequent stage contingent upon successful completion of the current stage. The donor's investment in stage one of a three stage project, then, is analogous to purchasing an option on stage two---i.e., the right but not the obligation to invest in stage two---which is in turn an option on stage three.

The ROV of stage 2 of a 3-stage project, $ROV_3(t)$, may be expressed as follows.

\begin{equation}
ROV_3(t)|_{t = 0} = e^{-r T_2} E[\max(ROV_2(T_2) - K_2, 0)]|_{t = 0}
\label{eq:eg3stage}
\end{equation}

Where $ROV_2(T_2)$ is the ROV of stage 3 evaluated at $T_2$, the end of stage 1/beginning of stage 2, $K_2$ is the cost of investing in stage 2 upon successful completion of stage 1; and stage 1 is considered successfully completed if $ROV_2(T_2) > K_2$. $ROV_2(T_2)$, in turn, is defined

\begin{equation}
ROV_2(T_2) = e^{-r T_1} E[\max(ROV_1(T_1) - K_1, 0)]|_{t = T_2}
\end{equation}

Where $ROV_1(T_1)$ is the ROV of project NPV ($x(T_0)$) evaluated at $T_1$, the end of stage 2/beginning of stage 3, $K_1$ is the cost of investing in stage 3 upon successful completion of stage 2; and stage 2 is considered successfully completed if $ROV_1(T_1) > K_1$. $ROV_1(T_1)$, finally, is just the single stage ROV already defined in Equation \ref{eq:basic}.

If $ROV_3(0)$ is greater than the investment $K_3$ required to implement stage 1, then investment in stage 1 is justified. The comparable CBA criterion for any $n$-stage research project would be

\begin{equation}
e^{-rT_0} E[x(T_0)]|_{t = 0} - \sum_{i = 0}^{n - 1} e^{-r T_i} K_i > K_n \:\: \rightarrow \:\: \text{invest in project}
\label{eq:cbaCrit}
\end{equation}

Where $n = 3$ in this particular example.
<!-- Generally, -->
<!-- \begin{equation} -->
<!-- ROV_n(0) = e^{-r T_{n - 1}} E[\max(ROV_{n - 1}(T_{n - 1}) - K_{n - 1}, 0)]|_{t = 0} -->
<!-- \end{equation} -->

Existing ROV methods, meanwhile, focus primarily on single stage projects. The one exception is a multistage model proposed by Cassimon et al. [-@cassimon2004valuation] for the valuation of pharmaceutical trials, building upon the two stage or "compound option" model originally developed by Geske [-@geske1979valuation] in the financial context. Again, such work is not readily extensible to AR4D due to its corporate and financial theoretical underpinnings.

In this article, we derive a method for evaluating the ROV of multistage AR4D projects (e.g., Equation \ref{eq:eg3stage}). Rather than build upon the existing ROV groundwork developed in the financial and corporate contexts, we demonstrate why that groundwork is incompatible with the AR4D context, and replace it with suitable assumptions. More specifically, in place of strained arguments to construe project NPV as a traded good in an efficient market, we show how an ROV model for AR4D research products follows from the definition of NPV itself, and from the choice of stochastic model to represent the time evolution of project NPV. Following the derivation, we describe a hypothetical use case wherein the derived model is applied to evaluate the ROV of stage 2 research of a real 4-stage AR4D project to develop a potato variety with resistance to Late Blight disease for release as a public good in two developing countries.
<!-- [The derivation begins with a defense of the geometric Brownian motion stochastic model of project NPV as striking the right balance between realism and methodological tractability in the AR4D context.] -->

It is important to distinguish the work presented here from a "real options approach" developed by numerous authors to determine the optimal delay, from a social planner's perspective, of the release of a finished transgenic agricultural R&D product with uncertain environmental impact [@scatasta2006irreversibility; @demont2004biodiversity; @wesseler2007maximum; @demont2005irreversible]. That work is an adaptation of a method developed by Dixit and Pindyck [-@dixit1994investment] for determining the optimal time at which a corporate real option should be exercised. As such, it is concerned with the agricultural research analogue of another type of financial option, the American call option, which may be exercised at any moment up to a given time limit [@hull9thEdition]. By contrast, here the focus is on ROV of the European call option type expressed in Equation \ref{eq:basic}.
<!-- This is the ROV, from the donor's perspective, of a research project with a fixed time horizon. -->
<!-- [The work presented here, by contrast, is concerned with the valuation, from the donor's standpoint, of agricultural research projects, transgenic or otherwise, as real options with fixed exercise dates (i.e., planned release dates).] -->

# The incompatible financial underpinnings of existing ROV approaches

## AR4D products are not traded goods in efficient markets

The ROV literature cited above has developed in the context of corporate projects aiming to develop new goods or services to be marketed for a profit. In such a market or near market setting, a financial argument known as "replicating portfolios" may be invoked [@brennan1985evaluating; @koller2010valuation; @amram1998real]. Methodologically, the replicating portfolios argument means that corporate project NPV is well approximated ("replicated") by a linear combination of relevant prices. This greatly facilitates the estimation of project NPV and risk---both of which are required for ROV---as they may be calculated at any time from publicly available price information.

AR4D projects, on the other hand, are born of market failures, where no such argument may be invoked; and so AR4D project NPV and risk must be calculated the "hard way", by ex-ante impact assessment. Some might contend that the recent emergence of carbon and green bond markets [@tolliver2019green; @bhutta2022green] paves the way for a replicating portfolios analogue in the AR4D context. However, in addition to green outcomes, AR4D projects typically focus on health, nutrition, and socioeconomic outcomes for marginalized populations, the respective values of which, almost by definition, are not reflected in any market. And, even if they were---even if there were an "SDG bond" mapped to every AR4D impact area---this might be useful in the evaluation of project NPV, but of very little use in the assessment of project risk, since the main source of AR4D risk is not "price risk" (tragically, there is little risk of the bottom falling out of the SDG "market" in our lifetimes), but rather technical risk, i.e. the risk that the proposed technology will not function or scale as expected, due either to technical difficulties encountered in the research itself, or to unforeseen adversity in the enabling environment (e.g., government policy shifts, deregulation issues, etc.).

Even in the corporate ROV context, the replicating portfolios argument is met with considerable skepticism [@borison2005real]; and proponents of the argument acknowledge that its validity is limited to a narrow range of project types, which generally does not include R&D projects [@schwartz2013real]. There is strong methodological incentive to invoke the argument because the fundamental equation governing all types of option (and all financial derivative) valuation---i.e., the Black-Scholes partial differential equation (PDE)---is formally derived from an assumption in financial markets known as the "no-arbitrage rule", which requires that the underlying project NPV be interpretable as a traded good in an efficient market [@hull9thEdition].

To preserve the Black-Scholes PDE in cases where the replicating portfolios argument may not be invoked, some corporate ROV practitioners invoke the "complete markets" assumption as a second-best alternative [@majd1987time; @pennings1997option; @schwartz2013real]. Under the complete markets assumption, project NPV cannot be modeled as a linear function of prices, but the Black-Scholes PDE is nonetheless preserved because "all risks can be hedged by trading securities" [@pennings1997option]. As just mentioned, the main source of AR4D project risk is technical risk associated with non-market factors. Clearly, then, AR4D risk cannot be hedged by trading securities; and so there are no grounds in the AR4D context on which to invoke complete markets.
<!-- i.e. where project NPV may not be replicable as a traded good, -->

More problematically still, the formal derivation of the Black-Scholes PDE from either the replicating portfolios or complete markets assumptions leads to a celebrated corollary known as "risk-neutral valuation", which implies that "investors do not increase the expected return they require from an investment in order to compensate for increased risk" [@hull9thEdition]. Clearly, AR4D donors are not risk neutral. They are willing to bet on a high risk project only if there is a sufficiently high expected return on the investment.

In the derivation of the AR4D ROV formula presented farther below, these problematic foundations are replaced with the comparatively simple assumption that future values of project NPV are lognormally distributed. The derivation also requires that the expected growth rate of project NPV be equal to the discount rate, but this follows trivially from the definition of project NPV itself, and thus does not have to be assumed.

For present purposes, the assumption of lognormally distributed project NPV is tantamount to assuming that project NPV evolves as a geometric Brownian motion (gBm), a notion that is eschewed in the financial and corporate contexts in favor of more complex stochastic models [@merton1976option, @tankov2003financial]. Before proceeding to the derivation of the AR4D ROV formula, then, it is first necessary to introduce, contextualize, and defend the assumption of lognormally distributed project NPV.
<!-- If the Black-Scholes PDE is to be consistent with the AR4D context, then, it must be formally derived from a suitable premise (not replicating portfolios or complete markets), and in a way that does not imply risk-neutral valuation as a corollary. In the method section, it is shown    it is shown how this can be achieved through the mere definition of project NPV. But first it is necessary to disassociate the present approach from the corporate ROV literature on another front. -->

## In defense of gBm as a resaonable model of the time evolution of AR4D project NPV \label{sec:gBmDefens}

<!-- Another important difference between the corporate and AR4D contexts concerns the modeling of the stochastic time evolution of project NPV. -->
Many in the AR4D audience may be unfamiliar with stochastic models, but well versed in statistics. For purposes of exposition, the choice of stochastic model of project NPV time evolution may be thought of as the choice of probability density function of future values of project NPV, or of the size distribution of changes in project NPV per small time increment. Because AR4D project NPV time series do not exist, the choice of size distribution of changes in NPV requires deductive reasoning. A reasonable starting point in this exercise is the observation that changes in project NPV seem to be of two types: research related and non-research related.

Research related changes in project value generally occur at discrete test points, when new information regarding the effectiveness of the new technology becomes available. Non-research related changes in project value occur as a result of changes in the political, socio-economic, and institutional enabling environments where the new technology is to be released. Such changes may include, for example, elections, policy changes, commodity price swings, changes in seed systems and other value chain mechanisms, changes in the security environment, the ebb and flow of public and private sector partnerships to enhance impact, and so forth.

Research related changes occur relatively infrequently, perhaps 1-4 times per year, but with relatively greater magnitude than non-research related changes which occur more frequently, perhaps 1-4 times per annual quarter. Overall, then, it is reasonable to expect changes in AR4D project NPV to occur in every quarter, but that most of these changes will be small, even negligibly small, interspersed by a few larger, substantive changes. Based on this rationale, the lognormal distribution is a reasonable choice as a model of the size distribution of percentage changes in project NPV per annual quarter. The corresponding stochastic process is the gBm, an example of which is depicted in the left panel of Figure \ref{fig:NPVevol}.
<!-- changes in project NPV occur as a result of research and non-research related events, and it is reasonable to assume that, generally speaking, the time evolution of project NPV is characterized by relatively few large shifts---occurring, e.g., at the critical test points in the project timeline and/or major events in the enabling environment, such as elections---interspersed with relatively many small shifts in NPV due to non-research related fluctuations in the enabling environment.    ...the gBm parameters may be adjusted so as to approach a stochastic jump diffusion process arbitrarily closely. -->
<!-- Lognormally distributed changes in NPV correspond to the popular stochastic model known as geometric Brownian motion (gBm), for example, displayed in the left panel of Figure \ref{fig:NPVevol}. (See Hull [-@hull9thEdition] for a detailed introduction to gBm.) -->

```{r, include=FALSE}
gbmFun <- function(tau = 40, m = 0.001, s = 0.003, x0 = 1,
                   randVec = NULL, seed = NULL) {
  if(is.null(randVec)){
    if(!is.null(seed)){set.seed(seed)}
    randVec <- rnorm(tau)
  }
  epsilon <- randVec
  lx <- c(); lx[1] <- log(x0)
  drift <- (m - s * s / 2)
  for(t in 2:tau){
    dBt <-  s * epsilon[t]
    lx[t] <- lx[t - 1] + drift + dBt
  }
  x <- exp(lx)
  return(x)
}
# m <- 0.001
# s <- 0.003
# tau <- 400
# x0 <- 1
# x <- gbmFun(tau, m, s, x0, randVec = NULL)
# df_plot <- data.frame(t = 1:tau, x)
# gg <- ggplot(df_plot, aes(x = t, y = x))
# gg <- gg + geom_line()
# acf(diff(log(x)))
# hist(diff(log(x)))
# shapiro.test(diff(log(x)))
#---------------------------------------------------------------------------
# Algorithm 6.2 in Tankov 2003 Financial modeling with jump processes
compoundPoisFun <- function(tau, lambda, m_y = 0, s_y = 1,
                            seed = NULL, maxiter = 500){
  if(!is.null(seed)){set.seed(seed)}
  N <- rpois(1, lambda * tau)
  U <- runif(N) * tau
  U <- round(U)
  n_iter <- 0; flag <- 1
  while(flag == 1){
    n_iter <- n_iter + 1
    U <- runif(N) * tau
    U <- round(U)
    if(sum(duplicated(U)) > 0 & n_iter <= maxiter){
      flag <- 1
    }else{
      flag <- 0
      if(n_iter == maxiter){
        print("Reached maxiter without generating duplicate-free event times vec. Dropping duplicates.")
        U <- U[-which(duplicated(U))]
      }
    }
  }
  Tt <- U[order(U)]
  J <- exp(rnorm(N, m_y, s_y)) - 1
  #---
  cumJ <- cumsum(J)
  # For explicit modeling of Yt per time step
  Yt <- rep(0, tau)
  Yt[Tt] <- cumJ
  #---
  Tt <- c(0, Tt)
  J <- c(0, J)
  if(Tt[length(Tt)] != tau){
    Tt <- c(Tt, tau)
    J <- c(J, 0)
  }
  cumJ <- cumsum(J)
  df_step <- data.frame(Tt, cumJ)
  #--------------------------
  nEvents <- length(Tt)
  cumYt <- c()
  for(i in 1:(nEvents - 1)){
    tStart <- Tt[i]
    tFin <- Tt[i + 1] - 1
    cumYt[tStart:tFin] <- cumJ[i]
  }
  cumYt[tau] <- cumYt[tFin]
  df_Yt <- data.frame(t = 1:tau, Yt, cumYt)
  
  list_out <- list(df_step, df_Yt)
  return(list_out)
  
}
#----------------------------------------------------------------------------
FractDim<-function(Data,graphon=FALSE) {
  X=Data;N=length(X);
  jstart=10;jend=floor(10*(log10(N)-1));
  kvec=c(1:4,floor(2^(c(jstart:jend)/4)));
  indkend=length(kvec);
  k=c()
  AvgLmk=c()
  err=c()
  for(indk in 1:indkend)
  {
    k=kvec[indk]
    Xend=c()
    Xsum=c()
    Lmk=c()
    for(m in 1:k)
    {
      Xend=floor((N-m)/k)
      Xsum=sum(abs(X[m+c(1:Xend)*k]-c(0, X[m+c(1:(Xend-1))*k])))
      Lmk[m]=1/k*1/k*(N-1)/Xend*Xsum
    }
    AvgLmk[indk]=mean(Lmk)
    #  err[indk]=sd(log(Lmk))
  }
  x<-log(kvec)
  y<-log(AvgLmk)
  q<-lm(y~x)
  slope<-q$coefficients[2]
  yintcept<-q$coefficients[1]
  yfit<-x*slope+yintcept
  FrDim <- -slope
  avgRes <- mean(abs(q$residuals))
  if(graphon==TRUE)
  {
    plot(x,y,main="If linear then fractal, w/Fr. Dim = (-)slope",xlab="Ln(k)",ylab="Ln(length of curve with interval k)")
    z<-line(x,yfit);abline(coef(z),col='blue');z<-NULL
    #z<-line(x,y);abline(coef(z),col='blue');z<-NULL
  }
  #z<-line(x,y);qq=coef(z)
  #yintcept=qq[1]
  #FrDim=-qq[2]
  return(c(FrDim, avgRes, yintcept))
}
#===========================================================================
m <- 0.005
s <- m * seq(5.5, 50, length.out = 3)
tau <- 48
x0 <- 1
#rn <- round(runif(1) * 1000)
#rn <- 905
#rn <- 517
# rn <- 340
# set.seed(rn)
# tau <- 12 * 4
lambda <- 0.1


#----------------------------------------------------------------------------
# Generate and plot geometric Brownian movement example
#gBm_seed <- 10^4 * round(runif(1), 4)
#gBm_seed <- 2482
#gBm_seed <- 7781
gBm_seed <- 1029
#randVec <- coloredNoise(N = tau, alpha = 1, scaleIt = T)
#acf(randVec)
list_df <- list()
list_spec <- list()
facet_labels <- c()
for(i in 1:length(s)){
  x <- gbmFun(tau, m, s[i], x0, randVec = NULL, seed = gBm_seed)
  df_x <- data.frame(t = 1:tau, x, s = as.character(s[i]))
  list_df[[i]] <- df_x
  o <- spectrum(x)
  df_gbmSpec <- data.frame(lfreq = log(o$freq), lpwr = log(o$spec))
  df_gbmSpec <- df_gbmSpec[-1, ]
  df_gbmSpec$s <- as.character(s[i])
  list_spec[[i]] <- df_gbmSpec
  
  mod <- lm(lpwr ~ lfreq, df_gbmSpec)
  # summary(mod)
  alpha <- round(as.numeric(coefficients(mod)[2]), 2)
  # yint <- as.numeric(coefficients(mod)[1])
  # df_out <- as.data.frame(broom::glance(mod))
  # adjR2 <- round(df_out$adj.r.squared, 2)
  # N <- df.residual(mod)
  this_facet_label <- paste0("Slope = ", alpha, " fd = ", round(FractDim(x)[1], 2))
  facet_labels[i] <- this_facet_label
}
#---
df_plot <- as.data.frame(do.call(rbind, list_df))
colnames(df_plot)[1:2] <- c("Time", "Project NPV")
df_plot <- subset(df_plot, s == s[2])
gg <- ggplot(df_plot, aes(x = Time, y = `Project NPV`))
gg <- gg + geom_line()
#gg <- gg + facet_wrap(~s, scales = "free_y", ncol = 1)
gg <- gg + theme_bw()
gg <- gg + theme(axis.text = element_blank(),
                 axis.title = element_text(size = axisTitle_size))
gg_gbm <- gg
dfPlot_gBm <- df_plot
#---
df_plot <- as.data.frame(do.call(rbind, list_spec))
colnames(df_plot)[1:2] <- c("Logged frequency", "Logged power spectral density")
df_plot <- subset(df_plot, s == s[2])
#names(facet_labels) <- s
gg <- ggplot(df_plot, aes(x = `Logged frequency`, y = `Logged power spectral density`))
gg <- gg + geom_smooth(method = lm, se = F)
gg <- gg + geom_line()
# gg <- gg + facet_wrap(~s, ncol = 1,
#                       labeller = labeller(s = facet_labels))
gg <- gg + theme_bw()
gg <- gg + theme(axis.text = element_blank(),
                 axis.title = element_text(size = axisTitle_size))
gg_gbmSpec <- gg
#----------------------------------------------------------------------------
# Generate and plot compound Poisson process example
#cPp_seed <- 10^4 * round(runif(1), 4)
#cPp_seed <- 6819
#cPp_seed <- 4880
#cPp_seed <- 7656
cPp_seed <- 2558
list_df <- list()
list_spec <- list()
facet_labels <- c()
for(i in 1:length(s)){
  #s_y = 0.3
  list_out <- compoundPoisFun(tau, lambda, m_y = m,
                              s_y = s[i], seed = cPp_seed,
                              maxiter = 500)
  df_x <- list_out[[1]]
  df_x$s <- as.character(s[i])
  list_df[[i]] <- df_x
  
  df_Yt <- list_out[[2]]
  o <- spectrum(df_Yt$cumYt)
  df_spec <- data.frame(lfreq = log(o$freq), lpwr = log(o$spec))
  df_spec <- df_spec[-1, ]
  df_spec$s <- as.character(s[i])
  list_spec[[i]] <- df_spec
  
  mod <- lm(lpwr ~ lfreq, df_spec)
  # summary(mod)
  alpha <- round(as.numeric(coefficients(mod)[2]), 2)
  # yint <- as.numeric(coefficients(mod)[1])
  # df_out <- as.data.frame(broom::glance(mod))
  # adjR2 <- round(df_out$adj.r.squared, 2)
  # N <- df.residual(mod)
  this_facet_label <- paste0("Slope = ", alpha, " fd = ", round(FractDim(df_Yt$cumYt)[1], 2))
  facet_labels[i] <- this_facet_label
  
}
#---
df_plot <- as.data.frame(do.call(rbind, list_df))
colnames(df_plot)[1:2] <- c("Time", "Project NPV")
df_plot <- subset(df_plot, s == s[2])
gg <- ggplot(df_plot, aes(Time, `Project NPV`))
#gg <- ggplot(df_cpp, aes(t, cumYt))
gg <- gg + geom_step()
#gg <- gg + facet_wrap(~s, ncol = 1)
gg <- gg + theme_bw()
gg <- gg + theme(axis.text = element_blank(),
                 axis.title.y = element_blank(),
                 axis.title.x = element_text(size = axisTitle_size))
gg_cpp <- gg
dfPlot_cPp <- df_plot
#gg
#---
df_plot <- as.data.frame(do.call(rbind, list_spec))
colnames(df_plot)[1:2] <- c("Logged frequency", "Logged power spectral density")
df_plot <- subset(df_plot, s == s[2])
#names(facet_labels) <- s
gg <- ggplot(df_plot, aes(x = `Logged frequency`, y = `Logged power spectral density`))
gg <- gg + geom_smooth(method = lm, se = F)
gg <- gg + geom_line()
# gg <- gg + facet_wrap(~s, ncol = 1,
#                       labeller = labeller(s = facet_labels))
gg <- gg + theme_bw()
gg <- gg + theme(axis.text = element_blank(),
                 axis.title.y = element_blank(),
                 axis.title.x = element_text(size = axisTitle_size))
gg_cppSpec <- gg

```

```{r Fig1, fig.show = "hold", fig.width = 5, fig.height=2, fig.align="center", fig.cap="\\label{fig:NPVevol}Examples of project NPV evolving over quarterly time steps as (left) a geometric Brownian motion and (right) a compound Poisson process.", echo = FALSE}

gg_gbm + gg_cpp + plot_layout(nrow = 1)

```

In the financial context, the gBm model is eschewed as unrealistic because it does not reflect the abrupt jumps empirically observed in price series, which are inconsistent with a lognormal size distribution. Instead, "jump" or "jump-diffusion" models are recommended, which more accurately capture these abrupt swings in value [@merton1976option, @tankov2003financial]. An example of a jump process, known as the compound Poisson process (cPp), is displayed in the right panel of Figure \ref{fig:NPVevol} (algorithm 6.2 in Cont and Tankov [-@tankov2003financial]).

The gBm model is methodologically attractive because it allows for a closed form solution to the Black-Scholes PDE. Jump and jump diffusion models, on the other hand, come at the high methodological cost of requiring numerical solutions to the Black-Scholes PDE. The development of corporate ROV methods has adopted the financial context's consensus against gBm in favor of jump and jump diffusion models, thus inheriting the same high degree of methodological complexity. Trigeorgis once characterized this complexity as the unavoidable "bitter pill" that all serious ROV practitioners must come to grips with [-@trigeorgis1993real].
<!-- which are exceedingly difficult to explain to anyone who is not a financial expert -->
<!-- # ```{r Fig2, fig.show = "hold", fig.width = 5, fig.height=2, fig.align="center", fig.cap="\\label{fig:NPVevol}(Left) An example of NPV changing randomly in every time step. (Right) An example of NPV changing randomly at random time steps, and otherwise remaining constant.", echo = FALSE} -->
<!-- gg_gbm + gg_cpp + plot_layout(nrow = 1) -->
<!-- ``` -->

In hindsight, the appetite for bitterness outside of academic audiences---that is to say, adoption of ROV thinking by real world decision makers---has remained low [@horn2015use; @triantis2005realizing; @driouchi2012real]. Both critics and proponents alike attribute this tepid reception to the formal complexity of ROV, much of which can be traced back to the use of sophisticated stochastic models of project NPV that require numerical solutions to the Black-Scholes PDE [@triantis2005realizing]. From the perspective of research donors and managers, such numerical methods are effectively black boxes; and even ROV experts find themselves bamboozled at times. A much cited numerical exercise by Majd and Pindyck [-@majd1987time], for example, contains an elementary error, which was only discovered some twelve years after publication [@milne2000time].
<!-- In hindsight, it is safe to say that energetic proponents of ROV like Trigeorgis have overestimated the appetite for bitterness outside of academic audiences. The adoption of ROV methods in real world decision making settings remains low; and the main reason given for the low adoption is the methodological complexity of ROV compared to conventional cost-benefit analysis methods [@ryan2002capital; @block2007real; @horn2015use; @triantis2005realizing; @driouchi2012real]. -->
<!-- [---enough so, at any rate, to warrant some revisiting of the matter:] -->
<!-- The case for complex ROV approaches weakens further when considering what is gained in return for sacrificing expedience. Pennings and Lint find only a $2\%$ difference between the the output of their cPp numerical model and that of the gBm closed form model [@pennings1997option]. To what extent is an increase in modeling realism even meaningful in a context where direct measurement of the reality one aspires to approximate---i.e., the evolution of project NPV---is highly problematic? Is the costly increase in realism even relevant to the aims of the modeling exercise? Is there an alternative, less costly way of achieving the same ends? -->
<!-- 33.1 - 32.3 -->

In the AR4D context, the grounds for swallowing this bitter pill are especially narrow. As mentioned above, it is not even clear what a realistic time evolution of AR4D project NPV looks like. The time and expense involved in AR4D ex-ante impact assessment make frequent, regular updates of project NPV impractical, which in turn means that direct empirical inspection of the stochastic character of project NPV over a series of small, regularly spaced time steps is generally not possible---certainly not in the way that is possible for a price series.

In the corporate context, Pennings and Lint [-@pennings1997option] attempt to resolve this issue by assembling from scratch an historical time series of project NPV; and then selecting and parameterizing a cPp model of future project NPV based on this. Such an approach does not so much resolve the issue as it does replace it with another set of problems. First and foremost, the historical project NPV must be carefully selected so as to be representative of the NPV trajectory of the new project under evaluation. Apart from a passing verbal assurance, Pennings and Lint offer little indication that their assembled time series may be plausibly construed as representative of the stochastic character of the new project under evaluation [-@pennings1997option]. In the AR4D context, especially, projects are so heterogeneous in their scale, scope, aims, target populations and environments, and so forth, that finding a past project NPV trajectory that plausibly maps onto a present project's NPV amounts to a prohibitive challenge.

Secondly, even if this were possible, the practitioner then runs into small sample problems. In both the corporate and AR4D contexts, the number of substantive adjustments to project NPV over the project's lifespan tends to be small. To generate "enough" data points, Pennings and Lint merge several past project NPV trajectories together into a single time series. In addition to severely compounding the first problem, the authors come up with just 17 observations over a 5 year period. Is this enough to select and parameterize a stochastic model of project NPV?

Thirdly, the cPp model selected by Pennings and Lint is appropriate only insofar as the interval size between changes in NPV is random [@tankov2003financial]. This is problematic since substantive changes in project NPV can often occur as the result of non-randomly spaced events, e.g. at scheduled test points in the research cycle, or scheduled shifts in the enabling environment (such as elections). Moreover, such changes are typically documented and announced through periodic, non-random reporting protocols.

Finally, there is the subtle and somewhat philosophical sounding, but deeply consequential, issue of sampling rate. When does a change in project NPV occur? Does it occur when the relevant causal event or set of events occurs, or only when management learns of its occurrence and announces the corresponding NPV adjustment? What about events that effectively change NPV, but that go unnoticed by management? Pennings and Lint tacitly presume that changes in NPV occur only if and when management learns of their occurrence. This is perhaps understandable in the corporate context, where the value of company activities is ultimately defined by the stock market, and hence (in principle) by publicly available information. In non-market contexts such as AR4D, on the other hand, one is at liberty to concern themselves only with the stochastic progression of real changes to project NPV, regardless of when management, or anyone else, discovers and documents these changes.

For present purposes, then, the periods of no change in the cPp model are effectively equivalent to periods of negligibly small changes in the gBm model; and the size distribution of changes in NPV generated by the two models is thus also effectively the same. The choice between gBm and cPp thus boils down to a choice between an expedient model and a methodological headache. In the present work, the expedient model (gBm) is chosen.
<!-- In any case, the two models can be parameterized such that the size distributions generated by the two models are effectively the same. The choice   -->
<!-- Even This is reflected in the periodograms corresponding to the two time series (Figure \ref{fig:NPVevol2}). -->
<!-- [Indeed], the size distribution of changes in the two models is asymptotically the same as "negligibly small" goes to zero. -->
<!-- In their corporate ROV study, Pennings and Lint find only a $2\%$ difference between ROV as calculated by their cPp-based numerical model and ROV as calculated by the gBm-based closed form model [-@pennings1997option]. -->
<!-- We note in passing, moreover, that whether the evolution of project NPV (or of any stochastic process) resembles the time series on the left or right of Figure \ref{fig:NPVevol} is, to a certain degree, a mere matter of the choice of time step. That is to say, the time series on the left can be transformed into to something resembling the time series on the right merely by plotting over a smaller time step. Likewise, the model on the right can be transformed into the model on the left by plotting over a sufficiently larger time step. The model on the right becomes unavoidable when said sufficiently larger time step results in an unacceptably small number of time steps for parameter estimation purposes. In the AR4D context, this is generally not a problem. Research projects typically last 9-25 years, such that, given a quarterly time step, the project NPV time series typically contains 36-100 steps. -->
<!-- # ```{r Fig3, fig.show = "hold", fig.width = 5, fig.height=2, fig.align="center", fig.cap="\\label{fig:NPVevol2}(Left) Periodogram of the time series in the left panel of previous figure. (Right) Periodogram of the time series in the right panel of previous figure.", echo = FALSE} -->
<!-- gg_gbmSpec + gg_cppSpec + plot_layout(nrow = 1) -->
<!-- ``` -->

# Formal derivation of multi-stage ROV in the AR4D context

## Derivation of single stage ROV \label{sec:straightInt}
<!-- # Method (Replacement of financial foundations with AR4D foundations) -->
<!-- Project NPV $x(t)$ is defined as all AR4D project net benefits discounted back to the present time $t$. Assuming $x(t)$ follows a gBm, then its evolution $\Delta x$ over a small time increment $\Delta t$ is described by -->
<!-- Project NPV $x(t)$ is defined as post-R&D project net benefits discounted back to the completion and release of the research product at time $T_0 > 0$, typically determined by ex-ante impact assessment. Time $t = 0$ is the time of the assessment.  -->

Assuming $x(t)$ follows a gBm, then its evolution $\Delta x$ over a small time increment $\Delta t$ is described by

\begin{equation}
\Delta x = x(t) m \Delta t + x(t) s \epsilon \sqrt{\Delta t} \:\:;\:\:\: \Delta x := x(t + \Delta t) - x(t)
\label{eq:gbmEq}
\end{equation}

Where $\epsilon$ is a normally distributed random variable with mean $0$ and variance $1$, such that $m$ and $s$ quantify the trend and volatility of the time evolution, respectively.

\begin{equation}
\begin{split}
m \Delta t &= E \left[\frac{\Delta x}{x} \right] \\
s^2 \Delta t &= Var \left[\frac{\Delta x}{x} \right]
\end{split}
\end{equation}

In other words, $m \Delta t$ and $s^2 \Delta t$ are the mean and variance of the instantaneous arithmetic return or growth rate. The expected value of project NPV at some future time $T$ as evaluated at time $t = 0$ is given by

\begin{equation}
E[x(T)]\bigr|_{t = 0} = e^{m T} x(0)
\label{eq:ExTt}
\end{equation}

And the mean and variance of the log return over any finite interval $\tau$ is given by

\begin{equation}
E \left[ \ln \left(\frac{x(T)}{x(0)} \right) \right]\biggr|_{t = 0}  = \left(m - \frac{s^2}{2} \right) T
\label{eq:meanLn}
\end{equation}

\begin{equation}
Var \left[ \ln \left(\frac{x(T)}{x(0)} \right) \right]\biggr|_{t = 0} = s^2 T
\end{equation}

(See Hull [-@hull9thEdition] for details.)

Since the calculation of project NPV already accounts for all expected changes to NPV that might occur over the time horizon, then, by definition, the expected growth rate of project NPV is just the discount rate ($m = r$).

The single stage ROV formula follows by evaluating Equation \ref{eq:basic} through straightforward integration.

In general, for a lognormally distributed random variable $q$ and a constant $C$,

\begin{equation}
E[\max(q - C, 0)] = E[q] \Phi \left(\frac{\ln \left( \frac{E[q]}{C} \right) + \frac{\omega^2}{2}}{\omega} \right) - C \Phi \left(-\frac{\ln \left( \frac{E[q]}{C} \right) - \frac{\omega^2}{2}}{\omega} \right)
\label{eq:genEq}
\end{equation}

Where $\Phi()$ is the standard cumulative normal distribution function. (See Appendix for proof.)

In the case where $q = x(T_0)$, $C = K_0$, and multiplying through by the discount factor $e^{-r T_0}$, this becomes

\begin{equation}
e^{-r T_0} E[\max(x(T_0) - K_0, 0)]\bigr|_{t = 0} = x(0) \Phi \left(\delta_0 + s \sqrt{T_0} \right) - e^{-r T_0} K_0 \Phi(\delta_0)
\label{eq:rov}
\end{equation}

Where

\begin{equation}
\delta_0 = \frac{ \ln \left(\frac{x(0)}{K_0} \right) + \left(r - \frac{s^2}{2} \right) T_0} {s \sqrt{T_0}}
\end{equation}

Note that the value of $\Phi(\delta_0)$ is instructive. It is the probability that $x(T_0)$ will exceed the exercise cost $K_0$---or, in real options parlance, the probability that the option finishes "in the money". To see this, note that $\delta_0$ may be rewritten as the negative standard score of $\ln(K_0/x(0))$.

\begin{equation}
\begin{split}
\delta_0 &= -\frac{ \ln \left(\frac{K_0}{x(0)} \right) - \left(r - \frac{s^2}{2} \right) T_0} {s \sqrt{T_0}} \\
&= -\frac{ \ln \left(\frac{K_0}{x(0)} \right) - E \left[ \ln \left(\frac{x(T_0)}{x(0)} \right) \right]\bigr|_{t = 0}} {s \sqrt{T_0}}
\end{split}
\end{equation}

Hence,

\begin{equation}
\begin{split}
\Phi(\delta_0) &= 1 - \Phi \left( \frac{ \ln \left(\frac{K_0}{x(0)} \right) - E \left[ \ln \left(\frac{x(T_0)}{x(0)} \right) \right]\bigr|_{t = 0}} {s \sqrt{T_0}} \right) \\
&= 1 - P \left( \ln \left(\frac{x(T_0)}{x(0)}\right) \leq \ln \left( \frac{K_0}{x(0)} \right)\right) \\ &= P \left( \ln \left(\frac{x(T_0)}{x(0)}\right) \geq \ln \left( \frac{K_0}{x(0)} \right)\right)
\end{split}
\end{equation}

## Relation to the Black-Scholes derivation

Geometric Brownian motion is a particular case of a broader category of stochastic processes known as Ito processes, defined as follows.

\begin{equation}
\Delta x = a(x, t) \Delta t + b(x, t) \epsilon \sqrt{\Delta t}
\end{equation}

Where $a$ and $b$ are functions of $x$ and $t$.
<!-- In the present case where $x(t)$ is project NPV, $a = x(t) r$ -->

Ito's lemma states that the evolution of a function $f(x, t)$ is also an Ito process, described as follows [@hull9thEdition].

\begin{equation}
\Delta f = \left(\frac{\partial f}{\partial x} a + \frac{\partial f}{\partial t} + \frac{1}{2} \frac{\partial^2 f}{\partial x^2} b^2 \right) \Delta t + \frac{\partial f}{\partial x} b \epsilon \sqrt{\Delta t}
\end{equation}

In the present case, where $x(t)$ is a gBm with $a = x r$, $b = x s$, Ito's lemma reduces to

\begin{equation}
\Delta f = \left( \frac{\partial f}{\partial x} x r + \frac{\partial f}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f}{\partial x^2} \right) \Delta t + \frac{\partial f}{\partial x} x s \epsilon \sqrt{\Delta t}
\label{eq:itoLem}
\end{equation}

It follows that the expected value and variance of instantaneous changes in $f$ are

\begin{equation}
E\left[ \Delta f \right] = \left( \frac{\partial f}{\partial x} x r + \frac{\partial f}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f}{\partial x^2} \right) \Delta t
\label{eq:Ef1}
\end{equation}

\begin{equation}
Var\left[ \Delta f \right] = f^2 \eta_{1,0}^2 s^2 \Delta t
\end{equation}

Where the shorthand $\eta_{1,0} = \frac{x}{f} \frac{\partial f}{\partial x}$ has been introduced. (See Hull [-@hull9thEdition] for details.)

The function $f(x, t)$ in mind here is, of course, ROV. Because ROV is defined as an expected future value discounted back to the present (Equation \ref{eq:basic}), then its expected instantaneous growth rate is, by definition, $E[\Delta f / f] = r \Delta t$. Equation \ref{eq:Ef1} may thus be set equal to $f r \Delta t$, resulting in the following PDE.

\begin{equation}
fr = \frac{\partial f}{\partial x} x r + \frac{\partial f}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f}{\partial x^2}
\label{eq:bsPDEar4d}
\end{equation}

To reach the same result in the financial context, Black and Scholes [-@black1973valuation] famously noted that equations \ref{eq:gbmEq} and \ref{eq:itoLem} could be combined so as to eliminate the random term as follows.

\begin{equation}
\Delta f - \frac{\partial f}{\partial x} \Delta x = \left(\frac{\partial f}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f}{\partial x^2} \right) \Delta t
\label{eq:bsInsight}
\end{equation}

In the financial context, the left-hand side of this equation may be thought of as the instantaneous evolution over the increment $\Delta t$ of a portfolio long one share of the financial derivative $f$ and short a quantity $\partial f / \partial x$ of the underlying security $x(t)$. This is where Black and Scholes applied their no-arbitrage argument: Since the random---i.e. risky---term has been eliminated from equation \ref{eq:bsInsight}, then the profit or loss of this portfolio over the increment $\Delta t$ must be riskless. That is, it must change at the risk free rate $r$.

\begin{equation}
\Delta f - \frac{\partial f}{\partial x} \Delta x = \left( f - \frac{\partial f}{\partial x} x \right) r \Delta t
\label{eq:BSarb}
\end{equation}

Equating the right-hand side of this equation with the right-hand side of the previous equation, the $\Delta t$'s cancel, resulting in Equation \ref{eq:bsPDEar4d}. The PDE may then be solved for $f$ under the boundary condition $f(T_0) = \max(x(T_0) - K_0, 0)$, resulting in the same expression obtained through straightforward integration in Equation \ref{eq:rov}. (See Appendix for details.)
<!-- the Black-Scholes PDE. -->
<!-- \begin{equation} -->
<!-- \left(f - \frac{\partial f}{\partial x} x \right) r = \frac{\partial f}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f}{\partial x^2} -->
<!-- \end{equation} -->

Note that the Black-Scholes derivation hinges critically upon the assumption that $x(t)$ follows a gBm. As discussed above in section \ref{sec:gBmDefens}, this assumption is largely rejected in the literature subsequent to Black and Scholes' seminal paper, thus rendering Equation \ref{eq:bsInsight}, and the resulting closed form in Equation \ref{eq:rov}, of mere academic interest in the financial and corporate ROV contexts.
<!-- Also as discussed above, in the AR4D context the assumption that $x(t)$ follows a gBm may be considered valid, such that Equation \ref{eq:bsInsight} is valid in the AR4D context. The AR4D compatible Black-Scholes PDE may then be derived by replacing the no-arbitrage argument, which is invalid in the AR4D context, with the following logic: Since the random element has been eliminated from Equation \ref{eq:bsInsight}, then $x$ and $f$ must change at their expected rates. That is to say, $\Delta x$ and $\Delta f$ in Equation \ref{eq:bsInsight} may be replaced by $E[\Delta x]$ and $E[\Delta f]$. As mentioned above, the expected growth rate of $x$, $E[\Delta x / x]$, is by definition $r \Delta t$; and hence $E[\Delta x] = rx \Delta t$. Likewise, ROV ($f$) is defined as an expected future value discounted back to the present, and thus also, by definition, has an expected growth rate of $E[\Delta f/f] = r \Delta t$, such that $E[\Delta f] = rf \Delta t$. Making the relevant substitutions in Equation \ref{eq:bsInsight} results in the Black-Scholes PDE. Alternatively, the Black-Scholes PDE is also obtained by substituting $r f \Delta t$ for $E[\Delta f]$ in Equation \ref{eq:Ef1}. -->
<!-- \begin{equation} -->
<!-- \begin{split} -->
<!-- E \left[\frac{\Delta x}{x} \right] &= r \Delta t \\ -->
<!-- E \left[\frac{\Delta f}{f} \right] &= r \Delta t -->
<!-- \end{split} -->
<!-- \end{equation} -->

To tidy up, note that, since the expected growth rate of ROV is defined as $r\Delta t$, then the time evolution of $f$ in Equation \ref{eq:itoLem} may be rewritten more simply as follows.

\begin{equation}
\Delta f = f r \Delta t + f \eta_{1,0} s \epsilon \sqrt{\Delta t}
\end{equation}

A further consequence of Ito's lemma is that log changes in $f$ are normally distributed with mean and variance

\begin{equation}
E\left[\left( \frac{f(\tilde{T_0})}{f(0)} \right) \right]\biggr|_{t = 0} = \left(r - \eta_{1,0}^2 \frac{s^2}{2} \right) T_0
\label{eq:muLf1_b}
\end{equation}

\begin{equation}
Var\left[\left( \frac{f(T_0)}{f(0)} \right) \right]\biggr|_{t = 0} = \eta_{1,0}^2 s^2 T_0
\label{eq:sigLf1}
\end{equation}

While the Ito calculus is not necessary for deriving the single stage ROV formula (this was demonstrated in section \ref{sec:straightInt}), it becomes useful in the derivation of a formula for multi-stage ROV because it provides a clear demonstration that ROV itself is lognormally distributed with computable parameters given in Equations \ref{eq:muLf1_b} and \ref{eq:sigLf1}; and that this is recursively true for the ROV of $f$, and for the ROV of the ROV of $f$, and so on, ad infinitum, as detailed in the next section.

## Extension to multi-stage ROV \label{sec:method}

For the derivation of a multi-stage ROV formula, it is henceforth necessary to index $f$ as $f_1$, $f_2$,..., on up to $f_n$. (The $f_i$ correspond to the $ROV_i$ appearing in the Introduction). Following this schema, $f_0$ corresponds to project NPV $x$.

Because $f_1$ is itself lognormally distributed, the same formula used to evaluate the ROV of $x(T_0)$ (Equation \ref{eq:genEq}) can be used to evaluate the ROV of $f_1(T_1)$. That is to say, the ROV of stage 2 of a 2-stage project may be expressed 
\begin{equation}
\begin{split}
f_2(f_1, t; T_1, K_1, s, r)|_{t = 0} &= e^{-r T_1} E[\max(f(T_1) - K_1, 0)]\bigr|_{t = 0} \\
&= f_1(0) \Phi(\delta_1 + \eta_{1,0} s \sqrt{T_1}) - e^{-r T_1} K_1 \Phi(\delta_1)
\end{split}
\label{eq:rov2stage}
\end{equation}

Where $T_1$ is the time until completion of stage 1, $K_1$ is the research investment required upon successful completion of stage 1---where stage 1 is considered successfully completed if $f_1(T_1) > K_1$---and where

\begin{equation}
\delta_1 = \frac{ \ln \left(\frac{f_1(0)}{K_1} \right) - \left(r - \eta_{1,0}^2 \frac{s^2}{2} \right) T_1} {\eta_{1,0} s \sqrt{T_1}}
\end{equation}

Moreover, because $f_1$ is an Ito process and $f_2$ is a function of $f_1$, then by Ito's lemma, $f_2$ is also an Ito process,

\begin{equation}
\Delta f_2 = \left( \frac{\partial f_2}{\partial f_1} r f_1 + \frac{\partial f_2}{\partial t} + \eta_{1, 0}^2 \frac{s^2 f_1^2}{2} \frac{\partial^2 f_2}{\partial f_1^2} \right) \Delta t + f_2 \eta_{1,0} s \epsilon \sqrt{\Delta t}
\label{eq:itoLem2}
\end{equation}

With expected value and variance of the instantaneous change $\Delta f_2$

\begin{equation}
E\left[ \Delta f_2 \right] = \left( \frac{\partial f_2}{\partial f_1} r f_1 + \frac{\partial f_2}{\partial t} + \eta_{1, 0}^2 \frac{s^2 f_1^2}{2} \frac{\partial^2 f_2}{\partial f_1^2} \right) \Delta t
\label{eq:Ef2}
\end{equation}

\begin{equation}
Var\left[ \Delta f_2 \right] = f_2^2 \eta_{2,0}^2 s^2 \Delta t \:\:;\:\:\: \eta_{2,0} = \frac{f_1}{f_2} \frac{\partial f_2}{\partial f_1} \eta_{1, 0}
\end{equation}

As in the case of $f_1$, because $f_2$ is defined as an expected future value discounted back to the present, then the expected growth rate of $f_2$ is just $E[\Delta f_2 / f_2] = r \Delta t$. Equation \ref{eq:Ef2} may thus be set equal to $f_2 r \Delta t$, resulting in a Black-Scholes PDE for $f_2$.

\begin{equation}
rf_2 = f_1 r \frac{\partial f_2}{\partial f_1} + \frac{\partial f_2}{\partial t} + \eta_{1,0}^2 \frac{s^2 f_1^2}{2} \frac{\partial^2 f_2}{\partial f_1^2}
\end{equation}

Which may then be solved for $f_2$ under the boundary condition $f_2(0) = \max(f_1(T_1) - K_1, 0)$ as another way of obtaining Equation \ref{eq:rov2stage}. And it follows, moreover, that $f_2$ is lognormally distributed with log return mean and variance

\begin{equation}
E\left[\left(\frac{f_2(T_1)}{f_2(0)} \right) \right]\biggr|_{t = 0} = \left(r - \eta_{2, 0}^2 \frac{s^2}{2} \right) T_1
\end{equation}

\begin{equation}
Var\left[ \left( \frac{f_2(T_1)}{f_2(0)} \right) \right]\biggr|_{t = 0} = \eta_{2,0}^2 s^2 T_1
\end{equation}

Such that the same process can be repeated for a function $f_3(f_2, t; T_2, K_2, s, r)$, i.e., the ROV of stage 2 of a 3-stage research project, and so on for the ROV of stage 2 of any $n$-stage project, $f_n(f_{n - 1}, t; T_{n - 1}, K_{n - 1}, s, r)$,

\begin{equation}
\begin{split}
f_n(f_{n - 1}, t; T_{n - 1}, K_{n - 1}, s, r)|_{t = 0} &= e^{-r T_{n - 1}} E[\max(f_{n - 1}(T_{n - 1}) - K_{n - 1}, 0)]\bigr|_{t = 0} \\
&= f_{n - 1}(0) \Phi \left(\delta_{n - 1} + \eta_{n - 1, 0} s \sqrt{T_{n - 1}} \right) - e^{-r T_{n - 1}} K_{n - 1} \Phi(\delta_{n - 1}) \:\:;\:\:\: n \in \mathbb{N}_0
\end{split}
\label{eq:ROVn}
\end{equation}

Where $T_{n - 1}$ is the time until completion of stage 1 of the $n$-stage research project, $K_{n - 1}$ is the research investment required upon successful completion of stage 1 at time $T_{n - 1}$, where stage 1 is considered successfully completed if $f_{n - 1}(T_{n - 1}) > K_{n - 1}$, and where
<!-- ($T_{n - 1} < T_{n - 2} <...< T_0$) -->

\begin{equation}
\delta_{n - 1} = \frac{ \ln \left(\frac{f_{n - 1}(0)}{K_{n - 1}} \right) - \left(r - \eta_{n - 1, 0}^2 \frac{s^2}{2} \right) T_{n - 1}} {\eta_{n - 1, 0} s \sqrt{T_{n - 1}}}
\end{equation}

The quantity $\eta_{n - 1, 0}$ is the elasticity of $f_{n - 1}$ with respect to project NPV, and thus an instructive measure of ROV sensitivity to changes in project NPV.

\begin{equation}
\eta_{n - 1, 0} = \frac{f_{n - 2}}{f_{n - 1}} \frac{\partial f_{n - 1}}{\partial f_{n - 2}} \eta_{n - 2, 0} \:\:;\:\:\: \eta_{0,0} = 1
\end{equation}

The calculation of $\eta_{n - 1, 0}$ requires calculation of $\partial f_{n - 1} / \partial f_{n - 2}$, which works out as follows.

\begin{equation}
\frac{\partial f_{n - 1}}{ \partial f_{n - 2}} = \Phi \left( \delta_{n - 2} + \eta_{n - 2, 0} s \sqrt{T_{n - 2}} \right) + \frac{\partial \eta_{n - 2, 0}}{ \partial f_{n - 2}} f_{n - 2} \phi \left(\delta_{n - 2} + \eta_{n - 2, 0} s \sqrt{T_{n - 2}} \right)
\end{equation}

Where $\phi()$ is the standard normal probability density function, and

\begin{equation}
\frac{\partial \eta_{i - 1, 0}}{ \partial f_{i - 1}} =
\begin{cases}
\frac{\partial}{\partial f_{i - 1}} 1 = 0 &, i = 1 \\
\frac{\partial}{\partial f_{i - 1}} \left(\frac{f_{i - 2}}{f_{i - 1}} \frac{\partial f_{i - 1}}{\partial f_{i - 2}} \right) = -\frac{\eta_{i - 1}}{f_{i - 1}} &, i > 1
\end{cases}
\end{equation}

The ROV of stage 2 of an $n$-stage project is thus calculated recursively, starting with the calculation of $f_1(x, t; T_0, K_0, s, r)|_{t = 0}$. In the process, the probabilities of each stage finishing in the money, $\Phi(\delta_i)$, and each stage's sensitivity to changes in project NPV, $\eta_{i, 0}$, are calculated.

# An illustrative example
<!-- of real option valuation of a multi-stage AR4D project -->

As an illustrative example, below we apply the formula developed above to calculate the ROV of a real multi-stage AR4D project currently in implementation. The aim of the project in question is to develop a transgenic potato variety with resistance to Late Blight disease (henceforth LBr potato), for release as a public good in two developing countries. Late Blight is the disease behind the infamous Irish Potato Famine of 1845-1849; and continues to pose a major threat to food security, especially in the developing world [@haverkort2008societal; @fry2008phytophthora]. Successful research and development of LBr potato varieties adapted to local environments is thus a potentially very high reward, disruptive proposition. It is also a high risk proposition, facing numerous research and non-research related challenges, not least of which is a strong "anti-GM" lobby in many of the target populations.

The LBr potato project is structured in four consecutive stages. These stages and their associated costs and time durations are summarized in Table 1, based on figures documented by Schiek et al. [-@schiek2016demys]. This is a purely pedagogical exercise designed to illustrate the use of the multi-stage ROV model derived in the previous sections. While the exercise is based on real project stage costs and time horizons, the other parameter values are hypothetical. The resulting calculations should therefore not be interpreted as an authoritative valuation of LBr potato research.
<!-- structure described in section \ref{sec:resStages}. The costs and time duration associated with each stage are summarized in Table 1,  -->
<!-- Costs are assessed as the sum of staff costs, direct operating costs (including lab bench costs), indirect operating costs (overhead), external contract costs, and stewardship costs. -->

```{r, echo = FALSE}
# Define functions
#----------------------------------------------------------------------------
# Table formatting function
# FitFlextableToPage <- function(ft, pgwidth = 6){
#   
#   ft_out <- ft %>% autofit()
#   #these_colWidths <- dim(ft_out)$widths * pgwidth  / (flextable_dim(ft_out)$widths)
#   these_colWidths <- dim(ft_out)$widths
#   these_colWidths[5] <- these_colWidths[1] * 1.5
#   #these_colWidths[6] <- these_colWidths[6] * 0.7
#   these_colWidths <- these_colWidths * pgwidth  / (flextable_dim(ft_out)$widths)
#   ft_out <- width(ft_out, width = these_colWidths)
#   return(ft_out)
# }

#============================================================================
#============================================================================
# End function definition
#============================================================================
#============================================================================
# Project stage time durations and costs (PREVIOUS DRAFT)
# (Values given in chronologically reverse order, starting with stage n.)
# Kvec[1] is the launch cost, Tvec[1] is the launch duration.
# Time durations given in years, multiplied by 4 to convert to quarters.
# MSU/cornell
# Tvec <- c(2, 3.5, 1, 2, 4) * 4
# Kvec <- c(300000, 200000, 400000, 400000, 530000)
# Tvec <- c(2, 3, 0.85, 1.7, 3.4) * 4
# Kvec <- c(250000, 181000, 312000, 336000, 530000)
# Kvec <- c(180541, 311974, 335530, 530250)
# CIP
# Kvec <- c(52000, 213000, 396000, 929000)
# Tvec <- c(1, 0.25, 2, 4.75) * 4
#===============================================================================
# Stage time duration params (CURRENT DRAFT)
# Stage durations - last stage first
# periodDurations <- c(3, 4, 2, 3) * 4
# tauVec <- rev(cumsum(periodDurations))
#TvecYrs <- c(4, 2, 4, 4); TvecQtrs <- TvecYrs * 4 # last first
#TvecYrs <- c(3, 1, 2, 4) # last first
TvecYrs <- c(4, 2, 1, 3); TvecQrs <- TvecYrs * 4 # In order
tauVecYrs <- rev(cumsum(TvecYrs)); tauVecQrs <- tauVecYrs * 4 # reverse so last first
stage1Invest <- 531000
Kvec <- c(500000, 181000, 312000, 336000) # Last stage first
#===============================================================================
# Define discount rate
rYrly_discrete <- 0.12 #0.035
rQrly_discrete <- (1 + rYrly_discrete)^(1 / 4) - 1
rYrly <- round(log(1 + rYrly_discrete), 3)
r <- round(log(1 + rQrly_discrete), 3)
#===============================================================================
# Create table summarizing stage costs, time durations, and descriptions
stage1desc <- "Basic replication and scaling up"
stage2desc <- "Multi-location/season testing"
stage3desc <- "Compilation of the regulatory dossier"
stage4desc <- "Deregulation"
#launchDesc <- "Launch in 2 countries"
descVec <- c(stage1desc, stage2desc, stage3desc, stage4desc)#, launchDesc)

df_table <- data.frame(Stage = c(1:4),
                       Kn = rev(Kvec),
                       Duration = TvecQrs,
                       DurationCum = rev(tauVecQrs),
                       Description = descVec)

colnames(df_table)[2:4] <- c("Cost\n(USD)", "Duration\n(annual quarters)", "Time until\ncompletion")

#df_table <- regulartable(df_table)
#df_table
#df_table <- width(df_table, width = 0.7)
table_title <- "Project to research and develop Late Blight resistant potato for release as a public good in 2 developing countries."
table_caption <- "Stage 1-4 costs and durations based on figures reported by Schiek et al. (2016)."# The launch cost and duration is hypothetical."

#df_table <- FitFlextableToPage(df_table)
# df_table <- add_header_lines(df_table, table_title)
# df_table <- add_footer_lines(df_table, table_caption)
# modifiedColnames <- colnames(df_table)
# modifiedColnames[3] <- "Duration\n(annual quarters)"
df_table %>%
  knitr::kable(
    format = "latex",
    caption = table_title,
    align = "l",
    booktabs = T,
    #longtable = T,
    linesep = " ",
    escape = F
  ) %>%
  kableExtra::kable_styling(
    position = "left",
    latex_options = c("HOLD_position", "scale_down", "striped", "repeat"),
    full_width = F,
    stripe_color = "gray!15"
  ) %>%
  # kableExtra::column_spec(column = 3:4, width = "1.5in"
  # ) %>%
  kableExtra::footnote(
    general = table_caption)
# number = c("Footnote 1; ", "Footnote 2; "),
# alphabet = c("Footnote A; ", "Footnote B; "),
# symbol = c("Footnote Symbol 1; ", "Footnote Symbol 2"))

# print_this_table <- function(df_table){
# df_table <- regulartable(df_table)
# df_table <- width(df_table, width = 5.5)
# # df_table <- FitFlextableToPage(df_table)
# 
# df_table %>% #regulartable() %>% autofit() %>%
#   valign(valign = "top", part = "all") %>%
#   align(align = "left", part = "all") %>%
#   fontsize(i = NULL, j = NULL, size = 9, part = "body") %>%
#   fontsize(i = NULL, j = NULL, size = 10, part = "header")
#   
# }


```

The donor, USAID, originally awarded the LBr potato research contract to Cornell University in 2010, with planned release in India. However, stage 1 research and development at Cornell was unsuccessful. In 2015, USAID transferred the contract to Michigan State University (MSU), which proposed a different stage 1 research strategy, with planned release in Bangladesh and Indonesia instead of India. India was dropped as a target country partly because of the vigorous anti-GM lobby there, which made stage 4 success unlikely. MSU completed stage 1 successfully in 2019, and a couple years later USAID awarded them a new contract for stage 2 research and development.
<!-- and extended the list of countries targeted for release of LBr potato to include Kenya and Nigeria. The evolution of LBr project NPV may thus be characterized as a handful of substantive changes, due to unexpected shifts in research and non-research related factors, interspersed by a much larger number of negligibly small changes. At the time of writing, stage 2 research is successfully nearing completion [pers correspondence]. -->

In the multi-stage real options language developed above, USAID bought an option on stage 2 of a 4 stage LBr potato research project when it awarded the original contract to Cornell; but this option expired out of the money at the end of stage 1. USAID then again bought an option on stage 2 research when it transferred the contract to MSU. This time, the option expired in the money, triggering investment in stage 2 research. The investment in stage 2 research is an option on stage 3.
<!-- , and is now approaching expiry in the money. -->

The aim of the present exercise is to calculate the ROV of stage 2 of the 4-stage LBr potato research project that USAID awarded to MSU in 2015. This is the value of USAID's option, but not obligation, to fund stage 2 once stage 1 is complete. The exercise is conducted from the donor's perspective in the months prior to the "go/no-go" stage 1 investment decision. All values are given in terms of 2015 US dollars.

In order to make the calculation, the research stage and final launch costs $K_0, K_1, \dots, K_4$ and time horizons $T_0, T_1, \dots, T_3$ listed in Table 1 are required, as well as the quarterly discount rate $r$, the project NPV volatility $s$, and the project NPV at the time of the go/no-go decision to invest in stage 1 LBr research, $x(0)$.

USAID generally uses a high annual discount rate of $0.12$ in its cost-benefit analyses of agricultural development projects [@usaid2015cba]. A high discount rate is reasonable considering the long time horizon and high uncertainty surrounding project NPV, and considering that any alternative use of USAID funds would entail a similar level of elevated risk. We thus adopt USAID's annual (discrete) discount rate for the present exercise, which works out to a (continuous) quarterly discount rate of `r r` used in the calculation.

```{r, fig.show = "hold", fig.width = 5, fig.height=4, fig.align="center", fig.cap="\\label{fig:netBens}(Top) A hypothetical 12 year projection of the discounted and undiscounted LBr potato net benefit stream from time of release in the target countries. (Bottom) The integral of discounted net benefits up to each year.", echo = FALSE}
# Define functions
get_di <- function(K_im1, f_im1, tau_i, m, s, eta_im10 = 1){
  d_i <- (log(f_im1 / K_im1) + (m - eta_im10^2 * s^2 / 2) * tau_i) / (s * eta_im10 * sqrt(tau_i))
  return(d_i)
}
ROVi <- function(K_im1, f_im1, tau_i, m, s, eta_im10 = 1){
  d_i <- get_di(K_im1, f_im1, tau_i, m, s, eta_im10)
  u <- d_i + eta_im10 * s * sqrt(tau_i)
  rov <- f_im1 * pnorm(u) - exp(-r * tau_i) * K_im1 * pnorm(d_i)
  probSuc <- pnorm(d_i)
  return(c(rov, probSuc))
}
get_dfidfim1 <- function(K_im1, f_im1, f_i, tau_i, m, s, eta_im10 = 1){
  d_i <- get_di(K_im1, f_im1, tau_i, m, s, eta_im10)
  u <- d_i + eta_im10 * s * sqrt(tau_i)
  if(eta_im10 == 1){dEtaim10dfim1 <- 0}else{dEtaim10dfim1 <- -eta_im10 / f_im1}
  dfidfim1 <- pnorm(u) + dEtaim10dfim1 * s * sqrt(tau_i) * f_im1 * dnorm(u)
  if(abs(dfidfim1) < 10^-10){dfidfim1 <- 0}
  return(dfidfim1)
}
ROVn <- function(X0, Kvec, tauVec, m, s){
  f_im1 <- X0; eta_im10 <- 1
  n <- length(Kvec)
  fiOut <- c(); etaOut <- c(); probSucVec <- c()
  for(i in 1:n){
    tau_i <- tauVec[i]; K_im1 <- Kvec[i]
    outROVi <- ROVi(K_im1, f_im1, tau_i, m, s, eta_im10)
    f_i  <- outROVi[1]; probSuc <- outROVi[2]
    dfidfim1 <- get_dfidfim1(K_im1, f_im1, f_i, tau_i, m, s, eta_im10)
    eta_i0 <- f_im1 / f_i * dfidfim1 * eta_im10
    fiOut[i] <- f_i; etaOut[i] <- eta_i0; probSucVec[i] <- probSuc
    f_im1 <- f_i; eta_im10 <- eta_i0
  }
  return(data.frame(f_i = fiOut, eta_i0 = etaOut, probSuc = probSucVec))
}
rootROVn <- function(X0, Kvec, tauVec, mm, s, stage1Invest){
  dfOut <- ROVn(X0, Kvec, tauVec, mm, s)
  f_n <- dfOut$f_i[nrow(dfOut)]
  slack <- f_n - stage1Invest
  return(slack)
}
#===============================================================================
#2013 potato VoP 2014-2016 constant USD
VoPIndonesia <- 0.8 #Indonesia: 0.8 billion
VoPBangladesh <- 1.6 #Bangladesh 1.6 billion
VoPKenya <- 0.8 #Kenya: 0.8 billion
VoPNigeria <- 0.5 #Nigeria: 0.5 billion
VoPvec <- c(VoPIndonesia, VoPBangladesh, VoPKenya, VoPNigeria)
# VoPtot <- sum(VoPvec)
# VoPpot <- VoPtot / 0.9
# yrlyLoss <- VoPpot - VoPtot
thisVoP <- VoPNigeria
VoPpot <- thisVoP / 0.9
yrlyLoss <- VoPpot - thisVoP
#yrlyLoss
# yrlyLoss <- VoPpot * 0.15 #billion
#yrlyLoss <- VoPIndonesia / 0.9 *  #billion
#===============================================================================
# Calculate project NPV(Tn) i.e. X0
yrHoriz <- 12; qtrHoriz <- yrHoriz * 4
t <- seq(0, qtrHoriz, length.out = qtrHoriz + 1)
# alphaYrly_discrete <- 0.65
# alphaQrly_discrete <- (1 + alphaYrly_discrete)^(1 / 4) - 1
# alphaQrly <- round(log(1 + alphaQrly_discrete), 3)
alphaQrly <- 0.6
dNVT0ref <- 0.11; tRef <- 12
dNVT0 <- dNVT0ref * (t / tRef)^alphaQrly
dNPVT0_discrete <- dNVT0 / (1 + rQrly_discrete)^t
#dNPVT0_discrete <- dNVT0 / (1 + rYrly_discrete)^t
dNPVT0_contin <- exp(-r * t) * dNVT0
#dNPVT0_contin <- exp(-rYrly * t) * dNVT0
library(expint)
A <- dNVT0ref * tRef^(-alphaQrly)
NPVT0 <- A / r^(1 + alphaQrly) * (-gammainc(1 + alphaQrly, r * t) + gammainc(1 + alphaQrly, 0))
NPVT0_discrete <- cumsum(dNPVT0_discrete)
NPV0_discrete <- exp(-r * tauVecQrs[1]) * NPVT0_discrete
NPV0 <- exp(-r * tauVecQrs[1]) * NPVT0
#NPV0 <- exp(-rYrly * tauVecYrs[1]) * NPVT0
# plot(t, dNVT0)
# plot(t, dNPVT0)
# plot(t, NPVTn)
#-------------------------------------------------------------------------------
nbCutoffYr <- 12 # Net benefit cutoff year
nbCutoffQtr <- nbCutoffYr * 4
X0 <- NPV0[nbCutoffQtr] * 10^6
#-------------------------------------------------------------------------------
# Plot dNV, dNPV, NPV
library(patchwork)
# Set graphic parameters
axisTitleSize <- 7
axisTextSize <- 6
legendKeySize <- 0.3
legendTextSize <- axisTextSize
#facetTitleSize <- axisTextSize
#plotTitleSize = axisTextSize
#labelSize <- 2
# Organize plot data into data frames
dfdNVT0 <- data.frame(Quarter = t, val = dNVT0, type = "Undiscounted\nnet benefits")
dfdNPVT0 <- data.frame(Quarter = t, val = dNPVT0_contin, type = "Continuously discounted\nnet benefits")
dfNPVT0 <- data.frame(Quarter = t, NPV = NPVT0)
df1 <- data.frame(rbind(dfdNVT0, dfdNPVT0))
df2 <- dfNPVT0
theseColors <- randomcoloR::distinctColorPalette(2)
# Plot undiscounted and discounted net benefits overlaid
gg <- ggplot(df1, aes(x = Quarter, y = val, fill = type))
gg <- gg + geom_bar(stat = "identity", position = position_dodge(width = 0.25), color = "black")
gg <- gg + scale_fill_manual(values = theseColors)
gg <- gg + scale_x_continuous(breaks = seq(0, qtrHoriz, 4),
                              labels = seq(0, yrHoriz, 1))
gg <- gg + labs(x = "Years from release", y = "Million USD")
gg <- gg + theme_bw()
gg <- gg + theme(axis.text = element_text(size = axisTextSize),
                 axis.title = element_text(size = axisTitleSize),
                 legend.title = element_blank(),
                 legend.position = "top",
                 legend.text = element_text(size = legendTextSize),
                 legend.key.size = unit(legendKeySize, "cm"))
gg1 <- gg
# Plot NPV
gg <- ggplot(dfNPVT0, aes(x = Quarter, y = NPV))
gg <- gg + geom_bar(stat = "identity", color = "black")
gg <- gg + scale_x_continuous(breaks = seq(0, qtrHoriz, 4),
                              labels = seq(0, yrHoriz, 1))
gg <- gg + labs(x = "Years from release", y = "NPV\n(million USD)")#, title = "(c)")
gg <- gg + theme_bw()
gg <- gg + theme(axis.text = element_text(size = axisTextSize),
                 axis.title = element_text(size = axisTitleSize))#,
#                 plot.title = element_text(size = axisTitleSize))
gg2 <- gg
gg1 / gg2 #+ plot_annotation(tag_levels = "a")
#===============================================================================
# Define project NPV volatility:
cv <- 1.5
s <- cv * r * sqrt(tauVecQrs[1])
# Calculate ROV of stage 1 research
m <- r
dfROVn <- ROVn(X0, Kvec, tauVecQrs, m, s)
f_n <- dfROVn$f_i[nrow(dfROVn)]
#f_n - stage1Invest
# Conventional CBA
CBAlhs <- X0 - sum(exp(-r * tauVecQrs) * Kvec)
CBA <- CBAlhs - stage1Invest
#===============================================================================
# "Manual" check step by step
eta_00 <- 1; f0 <- X0
outROVi <- ROVi(Kvec[1], f0, tauVecQrs[1], m, s, eta_00) # Value of option to launch
f1 <- outROVi[1]; probSuc1 <- outROVi[2]
df1df0 <- get_dfidfim1(Kvec[1], f0, f1, tauVecQrs[1], m, s, eta_00)
#pnorm(get_di(Kvec[1], X0, tauVecQrs[1], m, s, eta_00) + eta_00 * s * sqrt(tauVecQrs[1]))
eta_10 <- f0 / f1 * df1df0 * eta_00
outROVi <- ROVi(Kvec[2], f1, tauVecQrs[2], m, s, eta_10) # Value of option on stage 4 research
f2 <- outROVi[1]; probSuc2 <- outROVi[2]
df2df1 <- get_dfidfim1(Kvec[2], f1, f2, tauVecQrs[2], m, s, eta_10)
eta_20 <- f1 / f2 * df2df1 * eta_10
outROVi <- ROVi(Kvec[3], f2, tauVecQrs[3], m, s, eta_20) # Value of option on stage 3 research
f3 <- outROVi[1]; probSuc3 <- outROVi[2]
df3df2 <- get_dfidfim1(Kvec[3], f2, f3, tauVecQrs[3], m, s, eta_20)
eta_30 <- f2 / f3 * df3df2 * eta_20
outROVi <- ROVi(Kvec[4], f3, tauVecQrs[4], m, s, eta_30) # Value of option on stage 2 research
f4 <- outROVi[1]; probSuc4 <- outROVi[2]
df4df3 <- get_dfidfim1(Kvec[4], f3, f4, tauVecQrs[4], m, s, eta_30)
eta_40 <- f3 / f4 * df4df3 * eta_30
#-------------------------------------------------------------------------------
dfROVnCheck <- data.frame(f_i = c(f1, f2, f3, f4), eta_i0 = c(eta_10, eta_20, eta_30, eta_40), probSuc = c(probSuc1, probSuc2, probSuc3, probSuc4))
#dfROVn - dfROVnCheck


```
<!-- Ex-ante impact assessments of LBr potato in the target countries are underway, but have not yet been published at the time of writing [pers correspondence]. -->

At the 2015 go/no-go decision point, no published ex-ante impact assessments of LBr potato in the target countries exist. For the pedagogical purposes of this exercise, we suppose that the donor conducts its own ex-ante impact assessment internally, finding that annual net benefits are likely to scale sublinearly with time by `r alphaQrly`% for every $1$% increase in time, reaching \$`r dNVT0ref * 10^3` thousand in year `r tRef / 4` after release. This hypothetical assessment corresponds to the undiscounted net benefit projection in the top panel of Figure \ref{fig:netBens}, which may be expressed mathematically as follows.
[when Marc's paper comes out add sentence: "in hindsight, this will prove an overly conservative estimate"]

\begin{equation}
y(t) = y(\hat{t}) \left( \frac{t}{\hat{t}} \right)^{\alpha}
\end{equation}

Where $y(t)$ stands for LBr potato net benefit at time $t$ after release, $y(\hat{t}) =$ \$`r format(dNVT0ref * 10^6, scientific = F)`, $\alpha =$ `r alphaQrly`, and, for the quarterly time step in Figure \ref{fig:netBens}, $\hat{t} =$ `r tRef`.

The corresponding continuously discounted net benefit projection ($e^{-rt} y(t)$) is overlaid onto the undiscounted projection in the same top panel of Figure \ref{fig:netBens}. Integration of the discounted net benefits with respect to $t$ over $[T_0, T_{-1}]$ gives project NPV at time of release ($x(T_0)$), presented in the bottom panel of Figure \ref{fig:netBens}.

\begin{equation}
\begin{split}
x(T_0)|_{t = T_{-1}} &= \int_{T_0}^{T_{-1}} e^{-rt} y(t) \: dt \\
&= \frac{y(\hat{t})}{\hat{t}^{\alpha} r^{\alpha + 1}} ( -\Gamma(\alpha + 1, r(T_{-1} - T_0)) + \Gamma(\alpha + 1, 0) )
\end{split}
\end{equation}

Where $\Gamma(u,v)$ is the incomplete gamma function. The upper bound $T_{-1}$ is a net benefit cutoff set by the donor. Net benefits continue beyond $T_{-1}$, but the donor is only interested in net benefits up to $T_{-1}$. Values of $x(T_0)$ are given in the bottom panel of Figure \ref{fig:netBens} for cutoffs ranging from $1$ to `r nbCutoffYr` years after release. For the calculation of ROV in the present hypothetical exercise, the donor sets $T_{-1}$ to `r nbCutoffYr` years (`r 4 * nbCutoffYr` quarters) after release. This gives a project NPV of \$`r round(NPVT0[nbCutoffQtr], 3)` million at time of release $T_0$, i.e. at the end of stage 4 research. The project NPV discounted back to the time of the donor's go/no-go decision to fund stage 1 research is then $x(0) = e^{-rT_{4}} x(T_0) =$ \$`r round(X0 * 10^-6, 3)` million.

The only remaining information required to calculate ROV is the LBr potato release and outscaling cost due at $t = T_0$ upon successful completion of stage 4, and the project NPV volatility parameter $s$. For this pedagogical exercise, it is hypothesized that the donor estimates the release and outscaling cost to be \$`r Kvec[1] * 10^-3` thousand. As mentioned in section \ref{sec:gBmDefens}, no project NPV time series exists whereby project volatility $s$ might be directly estimated. In practice, an implicit value for $s$ can be calculated by eliciting from experts upper and lower bounds on $x(T_0)$. That is to say, interpreting these bounds as the 95% confidence interval, a value for $s$ can be "backed out" from the assumption that project NPV follows a gBm (which implies lognormally distributed $x(T_0)$). In the present exercise, we hypothesize that such a process results in a value of $s=$ `r round(s, 3)`. This corresponds to a coefficient of variation ($s / (r \sqrt{T_0})$) of `r cv`, reflecting the high uncertainty that typically surrounds the expected impact of disruptive new technology a decade in advance of its completion and release.

With all of the necessary information in hand, the ROV of stage 2 LBr research is calculated by first calculating the ROV of stage 4, the last stage, and then calculating the ROV of stage 3, and so forth, recursively, as explained in section \ref{sec:method}. In the present exercise, this results in an ROV of stage 2 LBr research of \$`r format(round(f_n), scientific = F)`, which exceeds the stage 1 cost of \$`r format(stage1Invest, scientific = F)` by \$`r format(round(f_n - stage1Invest), scientific = F)`. On the ROV basis, then, the stage 1 investment is justified. By the conventional CBA criterion, meanwhile, the project would be rejected, as the left-hand side of inequality \ref{eq:cbaCrit} works out to \$`r format(round(CBAlhs), scientific = F)`, which falls below the stage 1 cost by \$`r format(abs(round(CBA)), scientific = F)`.
<!-- \begin{equation} -->
<!-- 1180000 - \sum_{i = 0}^3 e^{-r T_i} K_i < 530000 \:\: \rightarrow \:\: \text{reject project} -->
<!-- \label{eq:convCBA} -->
<!-- \end{equation} -->

The recursively calculated ROVs for each stage of research are presented in Table 2. Also included in this table are each stage's ROV elasticity with respect to project NPV and probability of finishing in the money, which are calculated in the process. This provides additional information, not provided in conventional CBA, that the donor may find useful in their decision making process.

```{r, echo=FALSE}
#===============================================================================

dfROVn$Stage <- 4:1; #dfROVn$i <- 1:4
dfROVn <- dfROVn[, c("Stage", "f_i", "eta_i0", "probSuc")]
dfROVn$f_i <- round(dfROVn$f_i)
dfROVn$eta_i0 <- round(dfROVn$eta_i0, 3)
dfROVn$probSuc <- round(dfROVn$probSuc, 3)
dfROVn <- dfROVn[order(dfROVn$Stage, decreasing = F), ]
table_title <- "LBr potato project stage 1-4 ROV"
colnames(dfROVn) <- c("Stage", "ROV", "ROV elasticity w.r.t. project NPV", "Probability of success")
dfROVn %>%
  knitr::kable(
    format = "latex",
    row.names = F,
    caption = table_title,
    align = "l",
    booktabs = T,
    #longtable = T,
    linesep = " ",
    escape = F
  ) %>%
  column_spec(2:4, width = "4cm") %>%
  kable_styling(
    position = "center",
    latex_options = c("HOLD_position", "striped", "repeat"),
    full_width = F,
    stripe_color = "gray!15",
    font_size = 8
  )
#%>%
#  kableExtra::column_spec(column = 4:7, width = "1in")



# df_table %>%
#   knitr::kable(
#     format = "latex",
#     caption = table_title,
#     align = "l",
#     booktabs = T,
#     #longtable = T,
#     linesep = " ",
#     escape = F
#   ) %>%
#   kableExtra::kable_styling(
#     position = "left",
#     latex_options = c("HOLD_position", "scale_down", "striped", "repeat"),
#     full_width = F,
#     stripe_color = "gray!15"
#   ) %>%
#   # kableExtra::column_spec(column = 3:4, width = "1.5in"
#   # ) %>%
#   kableExtra::footnote(
#     general = table_caption)


#===============================================================================
# Find breakeven project NPV
#rootROVn(X0 * 0.2, Kvec, tauVecQrs, mm = r, s, stage1Invest)
thisInt <- c(10^5, 10^8)
outUniroot <- uniroot(rootROVn, interval = thisInt,
                                 #lower = min(thisInt), upper = max(thisInt),
                                 Kvec = Kvec, tauVec = tauVecQrs,
                                 mm = r, s = s, stage1Invest)
X0min <- outUniroot$root
#ROVn(X0min, Kvec, tauVecQrs, m, s)

```

In cases where no ex-ante impact assessment of project NPV is available, it may be instructive to solve ROV of stage 2 research for the break even project NPV, i.e. the value of $x(0)$ required to yield an ROV equal to the stage 1 cost. In this example, the break even project NPV is \$`r round(X0min * 10^-6, 3)` million. Any project NPV above this value results in an ROV of stage 2 LBr research greater than the investment required to implement stage 1.

<!-- USAID-ABSP II program -->
<!-- The project occurred in 4 distinct stages: 1) Late Blight resistant (LBr) event production and selection, 2) Wide area testing, 3) Compilation of the regulatory dossier, and 4) Registration and regulatory affairs. -->
<!-- In stage 1, the lead gene construct was developed in a target potato variety, and a small number of transgenic events exhibiting high resistance to Late Blight, as well as a number of other qualities (absence of backbone vector sequences, minimum number copy number of R genes, etc.) were screened from a large number of explants. -->
<!-- In stage 2, the transgenic events selected in stage 1 were cultivated in three distinct locations and three distinct seasons to assess environmental effects on the LBr trait, and vice versa. Any impacts of LBr on other key traits such as yield, maturation time, taste, and so forth, were also assessed. --><!-- In stage 3, the regulatory dossier was compiled for submission to the National Competent Authority in the country where the LBr potato was to be released. The dossier included compositional and safety assessments, as well as the environmental assessments of the previous stage. -->
<!-- In stage 4, the regulatory dossier was defended and amended before the National Competent Authorty in the target country. This stage may involve a variety of activities, including public advocacy, lobbying, and submission of additional information. -->
<!-- For details see Schiek et al. [@]. -->
<!-- Others argue for a much lower rate when appraising these kinds of projects [@moore2004just; @caplin2004social; @harrison2010valuing]. Low discounting based on the opportunity cost of capital   In the present exercise, we err on the side of high discounting, reflecting the donor's mandate -->

<!-- USAID generally uses a high annual discount rate of $0.12$ in its cost-benefit analyses of agricultural development projects [@usaid2015cba]. However, there are good reasons for using a much lower rate when appraising these kinds of projects [@moore2004just; @caplin2004social; @harrison2010valuing]. As a compromise between the two extremes, an annual (discrete) discount rate of `r rYrly_discrete` is assumed in this exercise, which works out to a (continuous) quarterly discount rate of `r r` used in the calculation. Abandonment values are assumed to be zero for the time being. -->

<!-- # ```{r, echo=FALSE} -->


<!-- df_table <- df[, c("Stage", "Fold (i)", -->
<!--                    "i-fold ROV", "Value of underlying", -->
<!--                    "Elasticity w.r.t. project NPV", -->
<!--                    "Standard dev. of underlying", -->
<!--                    "Probability of exercise")] -->
<!-- #df_tabwB <- df_wB[nrow(df_wB), c("OVn", "fnM10", "etaNm10", "sNm1", "Phi2")] -->
<!-- # colnames(df_table)[2:ncol(df_table)] <- c("ROV", "Value of\nunderlying", "Elasticity\nw.r.t. project NPV", "Standard dev.", "Phi 2") -->
<!-- df_table$`i-fold ROV` <- round(df_table$`i-fold ROV`) -->
<!-- df_table$`Value of underlying` <- round(df_table$`Value of underlying`) -->
<!-- these_cols <- c("Elasticity w.r.t. project NPV", "Standard dev. of underlying", "Probability of exercise") -->
<!-- df_table[, these_cols] <- round(df_table[, these_cols], 2) -->

<!-- # df_table <- regulartable(df_table) -->
<!-- # #df_table <- width(df_table, width = 0.7) -->
<!-- # df_table <- FitFlextableToPage(df_table) -->
<!-- # df_table -->

<!-- table_title <- "LBr potato project stage 1-4 ROVs" -->
<!-- modifiedColnames <- colnames(df_table) -->
<!-- modifiedColnames[2] <- "Fold $i$" -->
<!-- modifiedColnames[3] <- "$i$-fold ROV" -->
<!-- modifiedColnames[ncol(df_table)] <- "Prob. of exercise $\\Phi(\\delta_i)$" -->

<!-- df_table %>% -->
<!--   knitr::kable( -->
<!--     format = "latex", -->
<!--     caption = table_title, -->
<!--     align = "l", -->
<!--     booktabs = T, -->
<!--     #longtable = T, -->
<!--     linesep = " ", -->
<!--     col.names = modifiedColnames, -->
<!--     escape = F -->
<!--   ) %>% -->
<!--   kableExtra::kable_styling( -->
<!--     position = "left", -->
<!--     latex_options = c("scale_down", "striped", "repeat"), -->
<!--     full_width = F, -->
<!--     stripe_color = "gray!15" -->
<!--   ) %>% -->
<!--   kableExtra::column_spec(column = 4:7, width = "1in") -->
<!-- # %>% -->
<!-- #   kableExtra::save_kable("Table 1.png") -->
<!-- # here("Table 1", "test") -->
<!-- # %>% -->
<!-- #   kableExtra::footnote( -->
<!-- #     general = table_caption) -->
<!-- ``` -->


# Discussion and conclusion

<!-- As for the relation between project NPV and the outscaling investment, we refer to the marginally diminishing relationship that typically exists between AR4D project NPV and the size of the investment in the outscaling of the finished technology. That is to say, beyond a certain minimum level of investment required to release and support the diffusion and uptake of the project's research product on a pilot level, further increments in the outscaling investment have the effect of broadening the scope of impact---i.e. the size and number of target populations and environments where the research product is released and has an impact. Existing ROV methods tacitly assume that project NPV and the outscaling investment are independent, or that only one outscaling investment scenario is of interest. The adjustment introduced here facilitates examination of all outscaling investment scenarios, and even makes it possible to solve for the ROV-maximizing outscaling investment. -->

derivation at no point implies all the problematic assumptions of financial/corporate option value...
tradeoff--increasing volatility increases ROV but decreases probability of success...
abstract from the messiness... in particular deadline extensions, staggered finishing (Kenya) and release
Assessment of $s$...
potential use as insurance...
...can be used in any other suitable non-ar4d context

<!-- In this article, I have developed an $n$-fold ROV model to evaluate the real option value of multistage AR4D projects. The model effectively prices in the research donor's option to discontinue funding of a project at the end of well defined research stages, thereby facilitating donor commitment to the long time horizons of agricultural research. In other words, the model formalizes the de facto structure of most AR4D project funding arrangements. The model also accounts for the wide uncertainty that usually surrounds AR4D project NPV, thereby reducing the pressure on researchers to put an exact monetary value on impacts that may be decades in the future. I have also extended the model to include abandonment value. -->

<!-- The proposed model is particularly appropriate for the valuation of high risk, deep-in-the-money (i.e. high expected reward) projects. The higher a project's moneyness (i.e. the higher the expected reward), the higher must be its volatility for there to be a meaningful difference between the ROV and conventional CBA approaches. In the case of LBr potato examined above, for example, a small increase in the hypothetical NPV and/or decrease in the confidence interval given by $\bar{\ell}$, $\underline{\ell}$ (and hence a decrease in the volatility $s$) results in an ROV that is virtually the same as the NPV, in which case there is no point in evaluating the $n$-fold ROV. -->

<!-- The proposed model rests on the assumption that project NPV follows a gBm, and is thus subject to criticism insofar as this assumption is unrealistic. In response to critics who reject the gBm assumption on the basis that the time evolution of project NPV fails to resemble that of gBm, I have argued that 1) the time domain discrepancy is largely spurious, attributable to one's theory of how/when new information affects project NPV, and to one's choice of time step $\Delta t$. And, more importantly, I have argued that 2) it is not the time domain, but the frequency domain that is relevant when it comes to far-from-market ROV calculation. That is to say, the calculation of ROV hinges upon the size distribution of changes in NPV, regardless of when or in what order the changes occur. Assuming that project NPV follows a gBm is tantamount to assuming that percentage changes in project NPV are normally distributed. Insofar as this assumption is valid, then, the proposed model is valid. Practitioners are forewarned that rejection of this assumption tends to lead to the sort of black box complexity that has so far inhibited wider adoption of the ROV approach. -->

<!-- Note that project NPV usually scales with the launch and scaling up cost $K_n$. That is to say, beyond a certain minimum level of funding required to generate, release, and support the diffusion and uptake of the project's research product on a pilot level, further increments in the investment $K_n$ have the effect of broadening the scope of impact---i.e. extending the size and number of target populations and environments where the research product is released and has an impact. In future work, then, it might be worthwhile to explore the ROV implications of explicitly modeling project NPV as a function of the scaling up investment $K_n$. For example, $x(0)$ could be defined -->

<!-- \begin{equation} -->
<!-- x(0) = \tilde{x}(0) \left(\frac{K_n}{\bar{K}_n}\right)^{\alpha} -->
<!-- \end{equation} -->

<!-- Where the parameter $\bar{K}_n$ is a reference value---perhaps the minimum or maximum possible scale up investment, for example---$\tilde{x}(0)$ is the project NPV if scaling up funding equals the reference value, and the exponent $\alpha$ is restricted to fall between 0 and 1, reflecting decreasing returns to scale. It may then be interesting to analyze ROV response to successively higher scale up investments $K_n$, corresponding to successively broader geographical scopes of impact. -->

For purposes of exposition, I have focused here on the valuation of transgenic projects; but the $n$-fold ROV model derived in this article is of course not limited to such ventures. It applies just as well to the valuation of conventional crop and livestock breeding projects, as well as to multistage AR4D projects not necessarily built around the objective of genetic gain. This includes, for example, projects involving digital agriculture, value chain integration, social capital formation, agricultural biodiversity, environmental services, climate smart agriculture, agroecology, etc., and combinations thereof. The proposed model can also be applied at more aggregate levels of accounting---to valuate, for example, a multistage program consisting of several projects in various stages of implementation. While AR4D is the motivating context of the present work, the model presented here is generally applicable to the valuation of any far-from-market, multistage venture.


\appendix
\renewcommand{\thesection}{A}

# Appendix {-}

## Proof of equation \ref{eq:genEq} through straightforward integration {-}

<!-- Lemma: -->

<!-- If $v(t)$ follows a geometric Brownian motion; that is to say, if the instantaneous evolution of $v(t)$ over time can be expressed -->

<!-- \begin{equation} -->
<!-- \Delta v = \alpha v \Delta t + \beta v \epsilon \sqrt{\Delta t} \:\:;\:\:\: \Delta v = v(t + \Delta t) - v(t) -->
<!-- \label{eq:deltaV} -->
<!-- \end{equation} -->

<!-- Where $\epsilon$ is a normally distributed random variable with mean $0$ and variance $1$, and $\alpha$ and $\beta$ are constant with respect to the instantaneous time increment $\Delta t$, such that -->

<!-- \begin{equation} -->
<!-- \frac{\Delta v}{v} ~ \phi(\alpha \Delta t, \beta^2 \Delta t) -->
<!-- \end{equation} -->

<!-- Where $\phi()$ is the standard normal probability density function; and hence -->

<!-- \begin{equation} -->
<!-- v(T) = v(\hat{t}) e^{(\alpha - \beta^2 / 2) \tau + \beta \epsilon \sqrt{\tau}} -->
<!-- \label{eq:defVt} -->
<!-- \end{equation} -->

<!-- Where $T$ is some future time step, $\hat{t} < T$ is the time step at which $v(T)$ is evaluated, and $\tau = T - \hat{t}$. (See Hull [@hull9thEdition] for details.) Then, for a constant C, -->
<!-- <!-- , such that --> 
<!-- <!-- \begin{equation} --> 
<!-- <!-- \ln \left(\frac{v(T)}{v(\hat{t})} \right) ~ \phi \left(\left(\alpha - \frac{\beta^2}{2} \right) \tau, \beta^2 \tau \right) -->
<!-- <!-- \end{equation} -->

<!-- \begin{equation} -->
<!-- E[max(v(T) - C, 0)]\bigr|_{t = \hat{t}} = e^{\alpha \tau} v(\hat{t}) \Phi(\delta + \beta \sqrt{\tau}) - C \Phi(\delta) -->
<!-- \end{equation} -->

<!-- Where $\Phi()$ is the standard normal cumulative distribution function, and -->

<!-- \begin{equation} -->
<!-- \delta = \frac{\ln(v(\hat{t}) / C) + (\alpha - \beta^2 / 2) \tau}{\beta \sqrt{\tau}} -->
<!-- \end{equation} -->

<!-- Proof: -->

(The proof below closely follows that of Hull in the appendix to chapter 13 of his book [-@hull9thEdition]. It is presented here solely for the reader's convenience, with no claim to originality.)
<!-- _Part 1_ -->

By definition, for a random variable $q$ and a constant $C$,

\begin{equation}
E[\max(q - C, 0)] = \int_{C}^{\infty} (q - C) p(q) \: dq
\label{eq:def}
\end{equation}

Where $p(q)$ is the probability density function of the random variable $q$. If $\ln(q)$ is normally distributed with mean $\nu$ and variance $\omega^2$, then

\begin{equation}
E[q] = e^{\nu + \frac{\omega^2}{2}}
\label{eq:muXT}
\end{equation}

and

\begin{equation}
p(q) = \frac{1}{q \omega} \phi \left(\frac{\ln(q) - \nu}{\omega} \right)
\end{equation}

Where $\phi()$ is the standard normal probability density function.

Now, introducing a change of variables,

\begin{equation}
u = \frac{\ln(q) - \nu}{\omega}
\label{eq:subThis1}
\end{equation}

Such that

\begin{equation}
\frac{du}{d q} = \frac{1}{q \omega}\: \rightarrow \: d q = q \omega du
\label{eq:subThis2}
\end{equation}

The definition in equation \ref{eq:def} can be rewritten as follows.

\begin{equation}
\begin{split}
E[\max(q - C, 0)] &= \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} (e^{u \omega + \nu} - C) \phi(u) \: du \\
&= \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} e^{u \omega + \nu} \phi(u) \: du - C \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} \phi(u) \: du \\
&= \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} e^{u \omega + \nu} \phi(u) \: du - C \Phi \left(-\frac{\ln(C) - \nu}{\omega} \right)
\end{split}
\end{equation}

The remaining integral on the right-hand side of the definition resolves as follows.

\begin{equation}
\begin{split}
\int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} e^{u \omega + \nu} \phi(u) \: du &= \frac{1}{\sqrt{2 \pi}} \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} e^{u \omega + \nu -\frac{u^2}{2}} \: du \\
&= \frac{1}{\sqrt{2 \pi}} \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} e^{-1 / 2 (u^2 - 2 u \omega - 2 \nu)} \: du \\
&= \frac{1}{\sqrt{2 \pi}} \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} e^{-\frac{(u - \omega)^2}{2} + \nu + \frac{\omega^2}{2}} \: du \\
&= \frac{1}{\sqrt{2 \pi}} \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} e^{-\frac{(u - \omega)^2}{2}} e^{\nu + \frac{\omega^2}{2}} \: du \\
&= e^{\nu + \frac{\omega^2}{2}} \frac{1}{\sqrt{2 \pi}} \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} e^{-\frac{(u - \omega)^2}{2}} \: du \\
&= \frac{E[q]}{\sqrt{2 \pi}} \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} e^{-\frac{(u - \omega)^2}{2}} \: du \\
&= \frac{E[q]} \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} \phi(u - \omega) \: du \\
&= \frac{E[q]} \Phi \left(- \frac{\ln(C) - \nu}{\omega} + \omega \right)
\end{split}
\end{equation}

The definition may now be rewritten as follows.

\begin{equation}
E[\max(q - C, 0)] = E[q] \Phi \left(- \frac{\ln(C) - \nu}{\omega} + \omega \right) - C \Phi \left(-\frac{\ln(C) - \nu}{\omega} \right)
\end{equation}

Note that \ref{eq:muXT} can be rearranged into an expression for $\nu$.

\begin{equation}
\nu = \ln(E[q]) - \omega^2 / 2
\end{equation}

Substituting this for $\nu$ in the definition gives

\begin{equation}
E[\max(q - C, 0)] = E[q] \Phi \left(\frac{\ln \left( \frac{E[q]}{C} \right) + \frac{\omega^2}{2}}{\omega} \right) - C \Phi \left(-\frac{\ln \left( \frac{E[q]}{C} \right) - \frac{\omega^2}{2}}{\omega} \right)
\end{equation}

$\blacksquare$

## Derivation of Equation \ref{eq:rov} from the Black-Scholes PDE {-}

Starting from the Black-Scholes PDE,

\begin{equation}
fr = \frac{\partial f}{\partial x} x r + \frac{\partial f}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f}{\partial x^2}
\end{equation}

Note that

\begin{equation}
x^2 \frac{\partial^2 f}{\partial x^2} = \frac{\partial^2f}{\partial \ln(x)^2} - \frac{\partial f}{\partial \ln(x)}
\end{equation}

Such that the PDE may be rewritten

\begin{equation}
fr = \frac{\partial f}{\partial \ln(x)} \left(r - \frac{s^2}{2} \right) + \frac{\partial f}{\partial t} + \frac{s^2}{2} \frac{\partial^2f}{\partial \ln(x)^2}
\end{equation}

Defining $f = e^{-r \tau} y$ and substituting this in for $f$,

\begin{equation}
0 = \frac{\partial y}{\partial \ln(x)} \left(r - \frac{s^2}{2} \right) + \frac{\partial y}{\partial t} + \frac{s^2}{2} \frac{\partial^2 y}{\partial \ln(x)^2}
\end{equation}

Substituting $T - \tau$ for $t$ and expressing the equation in terms of a new function $v(u, \tau)$, where $u = \ln(x) + (r - s^2 / 2) \tau$,

\begin{equation}
0 = \frac{s^2}{2} \frac{\partial^2 v}{\partial u^2} - \frac{\partial v}{\partial t}
\end{equation}

This is the one dimensional heat equation, with fundamental solution

\begin{equation}
v(u, \tau) = \frac{1}{\sqrt{2 \pi s^2 \tau}} \int_{-\infty}^{\infty} v(\ell, 0) e^{-\frac{(u - \ell)^2}{2 s^2}} \:d \ell
\end{equation}

The boundary condition in this case is $f(x, T) = \max(X(T) - K, 0)$, which in terms of $v(u, \tau)$ is $v(u, 0) = \max(e^u - K, 0)$.

\begin{equation}
\begin{split}
v(u, \tau) &= \frac{1}{s \sqrt{2 \pi \tau}} \int_{\ln(K)}^{\infty} (e^{\ell} - K) e^{-\frac{(u - \ell)^2}{2 s^2}} \: d \ell \\
&= \frac{1}{s \sqrt{2 \pi \tau}} \int_{\ln(K)}^{\infty} e^{\ell - \frac{(u - \ell)^2}{2 s^2}} \:d \ell - \frac{K}{s \sqrt{2 \pi \tau}} \int_{\ln(K)}^{\infty} e^{-\frac{(u - \ell)^2}{2 s^2 \tau}} \:d \ell
\end{split}
\end{equation}

Introducing the substitution

\begin{equation}
z = \frac{\ell - u}{s\sqrt{\tau}} \rightarrow \: s\sqrt{\tau} dz = d \ell
\end{equation}

The integral simplifies to

\begin{equation}
\begin{split}
v(u, \tau) &= \frac{1}{\sqrt{2 \pi}} \int_{\frac{\ln(K) - u}{s \sqrt{\tau}}}^{\infty} e^{z s \sqrt{\tau} + u - \frac{z^2}{2}} \:dz - \frac{K}{\sqrt{2 \pi}} \int_{\frac{\ln(K) - u}{s \sqrt{\tau}}}^{\infty} e^{-\frac{z^2}{2}} \:d z \\
&= \frac{1}{\sqrt{2 \pi}} \int_{\frac{\ln(K) - u}{s \sqrt{\tau}}}^{\infty} e^{- \frac{-(z - s \sqrt{\tau})^2}{2} + u + \frac{s^2 \tau}{2}} \:d z - K \Phi \left(- \frac{\ln(K) - u}{s \sqrt{\tau}} \right) \\
&= e^{u + \frac{s^2 \tau}{2}} \frac{1}{\sqrt{2 \pi}} \int_{\frac{\ln(K) - u}{s \sqrt{\tau}}}^{\infty}  e^{- \frac{-(z - s \sqrt{\tau})^2}{2}} \: dz - K \Phi \left(- \frac{\ln(K) - u}{s \sqrt{\tau}} \right) \\
&= e^{u + \frac{s^2 \tau}{2}} \Phi \left( \frac{-\ln(K) - u}{s \sqrt{\tau}} + s \sqrt{\tau} \right) - K \Phi \left(- \frac{\ln(K) - u}{s \sqrt{\tau}} \right)
\end{split}
\end{equation}

Expressing everything once more in terms of $y(x, \tau)$, this reduces to

\begin{equation}
y(x, \tau) = e^{r \tau} x(t) \Phi(\delta + s \sqrt{\tau}) - K \Phi(\delta)
\end{equation}

Where

\begin{equation}
\delta = \frac{\ln \left( \frac{x(t)}{K} \right) + \left(r - \frac{s^2}{2} \right) \tau}{s \sqrt{\tau}}
\end{equation}

And multiplying through by the discount factor gives the expression for $f(x, \tau)$.

\begin{equation}
f(x, \tau) = x(t) \Phi(\delta + s \sqrt{\tau}) -  e^{-r \tau} K \Phi(\delta)
\end{equation}

$\blacksquare$

# References {-}

<!-- ::: {#refs} -->
<!-- ::: -->

<!-- To avoid confusion it is important to keep the following differences in mind: -->
<!-- +The ROV approach developed here is squarely founded upon the notion of the European call option defined in Equation \ref{eq:basic}. The optimal delay approach, on the other hand, is conceptually more akin to a different kind of financial option known as the American call option---which allows for exercise at any time before the end of the (potentially infinite) period $T$ [Hull]---and is, moreover, conflated with notions of "quasi-option value" developed in the environmental economics literature []. -->

<!-- +The optimal delay approach implicitly or explicitly adopts all of the corporate ROV assumptions enumerated above, and is thus suited to agricultural R&D products of a corporate or near market nature, but not to AR4D. -->

<!-- +The optimal delay approach limits its focus to R&D projects with uncertain externalities---typically, transgenic R&D with uncertain environmental impact. The ROV method developed here is applicable to both transgenic and conventional breeding projects. -->

<!-- +The optimal delay approach considers value from a social planner perspective, whereas the ROV approach pursued here considers value from the donor's perspective. -->

<!-- +The optimal delay approach implies that project ROV is generally lower than NPV, whereas the ROV appraisal method developed here implies the opposite. -->
<!-- +The ROV approach pursued here implies that the project NPV threshold above which investment in the project is justified, is lower than the threshold as computed in a conventional cost-benefit analysis (CBA). The optimal delay approach, on the other hand, implies that the investment-justifying NPV threshold is higher than the conventional CBA threshold. -->

<!-- These differences are formally demonstrated in the development of the ROV method below. After the main  -->

<!-- Each stage in the series is contingent upon successful completion of the previous stage, such that investment in any single stage may be viewed as the purchase of an option on the subsequent stage. -->
<!-- Both Geske and Cassimon et al. derive their models from the Black-Scholes partial differentiation equation [@black1973valuation]. Here we present an alternative derivation and formulation of the multistage, or "$n$-fold", real option value model based on straightforward integration, which some may find more intuitive and instructive---especially if they are unfamiliar with the financial origins of Geske's model. -->
<!-- ## Real option value basics -->
<!-- <!-- ### What is real option value? -->
<!-- In the motivating context of the present work, NPV refers to the net present value of future project impacts, starting from the anticipated date of release of the new technology. That is to say, it is the present value of the expected future benefits of the finished research product, minus the expected costs of its release and distribution, and any other cost required to support the uptake and outscaling of the finished research product. It is assumed that the cost and duration of each research stage are known. -->

<!-- # ```{r Fig2, fig.show = "hold", fig.width = 5, fig.height=2, fig.align="center", fig.cap="\\label{fig:NPVbasic}Investment timeline of Late Blight Potato research.", echo = FALSE} -->

<!-- #Tvec <- c(2, 3, 0.85, 1.7, 3.4) * 4 -->
<!-- r <- 0.12 -->
<!-- Tvec <- c(2, 3, 3, 4) -->
<!-- Kvec <- c(250000, 181000, 336000, 530000) -->
<!-- t0 <- 1; tT <- 40 -->
<!-- df <- data.frame(t = seq(t0, tT, 1), Val = NA) -->
<!-- indInv <- cumsum(Tvec) -->
<!-- tRelease <- 13 -->
<!-- indImpact <- c(tRelease:tT); tImpact <- 1:length(indImpact) -->
<!-- a <- 0.15; b <- 5 * 10^5 -->
<!-- df$Val[indInv] <- -Kvec -->
<!-- df$Val[indImpact] <- b * tImpact^a -->
<!-- df$type <- "Undiscounted" -->
<!-- dfDisc <- df %>% mutate(type = "Discounted") %>% mutate(Val = Val / (1 + r)^t) -->
<!-- df <- as.data.frame(rbind(df, dfDisc)) -->
<!-- # df$Val[indInv] <- -Kvec / (1 + r)^df$t -->
<!-- # impactVec <- exp(-r * df$t[indImpact]) * b * tImpact^a -->
<!-- # df$NPV[indImpact] <- impactVec -->
<!-- # df$type <- "NPV" -->
<!-- # df2 <- df; df2$type <- "Value"; df <- as.data.frame(rbind(df, df2));rm(df2) -->

<!-- gg <- ggplot(df, aes(x = t, y = Val, fill = type)) -->
<!-- gg <- gg + geom_bar(stat = "identity", position = "dodge") -->
<!-- gg <- gg + geom_hline(yintercept = 0, color = "red") -->
<!-- gg <- gg + geom_vline(xintercept = tRelease, color = "green") -->
<!-- gg <- gg + theme_bw() -->
<!-- gg -->

<!-- # Kvec <- c(180541, 311974, 335530, 530250) -->
<!-- # CIP -->
<!-- # Kvec <- c(52000, 213000, 396000, 929000) -->
<!-- # Tvec <- c(1, 0.25, 2, 4.75) * 4 -->
<!-- #------------------------------------------------------------------------ -->
<!-- # Crude project NPV estimate loosely based on expected adoption rates, time horizons, etc. -->
<!-- # rYrly_discrete <- 0.08 #0.035 -->
<!-- # rQrly_discrete <- (1 + rYrly_discrete)^(1 / 4) - 1 -->
<!-- # Tadopt <- 20 * 4 -->
<!-- # Timpact <- 10 * 4 -->
<!-- # yrlyBen <- 1 * 10^6 # (Assuming very low adoption) -->
<!-- # x0 <- sum(yrlyBen / (1 + rQrly_discrete)^(Tn + Tadopt + 1:Timpact)) -->
<!-- # # (Override) -->
<!-- # x0 <- 1.23 * 10^6 -->
<!-- #------------------------------------------------------------------------ -->
<!-- # Create table summarizing stage costs, time durations, and descriptions -->
<!-- stage1desc <- "Basic replication and scaling up" -->
<!-- stage2desc <- "Multi-location/season testing" -->
<!-- stage3desc <- "Compilation of the regulatory dossier" -->
<!-- stage4desc <- "Deregulation" -->
<!-- launchDesc <- "Launch in 2 countries" -->
<!-- descVec <- c(stage1desc, stage2desc, stage3desc, stage4desc, launchDesc) -->

<!-- df_table <- data.frame(Stage = c(1:4, "Launch"), -->
<!--                        Kn = rev(Kvec), -->
<!--                        Duration = rev(Tvec), -->
<!--                        DurationCum = cumsum(rev(Tvec)), -->
<!--                        Description = descVec) -->

<!-- colnames(df_table)[2:4] <- c("Cost\n(USD)", "Duration\n(annual quarters)", "Cumulative\nduration") -->

<!-- #df_table <- regulartable(df_table) -->
<!-- #df_table -->
<!-- #df_table <- width(df_table, width = 0.7) -->
<!-- table_title <- "Project to research and develop Late Blight resistant potato for release as a public good in 2 developing countries." -->
<!-- table_caption <- "Stage 1-4 costs and durations based on figures reported by Schiek et al. (2016). The launch cost and duration is hypothetical." -->
<!-- ``` -->



<!-- Letting $x(\hat{t})$ stand for project NPV evaluated at time $\hat{t}$, this is often expressed in discrete form as follows. -->

<!-- \begin{equation} -->
<!-- x(\hat{t}) = \sum_{\tau = \hat{t}} \frac{E[R(T)]\bigr|_{\hat{t}} -E[C(T)]\bigr|_{\hat{t}}{(1 + r)^T} -->
<!-- \end{equation} -->

<!-- Where $E[R(T)]\bigr|_{\hat{t}}$ and is the expected benefit in time step $T$ as evaluated at time $\hat{t}$  where r is the discrete annual discount rate. In the AR4D context,...It follows, moreover, that the same challenges faced in the estimation of project NPV---such as non-market valuation of "intangible" costs and benefits (environmental and public health outcomes, for example), or the estimation of technology adoption rates, and so forth---are faced in the estimation of ROV. To avoid raising false hopes, the reader is advised up front that the many important open problems in the field of NPV estimation fall outside the scope of the present work.... The infinite upper bound can be replaced by some arbitrary limit, but if it is necessary to do so then this is a sign that the discount rate is implausibly low. Here we have the continuous version in mind...continuous discount rate r -->

<!-- \begin{equation} -->
<!-- x(\hat{t}) = \int_{\hat{t}}^{\infty} e^{-rt} t^a \: dt -->
<!-- \end{equation} -->

<!-- The precise details of how NPV is calculated are immaterial for present purposes, it could just be a guess. -->

<!-- It does not include the main research investments which are required to generate the finished product in the first place. -->



<!-- Note that ROV is partly a function of NPV. In the ROV literature, ROV is sometimes characterized as an alternative to the "NPV approach". This is misleading insofar as it suggests that ROV is an alternative to ex-ante impact assessment. On the contrary, ROV requires ex-ante impact assessment.... the formal exposition so far demonstrates that ROV is a function of NPV, and thus involves its estimation (and this becomes clearer as the formal exposition continues, below). For this reason, the conventional or default approach to project funding decisions characterized in Inequality \ref{eq:convCBA}, against which the ROV approach is distinguished, is henceforth referred to as the "conventional CBA criterion"---and not the "NPV approach". -->




<!-- In the default approach to project funding decisions, project NPV is compared against the investment required to implement the project. If project NPV is less than the investment, then the project proposal is rejected. In other words, letting $x(0)$ represent project NPV as evaluated at time $t = 0$ (the start of the project) and $I$ the required investment, -->

<!-- \begin{equation} -->
<!-- x(0) < I \:\: \rightarrow \:\: \text{reject project} -->
<!-- \label{eq:convCBA} -->
<!-- \end{equation} -->

<!-- However, oftentimes the investment $I$ can be decomposed into an upfront sunk cost $S$ required to initiate and sustain project activities, and a subsequent outlay $K$ required a considerable time later, after certain intermediate project goals have been met. The cost-benefit analysis (CBA) criterion can thus be formulated more realistically as follows. -->


<!-- Moreover, project managers and stakeholders usually have the option to cancel the subsequent outlay $K$ if critical intermediate project goals are not met. More specifically, they can choose to cancel the outlay if the project NPV evaluated at time $T$ is less than the outlay $K$. The decision criterion may thus be expressed even more realistically as follows. -->

<!-- \begin{equation} -->
<!-- e^{-rT} E[\max(x(T) - K, 0)] < S \:\: \rightarrow \:\: \text{reject project} -->
<!-- \label{eq:rovRaw} -->
<!-- \end{equation} -->

<!-- The left-hand side of this inequality is the project ROV. -->
<!-- <!-- what authors, starting with Myers [-@myers1977determinants], refer to as the "real option value"--- because it is analogous to the value of a European call option in financial markets. -->
<!-- <!-- Since the term was first coined, the real options literature has become vast. See, for example, Trigeorgis [-@trigeorgis1993real], Hayes and Garvin [-@hayes1982managing], McGrath and MacMillan [-@mcgrath2000assessing], and references for introductions to, extensions of, and variations on the subject. For a special focus on research projects as real options, see Doctor, Newton, and Pearson [-@doctor2001managing], and Newton, Paxson, and Widdicks [-@newton2004real]. K{\"o}ppl-Turyna and K{\"o}ppl [-@koppl2013real] survey the relatively scant literature on ROV approaches to agricultural investments. -->
<!-- <!-- Omitted from this survey is an exploratory assessment of the potential usefulness of an ROV approach to agricultural venture capital decisions by Wang and Tang [-@wang2010research]. IF of 0.5 so don't mention it-->
<!-- <!-- In this literature, the real option value (ROV) approach to project valuation (Inequality \ref{eq:rovRaw}) is often construed as an alternative to the "NPV approach".  -->

<!-- Inequality \ref{eq:rovRaw} describes the ROV approach for a 1-stage project. One of the main objectives of the present article is the extension of this approach to multistage projects. The first step in this task is to develop the closed form expression for 1-stage ROV. -->
<!-- <!-- mention low uptake of ROV here? -->
<!-- <!-- So, what does the present article focus on?...As mentioned in the Introduction, ...1-stage. and no focus on AR4D -->
<!-- <!-- # Method --> 

<!-- Now, by definition, the log change in $x(t)$ over any finite time interval $\tau$ is expected to be zero. -->

<!-- \begin{equation} -->
<!-- E \left[ \ln \left(\frac{x(\tilde{t})}{x(t)} \right) \right]\biggr|_t  = 0 -->
<!-- \end{equation} -->

<!-- In other words, any expected changes are already, by definition, included in the ex-ante impact assessment. This is true even if one knows there is a good chance that future assessments will differ from the present assessment as more information becomes available after key test points in the research. (The "good chance" of future assessments differing from the present assessment is captured in the volatility parameter $s$.) By Equation \ref{eq:meanLn}, then, it follows that -->
<!-- <!-- $m = r$ and $E[x(\tilde{t})]\bigr|_t = e^{r\tau} x(t)$.  Since all expected changes in project NPV are included in the ex-ante assessment of NPV, then the expected instantaneous arithmetic rate of change of project NPV is, by definition, just the discount rate $r$. -->

<!-- \begin{equation} -->
<!-- m = \frac{s^2}{2} -->
<!-- \label{eq:ar4dRate} -->
<!-- \end{equation} -->

<!-- And so, by Equation \ref{eq:ExTt}, the expected value of project NPV at the future time $\tilde{t}$, as evaluated at the present ($t$), is -->

<!-- \begin{equation} -->
<!-- E[x(\tilde{t})]\bigr|_{t} = e^{\frac{s^2}{2} \tau} x(t) -->
<!-- \end{equation} -->

<!-- And the present value of $E[x(T)]\bigr|_{t = 0}$ is just the same multiplied by the discount factor $e^{-r\tau}$. -->
<!-- The present value of t $x(t)$ discounted back to the time of evaluation is $e^{-r \tau} x(t)$ -->
<!-- Let $y(t) = e^{-r \tau} x(t)$. Then $E[y(T)]\bigr|_t = e^{-(r - s^2/2) \tau} x(t)$ -->
<!-- This may be interpreted as risk adjusted discounting. -->


<!-- ## Risk non-neutrality and the NPV growth rate in far-from-market real options contexts -->

<!-- <!-- Another major source of complexity resulting in low adoption of ROV thinking regards the confused interpretation, in real options contexts, of the financial artifact known as "risk-neutral valuation". -->
<!-- The derivation of equation \ref{eq:rov} in the Appendix via the method of straightforward integration is atypical of the ROV literature. Most authors instead cite the Black-Scholes partial differentiation equation [@black1973valuation] as the source of the ROV formula. The method of straightforward integration is followed here because it is a considerably simpler method, and is stripped of financial trappings. In financial contexts, the Black-Scholes approach is advantageous because it generates a whole class of functional forms known as the "financial derivatives", of which the European call option formula (the financial analogue to equation \ref{eq:rov}) is just one. -->

<!-- More importantly, the Black-Scholes approach reveals, as a by-product, the deep result known as the principle of risk-neutral valuation: If it is not possible to make risk-free profits above the risk-free rate of return (the "no-arbitrage" rule), then investors are risk-neutral, i.e. "investors do not increase the expected return they require from an investment in order to compensate for increased risk" [@hull9thEdition]. Mathematically, this means that $m = r$ (where $r$, in financial contexts, refers to the risk-free rate of return). -->

<!-- The principle of risk-neutral valuation rests squarely upon the no-arbitrage rule, which is enforced through the market. This is fine in the financial context. However, in real options contexts, there is no clear theoretical or empirical basis for the no-arbitrage rule. Real project NPV is not a traded good, and there is no clear mechanism that might serve as a market analogue. On the contrary, most ROV contexts, especially research contexts, may be characterized as far-from-market---or even market failures, which the underlying project is supposed to redress. As a matter of simple observation, moreover, most project donors and managers do not seem to be risk-neutral; i.e., they seem to require an increase in expected project NPV to justify funding for a project with increased risk. -->

<!-- Critics note that the ROV literature is silent and/or conflicted on this point [@borison2005real; @block2007real]; and this has surely contributed to the complexity resulting in low adoption of ROV in real world decision making. It is not uncommon for ROV studies and surveys to assume risk-neutral valuation without any justification (see, for example, Trigeorgis [-@trigeorgis1993real], Majd and Pindyck [-@majd1987time], or Kemna [-@kemna1993case]). Some studies acknowledge the invalidity of the no-arbitrage argument in ROV contexts, but instead invoke "complete markets" to justify risk-neutral valuation (see, for example, Pennings and Lint [-@pennings1997option]). However, the complete markets assumption implies that 1) project NPV can be simulated by a portfolio of traded securities, and hence project risk can be hedged away by buying and/or selling these traded securities; and 2) project managers actually engage in the buying and selling of securities necessary to achieve this hedge. One may say without controversy that neither (1) nor (2) are common features of AR4D project management landscapes. -->

<!-- Nonetheless, a very simple, straightforward reason exists for setting $m = r$ in far-from-market settings: By the very definition of NPV as the discounted value of future impacts, NPV is effectively expected to appreciate at the discount rate $r$. -->
<!-- Conversely put, an expected NPV growth rate different from $r$ implies that the program NPV is inaccurately estimated. In the AR4D context, then, setting $m = r$ is tantamount to assuming that project NPV is accurately estimated. (This is a very strong, but nonetheless de facto, assumption implicit in any NPV estimate.) -->
<!-- Mathematically, the absence of any empirical or theoretical premise for risk-neutral valuation in far-from-market real options contexts means that there is no reason to set $m$ equal to $r$. -->
<!-- ## The far-from-market Black-Scholes PDE -->
<!-- But Black and Scholes' insight can be decomposed into two consecutive insights. The first insight is that, by eliminating the random terms in equation \ref{eq:bsInsight1}, the resulting expression is deterministic. And it equates a composite evolution in terms of $\Delta f$ and $\Delta x$ on the left-hand side to a time evolution $\Delta t$ on the right-hand side. Regardless of the no-arbitrage rule, it follows trivially that -->
<!-- \begin{equation} -->
<!-- \Delta f - \frac{\partial f}{\partial x} \Delta x = \left( f - \frac{\partial f}{\partial x} x \right) \kappa \Delta t -->
<!-- \end{equation} -->
<!-- <!-- So long as -->
<!-- <!-- \begin{equation} -->
<!-- <!-- \kappa = \frac{\frac{\partial f}{\partial t} + \frac{1}{2} \frac{\partial^2 f}{\partial x^2} s^2 x^2}{f - \frac{\partial f}{\partial x} x} -->
<!-- <!-- \end{equation} -->
<!-- <!-- holds. -->
<!-- Where $\kappa$ is constant with respect to the interval $\Delta t$. -->
<!-- The second insight is about resolving the value of $\kappa$. In financial markets, the no-arbitrage rule requires that $\kappa = r$. In the absence of the no-arbitrage rule, however, the $r$ in the Black-Scholes PDE must be replaced by $\kappa$. Solving this non-market version of the Black-Scholes PDE at the boundary condition $f(T) = \max(x(T) - K, 0)$ and comparing it to equation \ref{eq:EmaxTK}, which is obtained through straightforward integration, reveals that $\kappa$ must default to $m$. In the absence of the no-arbitrage rule, or any other overriding mechanism, then, the Black-Scholes PDE must default to -->
<!-- \begin{equation} -->
<!-- \left( f - \frac{\partial f}{\partial x} x \right) m = \frac{\partial f}{\partial t} + \frac{1}{2} \frac{\partial^2 f}{\partial x^2} s^2 x^2 -->
<!-- \label{eq:ffmBSpde} -->
<!-- \end{equation} -->
<!-- This is the far-from-market Black-Scholes PDE. -->
<!-- the now deterministic equation means that the evolution in terms of $\Delta f$ and $\Delta x$ on the left-hand side of equation \ref{eq:bsInsight1} may be rewritten in terms of a time evolution $\Delta t$. That is, we have an equation of the following form. -->
<!-- the evolution of the left-hand side must be constant over the interval $\Delta t$. This means -->
<!-- \begin{equation} -->
<!-- a \Delta f - b \Delta x = c \Delta t -->
<!-- \end{equation} -->
<!-- [Where $a$ ...] -->
<!-- Regardless of the no-arbitrage argument, it follows trivially that -->
<!-- \begin{equation} -->
<!-- \begin{split} -->
<!-- a f \kappa \Delta t - b x \kappa \Delta t  &= c \Delta t \\ -->
<!-- (a f - b x) \kappa \Delta t  &= c \Delta t -->
<!-- \end{split} -->
<!-- \end{equation} -->
<!-- And hence, trivially, -->
<!-- \begin{equation} -->
<!-- \begin{split} -->
<!-- a f \kappa \Delta t - b x \kappa \Delta t  &= c \Delta t \\ -->
<!-- (a f - b x) \kappa \Delta t  &= c \Delta t -->
<!-- \end{split} -->
<!-- \end{equation} -->



<!-- [@mitchell1988managing] -->
<!-- AR4D projects usually unfold in a series of stages, the precise structure of which can vary considerably from one project to another. For the purpose of exposition, the focus here is on transgenic projects. Transgenic projects tend to follow the generic four stage process defined below, regardless of crop, technology, and institution. For completeness, a pre-project and post-project stage are also defined, although these typically fall outside of the donor's funding horizon. -->
<!-- <!--The staging of conventional breeding projects must be assessed on a project by project basis, as this varies considerably across crops, technology, and research institution. The emergence of marker assisted breeding further complicates any effort to impose a generic structure on such projects. -->

<!-- * Pre-project: A discovery or "blue skies research" stage, during which new technologies are "discovered" through a careful exploration and extension of existing research---in which serendipity plays a key role---in conjunction with a careful prioritization of research demand. The output of this stage is a new technology proof-of-concept, usually in the form of a novel genotype expressing a set of desired traits, together with a set of recommended farm management practices. -->

<!-- 1) A basic replication or scaling up stage, whereby a technology proof-of-concept generated in the discovery phase is reproduced in greenhouse and/or confined field trials, in conjunction with a more refined assessment and prioritization of research demand, especially target populations and ecologies, and the relevant socioeconomic enabling environments (particularly seed systems, government policies, institutions, and markets). -->

<!-- 2) A multi-location, multi-season testing stage, whereby successful specimens generated in the preceding stage are taken for further confined field trials under distinct agronomic conditions over multiple cropping seasons. -->

<!-- 3) A regulatory dossier stage, wherein detailed agronomic, environmental, and toxicological data, mostly generated during the preceding stages, is compiled into dossier(s) for submission to the National Competent Authorities (NCAs) in the countries targeted for release of the new technology. -->

<!-- 4) A deregulation stage, during which the regulatory dossier(s) generated during the previous stage is/are submitted to the NCA(s), which may request further clarification and testing of certain aspects of the proposed technology. -->

<!-- * Post-project: A release and uptake stage, during which the new technology is made available for distribution in the target populations and environments. This stage depends critically on the quality of the socioeconomic enabling environment in the target countries, in conjunction with stewardship from the research institution to ensure correct provision and application of the improved germplasm at the farm level. The holistic "Agricultural Innovation System" view of AR4D considers this stage to be an integral part of AR4D projects [@klerkx2010adaptive]. -->

<!-- The duration of project stages varies depending on technology, crop, and research institution; but, as a general rule, transgenic projects (stages 1-4) tend to last 9-11 years. -->
<!-- development of the plant, and the trait assessment, are all known. Thus, none of the costs  -->
<!-- associated with research and development of the gene constructs or of testing them in  -->
<!-- transgenic  events  are  included  (cloning  and  testing  different  R  genes,  testing  the  -->
<!-- durability  of  LB  resistance,  evaluating  different  strategies  for  deployment,  socio- -->
<!-- economic  targeting  studies,  communicating  the  results  to  stakeholders,  and  building  -->
<!-- biotechnology  and  biosafety  facilities).  Also  excluded  are  the  costs  of  building  the  -->
<!-- capacity  of  partners,  scientific  publications,  and  participation  in  scientific  conferences  -->
<!-- apart from any such activities strictly needed for the LBr product development. The costs  -->
<!-- of  obtaining  freedom-to-operate  and/or  intellectual  property  rights  over  the  relevant  -->
<!-- technology are also excluded. It is assumed that these issues and costs have been dealt  -->
<!-- with  at  the  previous  stage  of  the  proof-of-concept  and  has  defined  which  technology  -->
<!-- element will be eventually used for product development. -->

<!-- # Acknowledgments {-} -->

<!-- Funding: The Foresight and Metrics Initiative -->


<!-- # Figures {-} -->

<!-- # ```{r, fig.show = "hold", echo=FALSE} -->

<!-- # library(numbers) -->
<!-- # library(pracma) -->
<!-- # library(gridExtra) -->
<!-- # coloredNoise <- function(n, a, normalize = T, graph = F) -->
<!-- # { -->
<!-- # # 13 / 02 / 18 -->
<!-- # # Description: 1/f^a noise generator with free parameter "a." -->
<!-- # # Outputs a 1/f^a noise R-by-C matrix. -->
<!-- # # By adjusting parameter "a" can generate pink, red, -->
<!-- # # white, blue, violet noise, or any gradation in between. -->
<!-- # # As "a" is less, the signal is more autocorrelated, less random, -->
<!-- # # degenerating ultimately into a sine curve. As "a" is greater, -->
<!-- # # the signal is more random, approaching white noise and beyond -->
<!-- # # (approaching any signal with fractal dimension of 2) -->
<!-- # # NOTE: "a" is closely related to the signal's fractal dimension. -->
<!-- # # "a" and fract. dim. are related by the logistic function. -->
<!-- # # Envisioned Use: Signal generation to immitate  -->
<!-- # # stock charts for example. Or as a "random number -->
<!-- # # generator" where it is possible to adjust the balance -->
<!-- # # between randomness and autocorrelation (by adjusting "a"). -->
<!-- # # In other words the user has here a random number generator  -->
<!-- # # where the fractal dimension of the number selection  -->
<!-- # # can be adjusted. -->
<!-- # # Source: This function is adapted from Hristo Zhivomirov's Pink, -->
<!-- # # Red, Violet, and Blue Noise Generation functions (written in Matlab) -->
<!-- # # https://la.mathworks.com/matlabcentral/fileexchange/42919-pink--red--blue-and-violet-noise-generation-with-matlab-implementation?focused=7825006&tab=function -->
<!-- # # All those functions are combined in this single function -->
<!-- # # (as well as the gradations in bewtween). -->
<!-- # #--------------------------- -->
<!-- #   # Input: -->
<!-- #   # R - number of rows to be returned -->
<!-- # # C - number of samples to be returned in each row vector -->
<!-- # # a - parameter relating power to frequency.  I.e. the  -->
<!-- # # power spectral density is proportional -->
<!-- # # to the frequency f by a factor f^(-2*a). In other words, -->
<!-- # # the amplitudes are proportional to f^(-a). -->
<!-- # # normalize - Normalizes output y if ==1.  Note normalization -->
<!-- # # changes the standard deviation of the output. -->
<!-- # # Output: -->
<!-- #   # y - row vector of noise samples -->
<!-- # #----------------------------- -->
<!-- #   # Each color of noise is generated by adjusting the  -->
<!-- # # parameter "a" as follows: -->
<!-- #   # a=-2    red or brown(ian) noise (fractal dim.~1.5 - like stock charts) -->
<!-- #   # a=-1  pink noise (fractal dim.~1.85) -->
<!-- #   # a=0     white noise (output equivalent to y=randn(1,N) IF normalize==0) -->
<!-- #   # a=1   blue noise (fractal dim.~2) -->
<!-- #   # a=2     violet noise (fractal dim.~2) -->
<!-- #    -->
<!-- #    -->
<!-- #   # More info on each noise color follows: -->
<!-- #     # (taken from Zhivomirov's notes) -->
<!-- #        #------------------------------------ -->
<!-- #        # red noise: Aka brown noise. In terms of power at a  -->
<!-- #        # constant bandwidth, red noise falls off at 6 dB per  -->
<!-- #        # octave. The power spectral density is inversely  -->
<!-- #        # proportional to the frequency by factor 1/(f^2),  -->
<!-- #        # i.e. the amplitudes are inversely proportional to 1/f. -->
<!-- #         -->
<!-- #        # pink noise: Aka "1/f noise." The pink noise setting  -->
<!-- #        # generates a sequence of pink (flicker) noise samples.  -->
<!-- #        # Pink noise has equal energy in all octaves (or similar  -->
<!-- #        # log bundles) of frequency. In terms of power at a  -->
<!-- #        # constant bandwidth, pink noise falls off at 3 dB per  -->
<!-- #        # octave. The power spectral density is inversely  -->
<!-- #        # proportional to the frequency by factor 1/f, -->
<!-- #        # i.e. the amplitudes are inversely proportional to 1/sqrt(f). -->
<!-- #         -->
<!-- #        # blue noise: In terms of power at a constant bandwidth,  -->
<!-- #        # blue noise increase in at 3 dB per octave. The power  -->
<!-- #        # spectral density is proportional to the frequency by  -->
<!-- #        # factor f, i.e. the amplitudes are proportional to sqrt(f). -->
<!-- #         -->
<!-- #        # violet noise: Aka purple noise. In terms of power at a  -->
<!-- #        # constant bandwidth, violet noise increase in at 6 dB per -->
<!-- #        # octave. The power spectral density is proportional to the  -->
<!-- #        # frequency by factor f^2, i.e. the amplitudes are  -->
<!-- #        # proportional to f. -->
<!-- #        #================================================ -->
<!-- #        if(rem(n, 2)){n <- n + 1} -->
<!-- #        # generate white noise with sigma = 1, mu = 0 -->
<!-- #        x <- rnorm(n) -->
<!-- #        # FFT -->
<!-- #        X <- fft(x) -->
<!-- #        # prepare a vector for 1/f multiplication -->
<!-- #        NumUniquePts <- n / 2 + 1 -->
<!-- #        ind_left <- 1:NumUniquePts -->
<!-- #        # multiply the left half of the spectrum so the power spectral density -->
<!-- #        # is inversely proportional to the frequency by factor f^a, i.e. the -->
<!-- #        # amplitudes are inversely proportional to f^(a/2) -->
<!-- #        X[ind_left] <- X[ind_left] * ind_left^(a / 2) -->
<!-- #        # prepare a right half of the spectrum - a copy of the left one, -->
<!-- #        # except the DC component and Nyquist frequency - they are unique -->
<!-- #        ind_right <- seq(n / 2, 2, -1) -->
<!-- #        X[(NumUniquePts + 1):n] <- Re(X[ind_right]) - 1i * Im(X[ind_right]); -->
<!-- #        # IFFT -->
<!-- #        y <- ifft(X) -->
<!-- #        # prepare output vector y -->
<!-- #        y <- Re(y[1:n]) -->
<!-- #        # normalise? -->
<!-- #          if(normalize == T){ -->
<!-- #            y <- y / max(abs(y)) -->
<!-- #          } -->
<!-- #        if(graph == T){ -->
<!-- #          xplot <- 1:n -->
<!-- #          dfplot <- data.frame(output = y, sequence = xplot) -->
<!-- #          gg1 <- ggplot(dfplot, aes(x = output)) + geom_density() -->
<!-- #          gg2 <- ggplot(dfplot, aes(x = sequence, y = output)) + geom_line() -->
<!-- #          grid.arrange(gg1, gg2, ncol = 1) -->
<!-- #        } -->
<!-- #        return(y) -->
<!-- # } -->
<!-- #  -->
<!-- # thisT <- 250 -->
<!-- # randVec <- coloredNoise(n = thisT, a = -2, normalize = F, graph = T) -->
<!-- #  -->
<!-- # ts <- cumsum(randVec) -->
<!-- # df_plot <- data.frame(randVec, dif = c(NA, diff(randVec)), ts, Time = c(1:thisT)) %>% -->
<!-- #   gather(Type, Val, randVec:ts) -->
<!-- # #colnames(df_plot)[1:2] <- c("Time", "Project NPV") -->
<!-- # gg <- ggplot(df_plot, aes(x = Time, y = Val)) -->
<!-- # gg <- gg + geom_line() -->
<!-- # gg <- gg + facet_wrap(~Type, scales = "free_y", ncol = 1) -->
<!-- # gg <- gg + theme_bw() -->
<!-- # # gg <- gg + theme(axis.text = element_blank(), -->
<!-- # #                  axis.title = element_text(size = axisTitle_size)) -->
<!-- # gg_gbm <- gg -->
<!-- # gg -->
<!-- #  -->
<!-- #  -->
<!-- # ``` -->


<!-- In place of risk-neutral valuation, then, [we show that risk-adjusted discounting follows as a corollary]. After deriving the ROV model for single stage AR4D projects, the extension to multistage projects -->
<!-- turns out to be remarkably simple compared to the aforementioned efforts of Cassimon et al. [-@cassimon2004valuation]. -->
<!-- The article concludes with a discussion of two minor, but useful modifications. First we show how the model can be extended to include "abandonment value", i.e., the value often generated by AR4D projects in the form of human and physical capital upgrades, regardless of the success or failure of the main research activities. And we demonstrate how the model might be modified to account for the scaling relation that typically exists between AR4D project investment and impact. -->
<!-- But first, all of this is prefaced by a studious avoidance of the theoretical underpinnings of corporate ROV methods, which follows immediately below in the literature review. -->
<!-- Since much of the intended audience may be unfamiliar with ROV, these main results are prefaced by an incremental mathematical explanation of the basic concept and intuition. This preface begins with a basic clarification of what is meant by "project NPV", plus an introduction to (and defense of) geometric Brownian movement (gBm) as a model of the stochastic evolution of project NPV. The closed form ROV equation for 1-stage projects known as the Black-Scholes model is then derived solely on the assumption that project NPV follows a gBm, without recourse to any of the usual assumptions applied in financial and corporate contexts. This is followed by brief remarks on building intuition. This is followed by the elementary adjustments to account for abandonment value -->
<!-- -This is followed by an explanation of the implications in B-S PDE land, completing the replacement of financial/corporate assumptions with suitable AR4D assumptions. How it does not imply risk-neutrality etc. (All of the assumptions listed above should receive clear treatment) This is where any remarks on Dixit and Pindyck would go. Possibly solve the Dixit-Pindyck PDE under the new AR4D boundary conditions? -->
<!-- -Here the adjustment to accommodate the impact scaling relation between the outscaling investment and project NPV; including showing how to solve for the ROV-maximizing outscaling investment. -->
<!-- -Finally, we apply the derived model to appraise a real 4-stage AR4D potato project. -->
<!-- Where does discussion of B-S PDE and Dixit & Pindyck etc. go? -->
<!-- [...the complexity of stochastic processes encountered in financial and corporate contexts leads them down the dark path of numerical methods at great methodological cost...Pennings & Lint cPp... Here argue that gBm is a good enough and great methodoligcal benefits, periods of no change (cPp can be modeled arbitrarily closely as periods of negligible change (gBm). -->
<!-- ...there is a strong consensus against gBm at great methodological cost... corp people be dissin the gBm bitter pill -- this will have to be tackled first, leads naturally then to derivation of (1-stage) ROV formula by straightforward integration based only on assumption of lognormal changes.] -->
<!-- ...We present an unoriginal, but little discussed, derivation of the option value equation identical to the one derived by Black and Scholes, but which does not depend upon the Black-Scholes PDE, nor any of the underlying assumptions that are problematic in the AR4D context. And we demonstrate that this independently derived equation is nonetheless consistent with [a certain interpretation of] the Black-Scholes PDE by presenting an alternative derivation of the Black-Scholes PDE that does not depend upon the no-arbitrage rule, nor complete markets, and does not imply risk-neutral valuation, and is thus consistent with the AR4D context. -->
<!-- [as  Moreover, since price information is automatically updated on a second-by-second basis, a project NPV time series is generated by which to estimate project risk (i.e. the standard deviation of the project NPV fractional change per time step), and to otherwise empirically inspect the stochastic character of the time evolution of project NPV.] -->
<!-- If it is not possible to make risk-free profits above the risk-free rate of return (the “no-arbitrage” rule), then investors are risk-neutral, i.e. “investors do not increase the expected return -->
<!-- they require from an investment in order to compensate for increased risk” (Hull, 2015) -->
<!-- Since the replicating portfolios argument effectively specifies project NPV as a linear function of prices, then project NPV may be easily calculated at any time from publicly available price information. Moreover, since price information is automatically updated on a second-by-second basis, a project NPV time series is generated by which to estimate project risk (i.e. the standard deviation of the project NPV fractional change per time step), and to otherwise empirically inspect the stochastic character of the time evolution of project NPV. -->
<!-- as it would merely indicate the value of the project objective (of which everyone is already convinced), and not of the particular technology, expertise, strategy, and enabling environment that distinguish the project from other projects pursuing similar objectives. -->
<!-- AR4D donors are already convinced of the value of the SDGs without waiting to see what the "markets say about it"; and, tragically, there is little or no risk of the "bottom falling out" of such markets, at least not in our lifetimes. -->
<!-- This bears emphasis, as it underscores a fundamental difference between the AR4D and corporate ROV contexts: Generally speaking, in corporate ROV contexts, project NPV hinges primarily upon the market value of the project objective (e.g., a natural resource), which may fluctuate considerably over the life of the project; and only secondarily upon technical progress toward the proposed project objective. In the AR4D context, it is the other way around: project NPV hinges critically upon technical progress towards the project objective (e.g., a disease resistant cultivar), which may fluctuate considerably over the life of the project, while the value of the objective itself is effectively taken for granted. In the former case, price risk is the key source of uncertainty; in the latter case, it is technical risk, i.e. the risk that the proposed technology will not function or scale as expected, due either to technical difficulties encountered in the research itself, or to unforeseen adversity in the enabling environment (e.g., government policy shifts, deregulation issues, etc.). -->
<!-- In other words, the main source of AR4D project risk---i.e. of significant, unforeseeable fluctuations in project NPV---is not variability in the value of the end objective, but rather the technical risk associated with the research itself, and/or the research enabling environment (e.g., government policy shifts, deregulation issues, etc.). -->
<!-- Unlike corporate project NPV, , AR4D project NPV is primarily a function of the technical feasibility of the research and/or the political and institutional enabling environment. -->
<!-- Here we present an alternative derivation of the Black-Scholes PDE based only the assumption of normally distributed log returns, and that the present value of future impacts appreciates at the discount rate. -->
<!-- which makes perfect sense to financial analysts, but is problematic in the AR4D setting. Risk-neutral valuation means that, if it is not possible to make risk-free profits above the risk-free rate of return (the "no-arbitrage" rule), then investors are risk-neutral, -->
<!-- Such assessments typically require a considerable investment of time, effort, and expertise, making frequent updates of project NPV unfeasible. As a result, we are left without a project NPV time series by which to estimate project risk or otherwise empirically inspect the stochastic character of project NPV. -->
<!-- Finally, and most importantly from a theoretical standpoint, the replicating portfolios argument means that project NPV may be treated as a traded good in an efficient market. This figures critically in the formal derivation of the financial option formula one wishes to adapt to real options (i.e. the Black-Scholes partial differential equation) via an argument known as the "no-arbitrage rule" [@hull9thEdition]. It also implies a  -->
<!-- Mathematically, this means that $m = r$ (where $r$, in financial contexts, refers to the risk-free rate of return). -->
<!-- @mathews2007practical -->
<!-- In the AR4D context, project NPV must be evaluated the "hard way", by ex-ante impact assessment. These assessments typically require a considerable investment of time, effort, and expertise, making frequent updates of project NPV unfeasible. As a result, we are left without a project NPV time series by which to estimate project risk or otherwise empirically inspect the stochastic character of project NPV. We must therefore devise some other way of estimating project risk...../ In the AR4D context, neither  NPV is not a traded good, nor may complete markets be invoked, then there is no theoretical premise for the B-S PDE. -->
<!-- Pennings and Lint [-@pennings1997option], for example, cite the case of the Merck pharmaceutical company, which has estimated R&D project risk based on the company's stock price volatility. -->
<!-- relatively recent critique and synthesis of real options theory by one of its founders [@trigeorgis2017real] -->
<!-- surveys repeatedly indicate low uptake of rov [@ryan2002capital; @block2007real; @horn2015use] -->
<!-- Triantis gives the best survey of methodological critiques or rov [@triantis2005realizing] -->
<!-- a survey of more conceptual or high level critiques of rov [@driouchi2012real] -->
<!-- good description of rov state of the art by key proponent [@schwartz2013real] -->
<!-- numerical models..[@triantis2005realizing]. the response to disappointing uptake and ctirique is thus to double down on trigergois' original "bitter pill" critique...[trigeorgis] (which is odd because this then results in an even blacker black box)... [At any rate] This entire discussion occurs in the context of corporate real options. The replicating portfolio arguments are already strained there at the fringes of the market. In the AR4D context they are broken. AR4D unfolds precisely in the midst of a market failure. Not profits but net benefits in terms of smallholder incomes, environmental services, nutritional and public health outcomes. [no way this can be represented in terms of market prices] -->
<!-- Rather than build upon the existing literature, then, we must break new ground. -->
<!-- ROV has been applied and discussed in private sector research contexts [@mitchell1990alternative; @pennings1997option; @cassimon2004valuation; @doctor2001managing; @newton2004real; @mathews2007practical]; and much of this work is relevant to the AR4D context---although there are some important differences which must be kept in mind. Regardless, rather than build upon the existing work in this direction, we propose an alternative -->
<!-- The project's net present value (NPV) is analogous to the price of the underlying security in the financial context, while the cost of the subsequent stage is analogous to the exercise price. (The cost of the subsequent stage must be known up front for the analogy to hold.)  -->
<!-- [Incidentally, this is an additional benefit of ROV---it explicitly takes account of risk.] -->
<!-- Pennings and Lint [-@pennings1997option], in this journal, evaluated the ROV of a project to develop a new consumer electronics product at a private tech firm. The exercise price, in this case, was the cost of building manufacturing plants required to produce the prospective product at scale plus marketing costs. -->
<!-- can 1) provide meaningful, risk-adjusted project appraisals, 2) secure long term commitments from donors, while at the same time 3) giving donors the flexibility they require to maintain solvent fiscal outlooks. -->

<!-- as in Equation \ref{eq:basic}. -->
<!-- [@trigeorgis2017real] -->
<!-- -@trigeorgis1993real; and McGrath [-@mcgrath2000assessing] -->
<!-- The methodological details of real option valuation can vary considerably from one applied context to another. But, generally speaking, -->

<!-- From the outset it is important to distinguish the notion of ROV pursued here (Equation \ref{eq:basic}) and originally developed by Myers [@myers1977determinants], from another approach---also calling itself a "real options approach"---already followed in numerous agricultural R&D appraisal studies [@scatasta2006irreversibility; @demont2004biodiversity; @wesseler2007maximum; @demont2005irreversible]. The purpose of the ROV approach developed here is to appraise, from the donor's perspective, AR4D projects with known time horizons in a way that prices in option value. The other "real option approach" currently implemented in the agricultural R&D literature is, more accurately, an "optimal delay approach", in the sense that it is primarily concerned with determining the optimal delay, from a social planner's perspective, of the release and outscaling of a finished agricultural R&D product with uncertain environmental impact. -->
<!-- As such, it is not primarily concerned with the valuation of the R&D product itself, which is what we pursue here. -->
<!-- , Newton, and Pearson   , Paxson, and Widdicks -->


<!-- a strong consensus exists in the corporate ROV literature, adopted from the financial literature, that the log returns of a project NPV time series are not normally distributed []. In the more technical speech that we will delve into below, they eschew geometric Brownian motion (gBm) as a naive model of project NPV, preferring instead more complicated stochastic jump models, such as a compound Poisson process (CPp), that can more realistically reflect abrupt jumps in the time evolution of NPV []. There are good reasons for applying stochastic jump models in the financial and (some) corporate settings, but it comes at a high methodological cost, as it adds a thick layer of complexity onto an already complex modeling workflow, and requires numerical methods for ROV solution.   ...bitter pill. The assumption of gBm greatly simplifies...a questionable gain in realism at great methodological cost. -->

<!-- Secondly, the mathematical option value formula we wish to adapt to real options settings (i.e., the Black-Scholes equation) is fundamentally derived from the assumption that the underlying good is traded in an efficient market---known in finance as the "no-arbitrage rule" [@hull9thEdition]. More problematically still, the no-arbitrage rule then leads to a corollary known as "risk-neutral valuation", which implies that the donor is willing to take on any level of risk for a given expected reward [@hull9thEdition]. Again, in some private sector R&D settings, it may be that project NPV is highly correlated with company price, and/or a linear combination of other relevant prices, effectively validating such assumptions. In the AR4D context, however, it can be said without controversy that neither the no-arbitrage rule nor risk-neutral valuation are valid assumptions. -->

<!-- and this has surely contributed to the complexity resulting in low adoption of ROV in real world decision making. It is not uncommon for ROV studies and surveys to assume risk-neutral valuation without any justification (see, for example, Trigeorgis [-@trigeorgis1993real], Majd and Pindyck [-@majd1987time], or Kemna [-@kemna1993case]). Some studies acknowledge the invalidity of the no-arbitrage argument in ROV contexts, but instead invoke "complete markets" to justify risk-neutral valuation (see, for example, Pennings and Lint [-@pennings1997option]). However, the complete markets assumption implies that 1) project NPV can be simulated by a portfolio of traded securities, and hence project risk can be hedged away by buying and/or selling these traded securities; and 2) project managers actually engage in the buying and selling of securities necessary to achieve this hedge. One may say without controversy that neither (1) nor (2) are common features of AR4D project management landscapes. -->

<!-- Agricultural research for development (AR4D) scientists are under ever increasing pressure from donors to put a defensible monetary value on their proposed projects. However,  -->
<!-- , such that project net present value is likely to fluctuate considerably over the life of the project -->
<!-- They are also (d) far-from-market, or even unfold in the midst of market failures, such that project value and/or changes in value may not be deduced or projected based on movements in the prices of commodities or financial securities. -->
<!-- Properties (a)-(d) make it extremely difficult to valuate AR4D projects in a way that is meaningfully different from a wild, if educated, guess. With good reason, then, AR4D researchers generally resent the mounting pressure to quantify promising, but distant and uncertain, impacts [@leeuwis2018reforming]. The resentment is evident across other scientific disciplines as well [@Petsko2011; @Moriarty2008]. AR4D donors, meanwhile, have grown disillusioned with the crudeness of research project appraisals---even to the point of disbelief, and a commensurate global decline in AR4D funding levels [@hurley2016returns; @hurley2014re; @pardey2018shifting]. The frustration of scientists and donors alike is compounded by increasingly austere fiscal restrictions on donors' ability to commit to the long time horizons of agricultural research. The upshot is an atmosphere of "ever growing distrust" between donors and research communities [@leeuwis2018reforming]. -->


<!-- In pursuit of realism, then, one not only sacrifices methodological expedience and transparency, but also faces a number of sampling issues that undermine the supposed gain in realism. And for what? After the cPp dust settles, P&L find that their numerical ROV model differs from the more expedient closed form Black-Scholes option forumla by a mere 2% []. -->

<!-- Deductive reasoning. For purposes of project appraisal, time explicit analysis not necessary, not trying to predict NPV in the next period. By definition, we always expect NPV to be the same in the next period as it is in the present period. it is the size distribution of changes in NPV that matter, not the exact order in which changes to NPV occur. lots of small changes interspersed by a few large changes -->

<!-- In any methodological decision, there is usually a tradeoff between realism and expedience. The job of the modeler is thus not merely to maximize realism, but to strike the optimal balance between realism and expedience under the particular time and resource constraints of the modeling exercise at hand, and in a way that is clearly relevant to the particular objectives of the exercise. This is especially true in real world decision making contexts, where constraints are considerably more severe than in academic contexts. And the patience of project donors and managers for arcane technical explanations must be counted among the resources that are in short supply. -->

<!-- Before making costly methodological decisions in the name of realism, then, one must carefully consider 1) to what extent an "increase in realism" is even meaningful, i.e., to what extent it is possible to empirically observe and quantify the reality one aspires to model; 2) whether the proposed increase in realism is actually relevant to the objectives of the modeling exercise, or whether it is just realism for realism's sake; and 3) whether there is a simpler, less costly way to achieve the same increment in realism, or the same modeling objectives which the increment in realism is supposed to serve. -->
<!-- [One must also be careful of merely replacing one unrealistic artifact with another.]  -->
<!-- In the financial context, the reality one aspires to model---i.e. some stochastic financial process, usually a price series---is quantitatively well defined in the form of historical time series that can be easily downloaded, measured, analyzed, etc. In the far-from-market AR4D context, by contrast, analogous historical time series of project NPV generally do not exist. The reality one aspires to model must be perceived indirectly, based primarily on rational assumptions and logic, as I have just done above. So, in far-from-market real options contexts, it is not even clear what one gets in return for sacrificing expedience. -->
<!-- Then there is the question of the relevance of the increase in realism. In the financial context, the relevance of a realistic model of the time evolution of financial securities is clear: it can make the difference between profit and loss. In far-from-market real options contexts, on the other hand, there is no real need for a good predictor of exactly when or in what order specific changes in project NPV occur. The need, rather, is to simulate a time series with a certain size distribution of changes in value. If the model can do this accurately, then it is a good model, regardless of what it looks like in the time domain. -->
<!-- ### In defense of the gBm model of project NPV -->
<!-- [Rejection of the gBm model in ROV contexts is partly inherited from the financial context, where gBm is generally viewed as a naive model of price movements. fat tails--debunked by Tankov, jumps--as discussed above, an artifact of the dam-break model, not a concern in ROV contexts, plus jumps can be closely approximated by gBm. en fin, gBm is much more versatile than it is generally given credit for.] -->
<!-- Like Pennings and Lint, many real options authors reject the gBm model, preferring instead to select a model which they perceive to more accurately approximate the real time evolution of project NPV. But this comes at a substantial loss of expedience, as the closed form expression in equation \ref{eq:rov} must be replaced by considerably less tractable and less intelligible expressions, up to and including numerical methods. Trigeorgis once characterized numerical methods as an unavoidable "bitter pill" that every serious ROV practitioner must come to grips with [-@trigeorgis1993real]. -->

<!-- Given all the research and non-research factors affecting project NPV, it is highly unlikely that there is not at least a small, if negligible, perturbation in NPV in every time step, in which case the gBm model is the more realistic choice (when modeling project NPV evolution as it happens, as opposed to the information dam-break approach). -->
<!-- The question is not when changes in NPV occur, but rather how often do substantial changes to NPV occur? In more technical terms, what is the size distribution of changes? In order to answer this question, it is more instructive to look at the signal's periodogram, not its evolution in the time domain. This can be examined by looking at a periodogram. Model 1 can effectively approximate model 2 to an arbitrary degree of precision by tuning the uncertainty parameter $s$ (Figure \ref)..... A few substantial changes followed by relatively long periods of little change. [The Poisson jump model represents a process in which there are a few substantial changes interspersed among periods of no changes at all. While the gbm model cannot replicate periods of no change exactly, it can approximate such periods arbitrarily closely through adjustments to the volatility parameter.... And recall that it is highly unlikely that there are no changes in project value in any given time step, but rather that there may be long periods of very small changes punctuated by brief periods of large changes. This is perhaps best illustrated by looking at periodograms (Figure ...).] -->
<!-- Geometric Brownian motion is a much more versatile model than portrayed in the literature.... "bitter pill" [trigergis]. criticism fat tails etc. starting with Mandelbrot []. but this has led to misconception... [Tankov]. The fact is that gbm remains a highly versatile model capable of representing a wide variety of stochastic processes by adjustments to the volatility parameters. The key question that Pennings and Lint address with their jump model may be formulated as follows: what is the size distribution of changes in project value?  [P&L Poisson jump model output differed from the lognormal assumption output by just x% [P&L].] -->
<!-- [For the purposes of evaluating real option value, the question is not so much when exactly the changes occur, but rather their size distribution. In other words not the time domain but the frequency domain that is important.] -->
<!-- as compared to the default NPV approach -->
<!-- ## Low adoption of real options thinking due to complexity -->
<!-- Despite a flood of academic interest in ROV following Myers' initial insight, adoption of the real options approach by real world decision makers remains low [@horn2015use; @triantis2005realizing; @driouchi2012real]. ROV critics and proponents alike attribute this tepid reception to the formal complexity of evaluating and explaining ROV as compared to the default NPV approach [@triantis2005realizing]. -->
<!-- Much of this complexity can be traced back to two sources. Firstly, there is the frequent and puzzling assumption of risk neutral valuation in far-from-market real options contexts, just mentioned above. Secondly, many authors reject the key assumption that project NPV evolution may be modeled as a gBm, preferring instead to evaluate equation \ref{eq:rovRaw} by numerical methods that are considerably less tractable, transparent, and instructive than equation \ref{eq:rov}. Trigeorgis, for example, calls numerical methods a "bitter pill" that every serious ROV practitioner must come to grips with [@trigeorgis1993real]. -->
<!-- Before deriving the $n$-fold ROV model, it is first necessary to redress these two sources of confusion in detail. It seems safe to say, in hindsight, that energetic ROV proponents like Trigeorgis may have overestimated the appetite for bitterness outside of academic audiences. After this introductory section, I preface the derivation of the $n$-fold ROV model with a defense of the gBm model of project NPV, followed by a repudiation of risk neutral valuation in far-from-market real options contexts. -->
<!--   present arguments in defense of gBm as a model of far-from-market project NPV. In particular, I note that the a as a much more versatile model than it is given credit for. -->
<!-- Secondly, there is confusion regarding the interpretation, in real options contexts, of the financial artifact known as "risk-neutral valuation". -->
<!-- (see, for example, Hayes and Garvin [@hayes1982managing], McGrath and MacMillan [@mcgrath2000assessing], Doctor, Newton, and Pearson [@doctor2001managing], and Newton, Paxson, and Widdicks [@newton2004real]), -->
<!-- [However, the question of where ... must be assessed on a case by case basis. is a matter of preference. In academic contexts, there is a premium on rigor and realism. Most real options settings, on the other hand, time, resources, patience, and attention-span are in relatively short supply ... there is a premium on transparency, expediency. Pennings and Lint use equation \ref{eq:rov} and find that the numerical method output differs by just x%. That is a lot of extra work for a negligible difference. Whether or not changes occur in every time step is a matter of judicious choice of time step. In most real options settings, changes might not occur every day or every week or even every month, but probably do occur at least once every quarter. Moreover, such meticulous realism quickly lands the practitioner in other problems. In most real options settings, the research, analysis, and reporting protocols by which new information affecting project NPV becomes available occur at predetermined, non-random intervals, whereas the CP model is only valid for events occurring at random intervals. The order of changes in NPV is irrelevant. It is the size distribution of changes that matters, not when they occur. The frequency domain is what matters, not the time evolution.] -->
<!-- # It's ok to be lognormal -->
<!-- When taking a real options approach to project evaluation, it becomes necessary to think carefully about the evolution of project NPV over the life of the project. -->
<!-- Many consider the assumption of lognormally distributed NPV unrealistic. This is to some degree rooted in the original financial context, where the assumption of lognormal security returns is widely viewed as naive... -->
<!-- Bibby and Sorensen [@bibby1996hyperbolic] -->
<!-- Pennings and Lint []. .  misconception [Tankov]. -->

<!-- \begin{equation} -->
<!-- e^{-r\tau} E[\max(x(\tilde{t}) - K, 0)]\bigr|_{t = \hat{t}} = x(\hat{t}) \Phi(\delta + s \sqrt{\tau}) - e^{-r \tau} K \Phi(\delta) -->
<!-- \label{eq:BSov} -->
<!-- \end{equation} -->

<!-- Where -->

<!-- \begin{equation} -->
<!-- \delta = \frac{1}{s \sqrt{\tau}} \left(\ln \left(\frac{x(\hat{t})}{K} \right) - \left(r - \frac{s^2}{2} \right) \tau \right) -->
<!-- \end{equation} -->
<!-- Note the similarity between this and the AR4D ROV expression derived in Equation \ref{eq:rov}. The two expressions are equivalent when evaluated at $r = s^2 / 2$, which implies risk adjusted discounting. -->
<!-- <!-- This bears some emphasis: Risk adjusted discounting equalizes the financial and AR4D option value problems, implying that markets are irrelevant -->
<!-- The same PDE is obtained if the expected growth rates of $f$ and $x$ are both $r \Delta t$ (as is the case in the AR4D context, where $r$ is the discount rate). This is why the Black-Scholes no arbitrage argument implies risk neutral valuation in financial contexts, where $r$ is the risk-free rate of return. -->