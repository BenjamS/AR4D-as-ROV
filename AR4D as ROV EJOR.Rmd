---
title: "The real option value of multistage, far-from-market agricultural research"
author:
  - name: Benjamin Schiek
    email: b.schiek@cgiar.org
    affiliation: CIAT
    correspondingauthor: true
address:
  - code: CIAT
    address: Performance, Innovation, and Strategic Analysis for Impact (PISA4Impact), Alliance of Bioversity International and CIAT, Km 17 Recta Cali-Palmira, Palmira, 763537
abstract: |
  Agricultural research for development (AR4D) donors face increasingly austere fiscal outlooks that restrict their ability to commit to high impact, high risk, agricultural research projects with long time horizons. This results in a series of short-term, piecemeal funding arrangements that inhibit the AR4D community's ability to conduct the disruptive research necessary to meet the Sustainable Development Goals. Real option valuation (ROV) presents a potential mechanism offering donors the flexibility they require to justify long term research funding commitments. However, adaptation of existing ROV methods to the AR4D context is complicated by the financial and corporate underpinnings of these methods, which are inconsistent with the non-market character of most AR4D projects. Adaptation is also complicated by the multistage structure of most AR4D projects, since existing ROV methods are mostly limited to single stage projects. Here we present a multistage ROV method derived from novel theoretical underpinnings that are consistent with the AR4D context. The derived method also accounts for project adandonment value, and for the scaling relation between project impact and funding level. As an illustrative example, we apply the derived model to evaluate a real, four stage potato research project.
keywords: 
  - Real option value
  - Agricultural research for development
  - Risk neutral valuation
  - Abandonment value
  - Far-from-market
journal: "European Journal of Operational Research"
date: "`r Sys.Date()`"
classoption: preprint, 3p, authoryear
bibliography: AR4Drealoptions.bib
linenumbers: false
numbersections: true
# Use a CSL with `citation_package = "default"`
# csl: https://www.zotero.org/styles/elsevier-harvard
output: 
  rticles::elsevier_article:
    keep_tex: true
    citation_package: natbib
header-includes:
  - \numberwithin{equation}{section}
  - \usepackage{float}
  #- \usepackage[nomarkers,tablesonly]{endfloat}
  #- \usepackage[printfigures]{figcaps}
  - \floatplacement{figure}{H}
  - \usepackage[nolists]{endfloat}
  - \usepackage{caption}
---

<!-- Manuscript contribution to the field -->
<!-- (In 200 words, describe the contribution of your manuscript to the research field. You should frame the research question(s) addressed in your work in the context of current knowledge, highlighting how the findings contribute to progress in your research discipline.) -->
<!-- Funding for agricultural research for development (AR4D) projects is set up in stages, such that the funding of any single stage can only move forward upon successful completion of the prior stages. When the project donor agrees to fund a research stage, then, they effectively buy the option, but not the obligation, to fund the subsequent stage. The donor’s investment therefore has option value, which can be considerable if there is high uncertainty (risk) surrounding the expected impact of the research. Conventional methods of AR4D project appraisal fail to account for option value, effectively underestimating the value of risky projects. Real option valuation (ROV) is a potential mechanism by which to price in option value, but adaptation of ROV to the AR4D context is complicated by the multistage, far-from-market-nature of AR4D projects. Here I address these challenges to develop a closed form, multistage ROV model. (I also introduce an elementary extension to account for abandonment value.) By explicitly accounting for risk and the option to abandon, the proposed model offers a more complete picture of AR4D project value as compared to conventional appraisal methods--potentially facilitating donor commitment to the long time horizons of agricultural research. -->


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      dev = c("png", "tiff"),
                      dpi = 300)
library(tidyverse)
library(flextable)
library(patchwork)

label_size <- 2.5
smallLabel_size <- 2
title_size <- 8
subtitle_size <- 7
legendText_size <- 6
axisText_size <- 6
axisTitle_size <- 7
facetTitle_size <- 7

```

# Introduction

<!-- Agricultural research for development (AR4D) scientists are under ever increasing pressure from donors to put a defensible monetary value on their proposed projects. However,  -->
Agricultural research for development (AR4D) projects tend to be high reward, but also high risk propositions with long time horizons. Donors are attracted by the high potential payoff of such projects, but face increasingly austere fiscal outlooks that restrict their ability to engage in long term, risky commitments. For researchers, the resulting uncertainty in the long term funding outlook incentivizes work in the direction of low risk, modest objectives that are achievable in the near term. Such research has its place; but the Sustainable Development Goals (SDGs) call for higher impact, riskier, longer term research as well. Real options valuation, a method of project appraisal adapted from financial analysis, presents a potential enabling mechanism by which to secure long term funding for disruptive research while also guaranteeing donors the fiscal flexibility they require to justify such commitments.
<!-- , such that project net present value is likely to fluctuate considerably over the life of the project -->
<!-- They are also (d) far-from-market, or even unfold in the midst of market failures, such that project value and/or changes in value may not be deduced or projected based on movements in the prices of commodities or financial securities. -->
<!-- Properties (a)-(d) make it extremely difficult to valuate AR4D projects in a way that is meaningfully different from a wild, if educated, guess. With good reason, then, AR4D researchers generally resent the mounting pressure to quantify promising, but distant and uncertain, impacts [@leeuwis2018reforming]. The resentment is evident across other scientific disciplines as well [@Petsko2011; @Moriarty2008]. AR4D donors, meanwhile, have grown disillusioned with the crudeness of research project appraisals---even to the point of disbelief, and a commensurate global decline in AR4D funding levels [@hurley2016returns; @hurley2014re; @pardey2018shifting]. The frustration of scientists and donors alike is compounded by increasingly austere fiscal restrictions on donors' ability to commit to the long time horizons of agricultural research. The upshot is an atmosphere of "ever growing distrust" between donors and research communities [@leeuwis2018reforming]. -->

The notion of a real option is born of the analogous concept of a type of financial option known as the European call option [...@meyer...]. The holder of a European call option on an underlying security (a stock, for example) has the right, but not the obligation, to purchase the security for a predetermined price---called the "strike" or "exercise" price---at the end of a certain time period. Analogously, donors who "buy" a real option on an underlying project commit to funding the project for a certain time period, at the end of which they have the right, but not the obligation, to continue funding the subsequent stage of the project. In the case of research projects, for example, the subsequent stage at the end of time period $T$ might be the distribution and outscaling of a new crop variety developed during the main research stage. The value of such a real option (ROV) may be expressed mathematically as follows.

\begin{equation}
ROV = e^{-r T_0} E[max(x(T_0) - K_0, 0)]
\label{eq:basic}
\end{equation}

Where $x(T_0)$ is project net present value (NPV) at the end of the time period $T_0$, $K_0$ is the cost of funding the subsequent project stage, and $r$ is the discount rate.
<!-- [@trigeorgis2017real] -->
<!-- -@trigeorgis1993real; and McGrath [-@mcgrath2000assessing] -->
<!-- The methodological details of real option valuation can vary considerably from one applied context to another. But, generally speaking, -->

A project's real option value (ROV) can be higher than its NPV, especially in the case of high risk, high reward projects, such that a project that would normally be rejected in a conventional cost-benefit analysis might pass muster on an ROV basis. For a detailed introduction to ROV, see Trigeorgis [-@trigeorgis1999real]. For an introduction to ROV in R&D contexts specifically, see [].

Real options contracts potentially bridge the divide between donor risk aversion and the risk tolerance required to achieve high impact AR4D because they are mutually beneficial for both donors and researchers alike. From the donor's perspective, a real option contract is a way to tentatively lay claim to promising, but distant and uncertain, research results, while at the same time guaranteeing easy extraction from underperforming projects. The resulting fiscal agility then translates into longer term funding commitments, which is music to the ears of the research community.

It is worth noting, moreover, that many donors already acquire an unacknowledged option value in their conventional research funding arrangements. That is to say, nowadays, most AR4D contracts are signed for no more than 1-5 years, at the end of which the contract comes up for renewal or cancellation, pending progress up to that point. By reserving the right to discontinue funding at specific time intervals, the donor effectively acquires option value. The introduction of ROV would thus merely formalize an already existing practice, and more accurately appraise the real value acquired by the donor in exchange for their investment. By the same token, the default methods of cost benefit analysis currently in place neglect to price in the donor's option value, and thus understate the real value acquired by the donor.

ROV methods have so far developed primarily in the context of corporate projects []. A simple extension of this work to the AR4D context is complicated, if not made impossible, by the fundamental difference between the two contexts: corporate projects unfold in market or near market settings, where much of the original option value theory developed in finance may be invoked. AR4D projects, on the other hand, typically unfold in the midst of market failures, where the underlying assumptions of such theory do not apply. In particular,

1) AR4D project NPV is not well approximated by a linear combination of price movements (the "replicating portfolios" assumption).

2) AR4D project risk cannot be hedged away by trading securities (the "complete markets" assumption).

3) AR4D donors are not willing to take on any level of risk for a given expected return ("risk neutral valuation").

4) Since AR4D project NPV is uncorrelated with markets, the capital asset pricing model (CAPM) is irrelevant. (The AR4D beta is zero, if you like.)
<!-- 5) AR4D projects do not pay dividends. [worth talking about only if gonna critique Dixit and Pindyck]-->

Extension of existing ROV methods to the AR4D context is also complicated by the multistage nature of most AR4D projects. For example, many AR4D plant breeding projects involve a preliminary greenhouse and/or field trial(s) stage, followed by more advanced, multi-location field trials [@covarrubias2022breeding]. In transgenic projects, additional toxicological testing is required, followed by the compilation of a regulatory dossier and application for deregulation before the national competent authority in the target countries where the new technology is to be released [@Schiek]. Finally, there is the release, distribution, and outscaling stage, which involves careful orchestration of complex networks of stakeholders and public-private partnerships.

Donors invest in each of these stages one at a time, consecutively, with investment in the subsequent stage contingent upon successful completion of the current stage. The donor's investment in stage one of a three stage project, then, is analogous to purchasing an option on stage two---i.e., the right but not the obligation to invest in stage two---which is in turn an option on stage three. Existing ROV methods, meanwhile, focus primarily on single stage projects. The one exception is a multistage model proposed by Cassimon et al. [-@cassimon2004valuation] for the evaluation of pharmaceutical trials, building upon the two stage or "compound option" model originally developed by Geske [-@geske1979valuation] in the financial context. Again, such work is not readily extensible to AR4D due to its corporate and financial theoretical underpinnings.

In this article, we derive a multistage ROV model for the AR4D project context. Rather than build upon the existing ROV groundwork developed in the financial and corporate contexts, we demonstrate why that groundwork is incompatible with the AR4D context, and develop a suitable foundation in its place. More specifically, in place of strained arguments to construe project NPV as a traded good in an efficient market, we show how an ROV model for non-traded goods follows from the definition of NPV itself, and from the choice of stochastic model to represent the time evolution of project NPV. The derivation begins with a defense of the geometric Brownian motion (gBm) stochastic model of project NPV as striking the right balance between realism and methodological tractability in the AR4D context. In place of risk-neutral valuation, then, [we show that risk-adjusted discounting follows as a corollary]. After deriving the ROV model for single stage AR4D projects, the extension to multistage projects turns out to be remarkably simple compared to the aforementioned efforts of Cassimon et al. [-@cassimon2004valuation].
<!-- In fact, we show that, in the AR4D context, the multistage ROV equation is essentially no different from the single stage equation. -->

Following the main derivation, we describe a hypothetical use case wherein the derived model is applied to evaluate the ROV of a real four stage AR4D project to develop a potato variety with resistance to Late Blight disease for release as a public good in developing countries. The article concludes with a discussion of two minor, but useful modifications. First we show how the model can be extended to include "abandonment value", i.e., the value often generated by AR4D projects in the form of human and physical capital upgrades, regardless of the success or failure of the main research activities. And we demonstrate how the model might be modified to account for the scaling relation that typically exists between AR4D project investment and impact.
<!-- But first, all of this is prefaced by a studious avoidance of the theoretical underpinnings of corporate ROV methods, which follows immediately below in the literature review. -->

From the outset it is important to distinguish the notion of ROV pursued here (Equation \ref{eq:basic}) and originally developed by Meyer [], from a so-called "real option approach" already followed in numerous agricultural R&D appraisal studies []. The purpose of the ROV approach developed here is to appraise, from the donor's perspective, AR4D projects with known time horizons in a way that prices in option value. The other "real option approach" currently implemented in the agricultural R&D literature is, more accurately, an "optimal delay approach", in the sense that it is primarily concerned with determining the optimal delay, from a social planner's perspective, of the release and outscaling of a finished agricultural R&D product with uncertain environmental impact []. As such, it is not primarily concerned with the valuation of the R&D product itself, which is what we pursue here.
<!-- Since much of the intended audience may be unfamiliar with ROV, these main results are prefaced by an incremental mathematical explanation of the basic concept and intuition. This preface begins with a basic clarification of what is meant by "project NPV", plus an introduction to (and defense of) geometric Brownian movement (gBm) as a model of the stochastic evolution of project NPV. The closed form ROV equation for 1-stage projects known as the Black-Scholes model is then derived solely on the assumption that project NPV follows a gBm, without recourse to any of the usual assumptions applied in financial and corporate contexts. This is followed by brief remarks on building intuition. This is followed by the elementary adjustments to account for abandonment value -->
<!-- -This is followed by an explanation of the implications in B-S PDE land, completing the replacement of financial/corporate assumptions with suitable AR4D assumptions. How it does not imply risk-neutrality etc. (All of the assumptions listed above should receive clear treatment) This is where any remarks on Dixit and Pindyck would go. Possibly solve the Dixit-Pindyck PDE under the new AR4D boundary conditions? -->
<!-- -Here the adjustment to accommodate the impact scaling relation between the outscaling investment and project NPV; including showing how to solve for the ROV-maximizing outscaling investment. -->
<!-- -Finally, we apply the derived model to appraise a real 4-stage AR4D potato project. -->
<!-- Where does discussion of B-S PDE and Dixit & Pindyck etc. go? -->
<!-- [...the complexity of stochastic processes encountered in financial and corporate contexts leads them down the dark path of numerical methods at great methodological cost...Pennings & Lint cPp... Here argue that gBm is a good enough and great methodoligcal benefits, periods of no change (cPp can be modeled arbitrarily closely as periods of negligible change (gBm). -->
<!-- ...there is a strong consensus against gBm at great methodological cost... corp people be dissin the gBm bitter pill -- this will have to be tackled first, leads naturally then to derivation of (1-stage) ROV formula by straightforward integration based only on assumption of lognormal changes.] -->
<!-- ...We present an unoriginal, but little discussed, derivation of the option value equation identical to the one derived by Black and Scholes, but which does not depend upon the Black-Scholes PDE, nor any of the underlying assumptions that are problematic in the AR4D context. And we demonstrate that this independently derived equation is nonetheless consistent with [a certain interpretation of] the Black-Scholes PDE by presenting an alternative derivation of the Black-Scholes PDE that does not depend upon the no-arbitrage rule, nor complete markets, and does not imply risk-neutral valuation, and is thus consistent with the AR4D context. -->
<!-- [as  Moreover, since price information is automatically updated on a second-by-second basis, a project NPV time series is generated by which to estimate project risk (i.e. the standard deviation of the project NPV fractional change per time step), and to otherwise empirically inspect the stochastic character of the time evolution of project NPV.] -->
<!-- If it is not possible to make risk-free profits above the risk-free rate of return (the “no-arbitrage” rule), then investors are risk-neutral, i.e. “investors do not increase the expected return -->
<!-- they require from an investment in order to compensate for increased risk” (Hull, 2015) -->
<!-- Since the replicating portfolios argument effectively specifies project NPV as a linear function of prices, then project NPV may be easily calculated at any time from publicly available price information. Moreover, since price information is automatically updated on a second-by-second basis, a project NPV time series is generated by which to estimate project risk (i.e. the standard deviation of the project NPV fractional change per time step), and to otherwise empirically inspect the stochastic character of the time evolution of project NPV. -->
<!-- as it would merely indicate the value of the project objective (of which everyone is already convinced), and not of the particular technology, expertise, strategy, and enabling environment that distinguish the project from other projects pursuing similar objectives. -->
<!-- AR4D donors are already convinced of the value of the SDGs without waiting to see what the "markets say about it"; and, tragically, there is little or no risk of the "bottom falling out" of such markets, at least not in our lifetimes. -->
<!-- This bears emphasis, as it underscores a fundamental difference between the AR4D and corporate ROV contexts: Generally speaking, in corporate ROV contexts, project NPV hinges primarily upon the market value of the project objective (e.g., a natural resource), which may fluctuate considerably over the life of the project; and only secondarily upon technical progress toward the proposed project objective. In the AR4D context, it is the other way around: project NPV hinges critically upon technical progress towards the project objective (e.g., a disease resistant cultivar), which may fluctuate considerably over the life of the project, while the value of the objective itself is effectively taken for granted. In the former case, price risk is the key source of uncertainty; in the latter case, it is technical risk, i.e. the risk that the proposed technology will not function or scale as expected, due either to technical difficulties encountered in the research itself, or to unforeseen adversity in the enabling environment (e.g., government policy shifts, deregulation issues, etc.). -->
<!-- In other words, the main source of AR4D project risk---i.e. of significant, unforeseeable fluctuations in project NPV---is not variability in the value of the end objective, but rather the technical risk associated with the research itself, and/or the research enabling environment (e.g., government policy shifts, deregulation issues, etc.). -->
<!-- Unlike corporate project NPV, , AR4D project NPV is primarily a function of the technical feasibility of the research and/or the political and institutional enabling environment. -->
<!-- Here we present an alternative derivation of the Black-Scholes PDE based only the assumption of normally distributed log returns, and that the present value of future impacts appreciates at the discount rate. -->
<!-- which makes perfect sense to financial analysts, but is problematic in the AR4D setting. Risk-neutral valuation means that, if it is not possible to make risk-free profits above the risk-free rate of return (the "no-arbitrage" rule), then investors are risk-neutral, -->
<!-- Such assessments typically require a considerable investment of time, effort, and expertise, making frequent updates of project NPV unfeasible. As a result, we are left without a project NPV time series by which to estimate project risk or otherwise empirically inspect the stochastic character of project NPV. -->
<!-- Finally, and most importantly from a theoretical standpoint, the replicating portfolios argument means that project NPV may be treated as a traded good in an efficient market. This figures critically in the formal derivation of the financial option formula one wishes to adapt to real options (i.e. the Black-Scholes partial differential equation) via an argument known as the "no-arbitrage rule" [@hull9thEdition]. It also implies a  -->
<!-- Mathematically, this means that $m = r$ (where $r$, in financial contexts, refers to the risk-free rate of return). -->
<!-- @mathews2007practical -->
<!-- In the AR4D context, project NPV must be evaluated the "hard way", by ex-ante impact assessment. These assessments typically require a considerable investment of time, effort, and expertise, making frequent updates of project NPV unfeasible. As a result, we are left without a project NPV time series by which to estimate project risk or otherwise empirically inspect the stochastic character of project NPV. We must therefore devise some other way of estimating project risk...../ In the AR4D context, neither  NPV is not a traded good, nor may complete markets be invoked, then there is no theoretical premise for the B-S PDE. -->
<!-- Pennings and Lint [-@pennings1997option], for example, cite the case of the Merck pharmaceutical company, which has estimated R&D project risk based on the company's stock price volatility. -->
<!-- relatively recent critique and synthesis of real options theory by one of its founders [@trigeorgis2017real] -->
<!-- surveys repeatedly indicate low uptake of rov [@ryan2002capital; @block2007real; @horn2015use] -->
<!-- Triantis gives the best survey of methodological critiques or rov [@triantis2005realizing] -->
<!-- a survey of more conceptual or high level critiques of rov [@driouchi2012real] -->
<!-- good description of rov state of the art by key proponent [@schwartz2013real] -->
<!-- numerical models..[@triantis2005realizing]. the response to disappointing uptake and ctirique is thus to double down on trigergois' original "bitter pill" critique...[trigeorgis] (which is odd because this then results in an even blacker black box)... [At any rate] This entire discussion occurs in the context of corporate real options. The replicating portfolio arguments are already strained there at the fringes of the market. In the AR4D context they are broken. AR4D unfolds precisely in the midst of a market failure. Not profits but net benefits in terms of smallholder incomes, environmental services, nutritional and public health outcomes. [no way this can be represented in terms of market prices] -->
<!-- Rather than build upon the existing literature, then, we must break new ground. -->
<!-- ROV has been applied and discussed in private sector research contexts [@mitchell1990alternative; @pennings1997option; @cassimon2004valuation; @doctor2001managing; @newton2004real; @mathews2007practical]; and much of this work is relevant to the AR4D context---although there are some important differences which must be kept in mind. Regardless, rather than build upon the existing work in this direction, we propose an alternative -->
<!-- The project's net present value (NPV) is analogous to the price of the underlying security in the financial context, while the cost of the subsequent stage is analogous to the exercise price. (The cost of the subsequent stage must be known up front for the analogy to hold.)  -->
<!-- [Incidentally, this is an additional benefit of ROV---it explicitly takes account of risk.] -->
<!-- Pennings and Lint [-@pennings1997option], in this journal, evaluated the ROV of a project to develop a new consumer electronics product at a private tech firm. The exercise price, in this case, was the cost of building manufacturing plants required to produce the prospective product at scale plus marketing costs. -->
<!-- can 1) provide meaningful, risk-adjusted project appraisals, 2) secure long term commitments from donors, while at the same time 3) giving donors the flexibility they require to maintain solvent fiscal outlooks. -->


# Literature review

<!-- a strong consensus exists in the corporate ROV literature, adopted from the financial literature, that the log returns of a project NPV time series are not normally distributed []. In the more technical speech that we will delve into below, they eschew geometric Brownian motion (gBm) as a naive model of project NPV, preferring instead more complicated stochastic jump models, such as a compound Poisson process (CPp), that can more realistically reflect abrupt jumps in the time evolution of NPV []. There are good reasons for applying stochastic jump models in the financial and (some) corporate settings, but it comes at a high methodological cost, as it adds a thick layer of complexity onto an already complex modeling workflow, and requires numerical methods for ROV solution.   ...bitter pill. The assumption of gBm greatly simplifies...a questionable gain in realism at great methodological cost. -->

<!-- Secondly, the mathematical option value formula we wish to adapt to real options settings (i.e., the Black-Scholes equation) is fundamentally derived from the assumption that the underlying good is traded in an efficient market---known in finance as the "no-arbitrage rule" [@hull9thEdition]. More problematically still, the no-arbitrage rule then leads to a corollary known as "risk-neutral valuation", which implies that the donor is willing to take on any level of risk for a given expected reward [@hull9thEdition]. Again, in some private sector R&D settings, it may be that project NPV is highly correlated with company price, and/or a linear combination of other relevant prices, effectively validating such assumptions. In the AR4D context, however, it can be said without controversy that neither the no-arbitrage rule nor risk-neutral valuation are valid assumptions. -->

<!-- and this has surely contributed to the complexity resulting in low adoption of ROV in real world decision making. It is not uncommon for ROV studies and surveys to assume risk-neutral valuation without any justification (see, for example, Trigeorgis [-@trigeorgis1993real], Majd and Pindyck [-@majd1987time], or Kemna [-@kemna1993case]). Some studies acknowledge the invalidity of the no-arbitrage argument in ROV contexts, but instead invoke "complete markets" to justify risk-neutral valuation (see, for example, Pennings and Lint [-@pennings1997option]). However, the complete markets assumption implies that 1) project NPV can be simulated by a portfolio of traded securities, and hence project risk can be hedged away by buying and/or selling these traded securities; and 2) project managers actually engage in the buying and selling of securities necessary to achieve this hedge. One may say without controversy that neither (1) nor (2) are common features of AR4D project management landscapes. -->

Existing project ROV methods have developed in the context of corporate projects aiming to develop new goods or services to be marketed for a profit. In such a market or near market setting, a financial argument known as "replicating portfolios" may be invoked [@brennan1985evaluating; @koller2010valuation; @amram1998real]. Methodologically, the replicating portfolios argument means that corporate project NPV is well approximated ("replicated") by a linear combination of relevant prices. This greatly facilitates the estimation of project NPV and risk---both of which are required for ROV---as they may be calculated at any time from publicly available price information.

AR4D projects, on the other hand, are born of market failures, where no such argument may be invoked; and so AR4D project NPV and risk must be calculated the "hard way", by ex-ante impact assessment. Some might contend that the recent emergence of carbon and green bond markets [@tolliver2019green; @bhutta2022green] paves the way for a replicating portfolios analogue in the AR4D context. However, in addition to green outcomes, AR4D projects typically focus on health, nutrition, and socioeconomic outcomes for marginalized populations, the respective values of which, almost by definition, are not reflected in any market. And, even if they were---even if there were an "SDG bond" mapped to every AR4D impact area---this might be useful in the evaluation of project NPV, but of very little use in the assessment of project risk, since the main source of AR4D risk is not "price risk" (tragically, there is little risk of the bottom falling out of the SDG "market" in our lifetimes), but rather technical risk, i.e. the risk that the proposed technology will not function or scale as expected, due either to technical difficulties encountered in the research itself, or to unforeseen adversity in the enabling environment (e.g., government policy shifts, deregulation issues, etc.).

Even in the corporate ROV context, the replicating portfolios argument is met with considerable skepticism [@borison2005real]; and proponents of the argument acknowledge that its validity is limited to a narrow range of project types, which generally does not include R&D projects [@schwartz2013real]. There is strong methodological incentive to invoke the argument because the fundamental equation governing all types of option (and all financial derivative) valuation---i.e., the Black-Scholes partial differential equation (PDE)---is formally derived from an assumption in financial markets known as the "no-arbitrage rule", which requires that the underlying project NPV be interpretable as a traded good in an efficient market [@hull9thEdition].

To preserve the Black-Scholes PDE in cases where the replicating portfolios argument may not be invoked, some corporate ROV practitioners invoke the "complete markets" assumption as a second-best alternative [majd; pennings; @schwartz2013real]. Under the complete markets assumption, project NPV cannot be modeled as a linear function of prices, but the Black-Scholes PDE is nonetheless preserved because "all risks can be hedged by trading securities" [pennings]. As just mentioned, the main source of AR4D project risk is technical risk associated with non-market factors. Clearly, then, AR4D risk cannot be hedged by trading securities; and so there are no grounds in the AR4D context on which to invoke complete markets.
<!-- i.e. where project NPV may not be replicable as a traded good, -->

More problematically still, the formal derivation of the Black-Scholes PDE from either the replicating portfolios or complete markets assumptions leads to a celebrated corollary known as "risk-neutral valuation", which implies that "investors do not increase the expected return they require from an investment in order to compensate for increased risk" [@hull9thEdition]. Clearly, AR4D donors are not risk neutral. They are willing to bet on a high risk project only if there is a sufficiently high expected return on the investment. If the Black-Scholes PDE is to be consistent with the AR4D context, then, it must be formally derived from a suitable premise (not replicating portfolios or complete markets), and in a way that does not imply risk-neutral valuation as a corollary.
<!-- , if it is not possible to make risk-free profits above the risk-free rate of return (the "no-arbitrage" rule), then investors are risk-neutral, i.e.-->

In the method section farther below, we show how an AR4D compatible Black-Scholes PDE can be derived from the definition of project NPV, [and how this leads to a risk adjusted discounting corollary instead of risk neutral valuation]. But first it is necessary to disassociate the present approach from the corporate ROV literature on another front.

## In defense of geometric Brownian motion model of project NPV evolution

Yet another difference between the corporate and AR4D contexts requiring careful attention concerns the modeling of the stochastic time evolution of project NPV. Many in the intended audience may be unfamiliar with stochastic models, but well versed in statistics. For purposes of exposition, the choice of stochastic model of NPV time evolution may be thought of as the choice of size distribution of percentage changes in project NPV per small time increment. Lognormally distributed changes in NPV correspond to the popular stochastic model known as gBm, for example, displayed in the left panel of Figure \ref{fig:NPVevol}. (See Hull [-@hull9thEdition] for a detailed introduction to gBm.)

```{r, include=FALSE}

# library(tidyverse)
# library(patchwork)
#----------------------------------------------------------------------------
gbmFun <- function(tau = 40, m = 0.001, s = 0.003, x0 = 1,
                   randVec = NULL, seed = NULL) {
  if(is.null(randVec)){
    if(!is.null(seed)){set.seed(seed)}
    randVec <- rnorm(tau)
  }
  epsilon <- randVec
  lx <- c(); lx[1] <- log(x0)
  drift <- (m - s * s / 2)
  for(t in 2:tau){
    dBt <-  s * epsilon[t]
    lx[t] <- lx[t - 1] + drift + dBt
  }
  x <- exp(lx)
  return(x)
}
# m <- 0.001
# s <- 0.003
# tau <- 400
# x0 <- 1
# x <- gbmFun(tau, m, s, x0, randVec = NULL)
# df_plot <- data.frame(t = 1:tau, x)
# gg <- ggplot(df_plot, aes(x = t, y = x))
# gg <- gg + geom_line()
# acf(diff(log(x)))
# hist(diff(log(x)))
# shapiro.test(diff(log(x)))
#---------------------------------------------------------------------------
# Algorithm 6.2 in Tankov 2003 Financial modeling with jump processes
compoundPoisFun <- function(tau, lambda, m_y = 0, s_y = 1,
                            seed = NULL, maxiter = 500){
  if(!is.null(seed)){set.seed(seed)}
  N <- rpois(1, lambda * tau)
  U <- runif(N) * tau
  U <- round(U)
  n_iter <- 0; flag <- 1
  while(flag == 1){
    n_iter <- n_iter + 1
    U <- runif(N) * tau
    U <- round(U)
    if(sum(duplicated(U)) > 0 & n_iter <= maxiter){
      flag <- 1
    }else{
      flag <- 0
      if(n_iter == maxiter){
        print("Reached maxiter without generating duplicate-free event times vec. Dropping duplicates.")
        U <- U[-which(duplicated(U))]
      }
    }
  }
  Tt <- U[order(U)]
  J <- exp(rnorm(N, m_y, s_y)) - 1
  #---
  cumJ <- cumsum(J)
  # For explicit modeling of Yt per time step
  Yt <- rep(0, tau)
  Yt[Tt] <- cumJ
  #---
  Tt <- c(0, Tt)
  J <- c(0, J)
  if(Tt[length(Tt)] != tau){
    Tt <- c(Tt, tau)
    J <- c(J, 0)
  }
  cumJ <- cumsum(J)
  df_step <- data.frame(Tt, cumJ)
  #--------------------------
  nEvents <- length(Tt)
  cumYt <- c()
  for(i in 1:(nEvents - 1)){
    tStart <- Tt[i]
    tFin <- Tt[i + 1] - 1
    cumYt[tStart:tFin] <- cumJ[i]
  }
  cumYt[tau] <- cumYt[tFin]
  df_Yt <- data.frame(t = 1:tau, Yt, cumYt)
  
  list_out <- list(df_step, df_Yt)
  return(list_out)
  
}
#----------------------------------------------------------------------------
FractDim<-function(Data,graphon=FALSE) {
  X=Data;N=length(X);
  jstart=10;jend=floor(10*(log10(N)-1));
  kvec=c(1:4,floor(2^(c(jstart:jend)/4)));
  indkend=length(kvec);
  k=c()
  AvgLmk=c()
  err=c()
  for(indk in 1:indkend)
  {
    k=kvec[indk]
    Xend=c()
    Xsum=c()
    Lmk=c()
    for(m in 1:k)
    {
      Xend=floor((N-m)/k)
      Xsum=sum(abs(X[m+c(1:Xend)*k]-c(0, X[m+c(1:(Xend-1))*k])))
      Lmk[m]=1/k*1/k*(N-1)/Xend*Xsum
    }
    AvgLmk[indk]=mean(Lmk)
    #  err[indk]=sd(log(Lmk))
  }
  x<-log(kvec)
  y<-log(AvgLmk)
  q<-lm(y~x)
  slope<-q$coefficients[2]
  yintcept<-q$coefficients[1]
  yfit<-x*slope+yintcept
  FrDim <- -slope
  avgRes <- mean(abs(q$residuals))
  if(graphon==TRUE)
  {
    plot(x,y,main="If linear then fractal, w/Fr. Dim = (-)slope",xlab="Ln(k)",ylab="Ln(length of curve with interval k)")
    z<-line(x,yfit);abline(coef(z),col='blue');z<-NULL
    #z<-line(x,y);abline(coef(z),col='blue');z<-NULL
  }
  #z<-line(x,y);qq=coef(z)
  #yintcept=qq[1]
  #FrDim=-qq[2]
  return(c(FrDim, avgRes, yintcept))
}
#===========================================================================
m <- 0.005
s <- m * seq(5.5, 50, length.out = 3)
tau <- 48
x0 <- 1
#rn <- round(runif(1) * 1000)
#rn <- 905
#rn <- 517
# rn <- 340
# set.seed(rn)
# tau <- 12 * 4
lambda <- 0.1


#----------------------------------------------------------------------------
# Generate and plot geometric Brownian movement example
#gBm_seed <- 10^4 * round(runif(1), 4)
#gBm_seed <- 2482
#gBm_seed <- 7781
gBm_seed <- 1029
#randVec <- coloredNoise(N = tau, alpha = 1, scaleIt = T)
#acf(randVec)
list_df <- list()
list_spec <- list()
facet_labels <- c()
for(i in 1:length(s)){
  x <- gbmFun(tau, m, s[i], x0, randVec = NULL, seed = gBm_seed)
  df_x <- data.frame(t = 1:tau, x, s = as.character(s[i]))
  list_df[[i]] <- df_x
  o <- spectrum(x)
  df_gbmSpec <- data.frame(lfreq = log(o$freq), lpwr = log(o$spec))
  df_gbmSpec <- df_gbmSpec[-1, ]
  df_gbmSpec$s <- as.character(s[i])
  list_spec[[i]] <- df_gbmSpec
  
  mod <- lm(lpwr ~ lfreq, df_gbmSpec)
  # summary(mod)
  alpha <- round(as.numeric(coefficients(mod)[2]), 2)
  # yint <- as.numeric(coefficients(mod)[1])
  # df_out <- as.data.frame(broom::glance(mod))
  # adjR2 <- round(df_out$adj.r.squared, 2)
  # N <- df.residual(mod)
  this_facet_label <- paste0("Slope = ", alpha, " fd = ", round(FractDim(x)[1], 2))
  facet_labels[i] <- this_facet_label
}
#---
df_plot <- as.data.frame(do.call(rbind, list_df))
colnames(df_plot)[1:2] <- c("Time", "Project NPV")
df_plot <- subset(df_plot, s == s[2])
gg <- ggplot(df_plot, aes(x = Time, y = `Project NPV`))
gg <- gg + geom_line()
#gg <- gg + facet_wrap(~s, scales = "free_y", ncol = 1)
gg <- gg + theme_bw()
gg <- gg + theme(axis.text = element_blank(),
                 axis.title = element_text(size = axisTitle_size))
gg_gbm <- gg
#---
df_plot <- as.data.frame(do.call(rbind, list_spec))
colnames(df_plot)[1:2] <- c("Logged frequency", "Logged power spectral density")
df_plot <- subset(df_plot, s == s[2])
#names(facet_labels) <- s
gg <- ggplot(df_plot, aes(x = `Logged frequency`, y = `Logged power spectral density`))
gg <- gg + geom_smooth(method = lm, se = F)
gg <- gg + geom_line()
# gg <- gg + facet_wrap(~s, ncol = 1,
#                       labeller = labeller(s = facet_labels))
gg <- gg + theme_bw()
gg <- gg + theme(axis.text = element_blank(),
                 axis.title = element_text(size = axisTitle_size))
gg_gbmSpec <- gg
gg
#----------------------------------------------------------------------------
# Generate and plot compound Poisson process example
#cPp_seed <- 10^4 * round(runif(1), 4)
#cPp_seed <- 6819
#cPp_seed <- 4880
#cPp_seed <- 7656
cPp_seed <- 2558
list_df <- list()
list_spec <- list()
facet_labels <- c()
for(i in 1:length(s)){
  #s_y = 0.3
  list_out <- compoundPoisFun(tau, lambda, m_y = m,
                              s_y = s[i], seed = cPp_seed,
                              maxiter = 500)
  df_x <- list_out[[1]]
  df_x$s <- as.character(s[i])
  list_df[[i]] <- df_x
  
  df_Yt <- list_out[[2]]
  o <- spectrum(df_Yt$cumYt)
  df_spec <- data.frame(lfreq = log(o$freq), lpwr = log(o$spec))
  df_spec <- df_spec[-1, ]
  df_spec$s <- as.character(s[i])
  list_spec[[i]] <- df_spec
  
  mod <- lm(lpwr ~ lfreq, df_spec)
  # summary(mod)
  alpha <- round(as.numeric(coefficients(mod)[2]), 2)
  # yint <- as.numeric(coefficients(mod)[1])
  # df_out <- as.data.frame(broom::glance(mod))
  # adjR2 <- round(df_out$adj.r.squared, 2)
  # N <- df.residual(mod)
  this_facet_label <- paste0("Slope = ", alpha, " fd = ", round(FractDim(df_Yt$cumYt)[1], 2))
  facet_labels[i] <- this_facet_label
  
}
#---
df_plot <- as.data.frame(do.call(rbind, list_df))
colnames(df_plot)[1:2] <- c("Time", "Project NPV")
df_plot <- subset(df_plot, s == s[2])
gg <- ggplot(df_plot, aes(Time, `Project NPV`))
#gg <- ggplot(df_cpp, aes(t, cumYt))
gg <- gg + geom_step()
#gg <- gg + facet_wrap(~s, ncol = 1)
gg <- gg + theme_bw()
gg <- gg + theme(axis.text = element_blank(),
                 axis.title.y = element_blank(),
                 axis.title.x = element_text(size = axisTitle_size))
gg_cpp <- gg
#---
df_plot <- as.data.frame(do.call(rbind, list_spec))
colnames(df_plot)[1:2] <- c("Logged frequency", "Logged power spectral density")
df_plot <- subset(df_plot, s == s[2])
#names(facet_labels) <- s
gg <- ggplot(df_plot, aes(x = `Logged frequency`, y = `Logged power spectral density`))
gg <- gg + geom_smooth(method = lm, se = F)
gg <- gg + geom_line()
# gg <- gg + facet_wrap(~s, ncol = 1,
#                       labeller = labeller(s = facet_labels))
gg <- gg + theme_bw()
gg <- gg + theme(axis.text = element_blank(),
                 axis.title.y = element_blank(),
                 axis.title.x = element_text(size = axisTitle_size))
gg_cppSpec <- gg

```

```{r Fig2, fig.show = "hold", fig.width = 5, fig.height=2, fig.align="center", fig.cap="\\label{fig:NPVevol}(Left)An example of NPV changing randomly in every time step. (Right)An example of NPV changing randomly at random time steps, and otherwise remaining constant.", echo = FALSE}

gg_gbm + gg_cpp + plot_layout(nrow = 1)


```
There is a tradeoff between realism and methodological expedience when choosing a suitable stochastic model of project NPV evolution. The gBm model is methodologically attractive because it allows for a closed form solution to the Black-Scholes PDE, i.e., the Black-Scholes option value equation. However, in the financial context, the gBm model is eschewed as unrealistic because it does not reflect the abrupt jumps empirically observed in many price series, which are inconsistent with a lognormal size distribution. Instead, a number of "jump" and "jump-diffusion" models are applied, which more accurately characterize the observed price data [merton, tankov]. An example of a jump process, known as the compound Poisson process (cPp), is displayed in the right panel of Figure \ref{fig:NPVevol}. This then comes at the high methodological cost of requiring numerical solutions to the Black-Scholes PDE. The same consensus against gBm, at the same high methodological cost, is adopted in the corporate ROV context. Trigeorgis once characterized numerical methods as the unavoidable "bitter pill" that all serious ROV practitioners must come to grips with [-@trigeorgis1993real].
<!-- which are exceedingly difficult to explain to anyone who is not a financial expert -->

In hindsight, the appetite for bitterness outside of academic audiences---that is to say, adoption of ROV thinking by real world decision makers---has remained low [@horn2015use; @triantis2005realizing; @driouchi2012real]. Both critics and proponents alike attribute this tepid reception to the formal complexity of ROV, much of which can be traced back to the use of sophisticated stochastic models of project NPV that require numerical solutions to the Black-Scholes PDE [@triantis2005realizing]. From the perspective of research donors and managers, such numerical methods are effectively black boxes; and even ROV experts find themselves bamboozled at times. A much cited numerical exercise by Majd and Pindyck [-@majd1987time], for example, contains an elementary error, which was only discovered some twelve years after publication [@milne2000time].
<!-- In hindsight, it is safe to say that energetic proponents of ROV like Trigeorgis have overestimated the appetite for bitterness outside of academic audiences. The adoption of ROV methods in real world decision making settings remains low; and the main reason given for the low adoption is the methodological complexity of ROV compared to conventional cost-benefit analysis methods [@ryan2002capital; @block2007real; @horn2015use; @triantis2005realizing; @driouchi2012real]. -->
<!-- [---enough so, at any rate, to warrant some revisiting of the matter:] -->
<!-- The case for complex ROV approaches weakens further when considering what is gained in return for sacrificing expedience. Pennings and Lint find only a $2\%$ difference between the the output of their cPp numerical model and that of the gBm closed form model [@pennings1997option]. To what extent is an increase in modeling realism even meaningful in a context where direct measurement of the reality one aspires to approximate---i.e., the evolution of project NPV---is highly problematic? Is the costly increase in realism even relevant to the aims of the modeling exercise? Is there an alternative, less costly way of achieving the same ends? -->
<!-- 33.1 - 32.3 -->

In the AR4D context, the grounds for swallowing this bitter pill are especially narrow. To begin with, it is not even clear what a realistic time evolution of AR4D project NPV looks like. The time and expense involved in AR4D ex-ante impact assessment make frequent, regular updates of project NPV impractical, which in turn means that direct empirical inspection of the stochastic character of project NPV over a series of small, regularly spaced time steps is generally not possible---certainly not in the way that is possible for a price series.

In the corporate context, Pennings and Lint [-@pennings1997option] attempt to resolve this issue by assembling from scratch an historical time series of project NPV; and then selecting and parameterizing their stochastic model of future project NPV based on this. Such an approach, arguably, does not so much resolve the issue as it does replace it with another set of problems. First and foremost, the historical project NPV must be carefully selected so as to be representative of the NPV trajectory of the new project under evaluation. Apart from a passing verbal assurance, Pennings and Lint offer little indication that their assembled time series may be plausibly construed as representative of the stochastic character of the new project under evaluation [-@pennings1997option]. In the AR4D context, especially, projects are so heterogeneous in their scale, scope, aims, target populations and environments, and so forth, that finding a past project NPV trajectory that plausibly maps onto a present project's NPV amounts to a prohibitive challenge.

Secondly, even if this were possible, the practitioner then runs into small sample problems. In both the corporate and AR4D contexts, the number of substantive adjustments to project NPV over the project's lifespan tends to be small. To generate "enough" data points, P&L merge several past project NPV trajectories together into a single time series. In addition to severely compounding the first problem, the authors come up with just 17 observations over a 5 year period [-@pennings1997option]. Is this enough to select and parameterize a stochastic model of project NPV?

Thirdly, the cPp model selected by Pennings and Lint is appropriate only insofar as the interval size between changes in NPV is random. This is problematic since substantive changes in project NPV can often occur as the result of non-randomly spaced events, e.g. at scheduled test points in the research cycle, or scheduled shifts in the enabling environment (such as elections). Moreover, such changes are typically documented and announced through periodic, non-random reporting protocols.

Finally, there is the subtle and somewhat philosophical sounding, but deeply consequential, issue of sampling rate. When does a change in project NPV occur? Does it occur when the relevant causal event or set of events occurs, or only when management learns of its occurrence and announces the corresponding NPV adjustment? What about events that effectively change NPV, but that go unnoticed by management? Pennings and Lint tacitly presume that changes in NPV occur only if and when management learns of their occurrence. This is perhaps understandable in the corporate context, where the value of company activities is ultimately defined by the stock market, and hence (in principle) by publicly available information. In non-market contexts such as AR4D, on the other hand, we are at liberty to concern ourselves only with the stochastic progression of real changes to project NPV, regardless of when, or even if, management, or anyone else, discovers and documents these changes.

A reasonable starting point in this consideration is the observation that changes in AR4D project value seem to be of two types: research related and non-research related.

Research related changes in project value generally occur at discrete test points, when new information regarding the effectiveness of the new technology becomes available. Non-research related changes in project value occur as a result of changes in the political, socio-economic, and institutional enabling environments where the new technology is to be released. Such changes may include, for example, elections, abrupt changes in government policies, commodity price swings, changes in seed systems and other value chain mechanisms, changes in the security environment, the ebb and flow of public and private sector partnerships to enhance impact, and so forth.

In this setting, then, one may reasonably characterize the project NPV trajectory as a series of negligibly small changes interspersed by relatively few large changes. For purposes of modeling the stochastic character of project NPV, this is enough.


changes in project NPV occur as a result of research and non-research related events, and it is reasonable to assume that, generally speaking, the time evolution of project NPV is characterized by relatively few large shifts---occurring, e.g., at the critical test points in the project timeline and/or major events in the enabling environment, such as elections---interspersed with relatively many small shifts in NPV due to non-research related fluctuations in the enabling environment. Based on this rationale, the lognormal distribution is a reasonable choice as model of the size distribution of changes in project NPV.   ...the gBm parameters may be adjusted so as to approach a stochastic jump diffusion process arbitrarily closely.

We note in passing, moreover, Whether the evolution of project NPV (or of any stochastic process) resembles the time series on the left or right of Figure \ref{fig:NPVevol} is, to a certain degree, a mere matter of the choice of time step. That is to say, the time series on the left can be transformed into to something resembling the time series on the right merely by plotting over a smaller time step. Likewise, the model on the right can be transformed into the model on the left by plotting over sufficiently larger time step. The model on the right becomes unavoidable when said sufficiently larger time step results in an unacceptably small number of time steps for parameter estimation purposes. For present purposes, this is not a problem 

In the AR4D context, this is generally not a problem. Projects typically last 9-25 years, such that, given a quarterly time step, the project NPV time series typically contains 36-100 steps.


In pursuit of realism, then, one not only sacrifices methodological expedience and transparency, but also faces a number of sampling issues that undermine the supposed gain in realism. And for what? After the cPp dust settles, P&L find that their numerical ROV model differs from the more expedient closed form Black-Scholes option forumla by a mere 2% [].

In the AR4D context, certainly, ROV practitioners must not rush to swallow such bitter pills. At the very least, we must make certain that we indeed achieve greater realism in exchange for any sacrificed expedience and transparency, and do not merely substitute one set of problems for another. In the absence of empirical 


This then answers the final question of whether or not a comparable increase in realism, or the objective which the desired increase in realism is supposed to serve, may be achieved at lower cost of expedience. The cPp model might seem like a good choice when trying to approximate a time series in which there are a few big changes interspersed by long periods of no change. However, the periodograms given in Figure \ref{fig:NPVevol2} indicate that the far more expedient gBm model can approximate such a size distribution arbitrarily closely, so long as it is acceptable to substitute "periods of no change" with "periods of negligibly small changes". In their corporate ROV study, Pennings and Lint find only a $2\%$ difference between ROV as calculated by their cPp-based numerical model and ROV as calculated by the gBm-based closed form model [-@pennings1997option].


<!-- ## Modeling the evolution of AR4D project NPV -->
When evaluating AR4D projects as real options, it becomes necessary to think carefully about how project NPV changes over time. This, in turn, requires careful consideration of the causes behind changes in project value. 

Research related changes occur perhaps 1-4 times per year, while non-research related changes occur with greater frequency, perhaps 1-4 times per quarter. Overall, then, it is reasonable to expect changes in AR4D project value to occur every quarter. If the time step is defined as a quarter, then, changes can be expected to occur in every time step, as in the left panel of Figure \ref{fig:NPVevol}.


This conclusion implies a subtle but fundamental decision to model changes in R&D project value _when they occur_, as opposed to when project managers learn of their occurrence. In the corporate R&D context, Pennings and Lint [-@pennings1997option] take the opposite approach, registering changes in project NPV only when management becomes aware of the changes through internal analysis and reporting protocols. In other words, they model changes in project value as "information dam-breaks" (our phrase), whereby new information affecting project value accumulates for a time until it is suddenly released in a report to management, at which time the project value is updated. Such a model of project NPV evolution is depicted in the right panel of Figure \ref{fig:NPVevol}. This approach may be appropriate for corporate R&D, where the value of company assets and activities is ultimately defined by the stock market, and hence (in principle) by publicly available information.
<!-- The information dam-break approach -->
<!-- (Indeed, information dam-breaks are the premise of frontrunning, and hence the bread and butter of many an investment bank.) In the far-from-market R&D context, however, no such nuance comes into play. -->



The time series on the left of Figure \ref{fig:NPVevol} is an example of gBm, while the time series on the right is a compound Poisson process (algorithm 6.2 in Cont and Tankov [-@tankov2003financial]). The compound Poisson process (cPp) assumes that changes in value occur at random time intervals. This is fine in the financial context, but may be problematic in real options contexts, where the information affecting project NPV is released through reports to management---events that are usually, at least in the AR4D context, non-random.

```{r, fig.show = "hold", echo=FALSE}

library(numbers)
library(pracma)
library(gridExtra)
coloredNoise <- function(n, a, normalize = T, graph = F)
{
# 13 / 02 / 18
# Description: 1/f^a noise generator with free parameter "a."
# Outputs a 1/f^a noise R-by-C matrix.
# By adjusting parameter "a" can generate pink, red,
# white, blue, violet noise, or any gradation in between.
# As "a" is less, the signal is more autocorrelated, less random,
# degenerating ultimately into a sine curve. As "a" is greater,
# the signal is more random, approaching white noise and beyond
# (approaching any signal with fractal dimension of 2)
# NOTE: "a" is closely related to the signal's fractal dimension.
# "a" and fract. dim. are related by the logistic function.
# Envisioned Use: Signal generation to immitate 
# stock charts for example. Or as a "random number
# generator" where it is possible to adjust the balance
# between randomness and autocorrelation (by adjusting "a").
# In other words the user has here a random number generator 
# where the fractal dimension of the number selection 
# can be adjusted.
# Source: This function is adapted from Hristo Zhivomirov's Pink,
# Red, Violet, and Blue Noise Generation functions (written in Matlab)
# https://la.mathworks.com/matlabcentral/fileexchange/42919-pink--red--blue-and-violet-noise-generation-with-matlab-implementation?focused=7825006&tab=function
# All those functions are combined in this single function
# (as well as the gradations in bewtween).
#---------------------------
  # Input:
  # R - number of rows to be returned
# C - number of samples to be returned in each row vector
# a - parameter relating power to frequency.  I.e. the 
# power spectral density is proportional
# to the frequency f by a factor f^(-2*a). In other words,
# the amplitudes are proportional to f^(-a).
# normalize - Normalizes output y if ==1.  Note normalization
# changes the standard deviation of the output.
# Output:
  # y - row vector of noise samples
#-----------------------------
  # Each color of noise is generated by adjusting the 
# parameter "a" as follows:
  # a=-2    red or brown(ian) noise (fractal dim.~1.5 - like stock charts)
  # a=-1  pink noise (fractal dim.~1.85)
  # a=0     white noise (output equivalent to y=randn(1,N) IF normalize==0)
  # a=1   blue noise (fractal dim.~2)
  # a=2     violet noise (fractal dim.~2)
  
  
  # More info on each noise color follows:
    # (taken from Zhivomirov's notes)
       #------------------------------------
       # red noise: Aka brown noise. In terms of power at a 
       # constant bandwidth, red noise falls off at 6 dB per 
       # octave. The power spectral density is inversely 
       # proportional to the frequency by factor 1/(f^2), 
       # i.e. the amplitudes are inversely proportional to 1/f.
       
       # pink noise: Aka "1/f noise." The pink noise setting 
       # generates a sequence of pink (flicker) noise samples. 
       # Pink noise has equal energy in all octaves (or similar 
       # log bundles) of frequency. In terms of power at a 
       # constant bandwidth, pink noise falls off at 3 dB per 
       # octave. The power spectral density is inversely 
       # proportional to the frequency by factor 1/f,
       # i.e. the amplitudes are inversely proportional to 1/sqrt(f).
       
       # blue noise: In terms of power at a constant bandwidth, 
       # blue noise increase in at 3 dB per octave. The power 
       # spectral density is proportional to the frequency by 
       # factor f, i.e. the amplitudes are proportional to sqrt(f).
       
       # violet noise: Aka purple noise. In terms of power at a 
       # constant bandwidth, violet noise increase in at 6 dB per
       # octave. The power spectral density is proportional to the 
       # frequency by factor f^2, i.e. the amplitudes are 
       # proportional to f.
       #================================================
       if(rem(n, 2)){n <- n + 1}
       # generate white noise with sigma = 1, mu = 0
       x <- rnorm(n)
       # FFT
       X <- fft(x)
       # prepare a vector for 1/f multiplication
       NumUniquePts <- n / 2 + 1
       ind_left <- 1:NumUniquePts
       # multiply the left half of the spectrum so the power spectral density
       # is inversely proportional to the frequency by factor f^a, i.e. the
       # amplitudes are inversely proportional to f^(a/2)
       X[ind_left] <- X[ind_left] * ind_left^(a / 2)
       # prepare a right half of the spectrum - a copy of the left one,
       # except the DC component and Nyquist frequency - they are unique
       ind_right <- seq(n / 2, 2, -1)
       X[(NumUniquePts + 1):n] <- Re(X[ind_right]) - 1i * Im(X[ind_right]);
       # IFFT
       y <- ifft(X)
       # prepare output vector y
       y <- Re(y[1:n])
       # normalise?
         if(normalize == T){
           y <- y / max(abs(y))
         }
       if(graph == T){
         xplot <- 1:n
         dfplot <- data.frame(output = y, sequence = xplot)
         gg1 <- ggplot(dfplot, aes(x = output)) + geom_density()
         gg2 <- ggplot(dfplot, aes(x = sequence, y = output)) + geom_line()
         grid.arrange(gg1, gg2, ncol = 1)
       }
       return(y)
}

thisT <- 250
randVec <- coloredNoise(n = thisT, a = -2, normalize = F, graph = T)

ts <- cumsum(randVec)
df_plot <- data.frame(randVec, dif = c(NA, diff(randVec)), ts, Time = c(1:thisT)) %>%
  gather(Type, Val, randVec:ts)
#colnames(df_plot)[1:2] <- c("Time", "Project NPV")
gg <- ggplot(df_plot, aes(x = Time, y = Val))
gg <- gg + geom_line()
gg <- gg + facet_wrap(~Type, scales = "free_y", ncol = 1)
gg <- gg + theme_bw()
# gg <- gg + theme(axis.text = element_blank(),
#                  axis.title = element_text(size = axisTitle_size))
gg_gbm <- gg
gg


```


Deductive reasoning. For purposes of project appraisal, time explicit analysis not necessary, not trying to predict NPV in the next period. By definition, we always expect NPV to be the same in the next period as it is in the present period. it is the size distribution of changes in NPV that matter, not the exact order in which changes to NPV occur. lots of small changes interspersed by a few large changes

In any methodological decision, there is usually a tradeoff between realism and expedience. The job of the modeler is thus not merely to maximize realism, but to strike the optimal balance between realism and expedience under the particular time and resource constraints of the modeling exercise at hand, and in a way that is clearly relevant to the particular objectives of the exercise. This is especially true in real world decision making contexts, where constraints are considerably more severe than in academic contexts. And the patience of project donors and managers for arcane technical explanations must be counted among the resources that are in short supply.

Before making costly methodological decisions in the name of realism, then, one must carefully consider 1) to what extent an "increase in realism" is even meaningful, i.e., to what extent it is possible to empirically observe and quantify the reality one aspires to model; 2) whether the proposed increase in realism is actually relevant to the objectives of the modeling exercise, or whether it is just realism for realism's sake; and 3) whether there is a simpler, less costly way to achieve the same increment in realism, or the same modeling objectives which the increment in realism is supposed to serve.
<!-- [One must also be careful of merely replacing one unrealistic artifact with another.]  -->

In the financial context, the reality one aspires to model---i.e. some stochastic financial process, usually a price series---is quantitatively well defined in the form of historical time series that can be easily downloaded, measured, analyzed, etc. In the far-from-market AR4D context, by contrast, analogous historical time series of project NPV generally do not exist. The reality one aspires to model must be perceived indirectly, based primarily on rational assumptions and logic, as I have just done above. So, in far-from-market real options contexts, it is not even clear what one gets in return for sacrificing expedience.

Then there is the question of the relevance of the increase in realism. In the financial context, the relevance of a realistic model of the time evolution of financial securities is clear: it can make the difference between profit and loss. In far-from-market real options contexts, on the other hand, there is no real need for a good predictor of exactly when or in what order specific changes in project NPV occur. The need, rather, is to simulate a time series with a certain size distribution of changes in value. If the model can do this accurately, then it is a good model, regardless of what it looks like in the time domain.

```{r Fig3, fig.show = "hold", fig.width = 5, fig.height=2, fig.align="center", fig.cap="\\label{fig:NPVevol2}(Left) Periodogram of the time series in the left panel of previous figure. (Right) Periodogram of the time series in the right panel of previous figure.", echo = FALSE}

gg_gbmSpec + gg_cppSpec + plot_layout(nrow = 1)

```

<!-- ### In defense of the gBm model of project NPV -->
<!-- [Rejection of the gBm model in ROV contexts is partly inherited from the financial context, where gBm is generally viewed as a naive model of price movements. fat tails--debunked by Tankov, jumps--as discussed above, an artifact of the dam-break model, not a concern in ROV contexts, plus jumps can be closely approximated by gBm. en fin, gBm is much more versatile than it is generally given credit for.] -->
Like Pennings and Lint, many real options authors reject the gBm model, preferring instead to select a model which they perceive to more accurately approximate the real time evolution of project NPV. But this comes at a substantial loss of expedience, as the closed form expression in equation \ref{eq:rov} must be replaced by considerably less tractable and less intelligible expressions, up to and including numerical methods. Trigeorgis once characterized numerical methods as an unavoidable "bitter pill" that every serious ROV practitioner must come to grips with [-@trigeorgis1993real].


<!-- Given all the research and non-research factors affecting project NPV, it is highly unlikely that there is not at least a small, if negligible, perturbation in NPV in every time step, in which case the gBm model is the more realistic choice (when modeling project NPV evolution as it happens, as opposed to the information dam-break approach). -->
<!-- The question is not when changes in NPV occur, but rather how often do substantial changes to NPV occur? In more technical terms, what is the size distribution of changes? In order to answer this question, it is more instructive to look at the signal's periodogram, not its evolution in the time domain. This can be examined by looking at a periodogram. Model 1 can effectively approximate model 2 to an arbitrary degree of precision by tuning the uncertainty parameter $s$ (Figure \ref)..... A few substantial changes followed by relatively long periods of little change. [The Poisson jump model represents a process in which there are a few substantial changes interspersed among periods of no changes at all. While the gbm model cannot replicate periods of no change exactly, it can approximate such periods arbitrarily closely through adjustments to the volatility parameter.... And recall that it is highly unlikely that there are no changes in project value in any given time step, but rather that there may be long periods of very small changes punctuated by brief periods of large changes. This is perhaps best illustrated by looking at periodograms (Figure ...).] -->
<!-- Geometric Brownian motion is a much more versatile model than portrayed in the literature.... "bitter pill" [trigergis]. criticism fat tails etc. starting with Mandelbrot []. but this has led to misconception... [Tankov]. The fact is that gbm remains a highly versatile model capable of representing a wide variety of stochastic processes by adjustments to the volatility parameters. The key question that Pennings and Lint address with their jump model may be formulated as follows: what is the size distribution of changes in project value?  [P&L Poisson jump model output differed from the lognormal assumption output by just x% [P&L].] -->
<!-- [For the purposes of evaluating real option value, the question is not so much when exactly the changes occur, but rather their size distribution. In other words not the time domain but the frequency domain that is important.] -->
<!-- as compared to the default NPV approach -->
<!-- ## Low adoption of real options thinking due to complexity -->
<!-- Despite a flood of academic interest in ROV following Myers' initial insight, adoption of the real options approach by real world decision makers remains low [@horn2015use; @triantis2005realizing; @driouchi2012real]. ROV critics and proponents alike attribute this tepid reception to the formal complexity of evaluating and explaining ROV as compared to the default NPV approach [@triantis2005realizing]. -->
<!-- Much of this complexity can be traced back to two sources. Firstly, there is the frequent and puzzling assumption of risk neutral valuation in far-from-market real options contexts, just mentioned above. Secondly, many authors reject the key assumption that project NPV evolution may be modeled as a gBm, preferring instead to evaluate equation \ref{eq:rovRaw} by numerical methods that are considerably less tractable, transparent, and instructive than equation \ref{eq:rov}. Trigeorgis, for example, calls numerical methods a "bitter pill" that every serious ROV practitioner must come to grips with [@trigeorgis1993real]. -->
<!-- Before deriving the $n$-fold ROV model, it is first necessary to redress these two sources of confusion in detail. It seems safe to say, in hindsight, that energetic ROV proponents like Trigeorgis may have overestimated the appetite for bitterness outside of academic audiences. After this introductory section, I preface the derivation of the $n$-fold ROV model with a defense of the gBm model of project NPV, followed by a repudiation of risk neutral valuation in far-from-market real options contexts. -->
<!--   present arguments in defense of gBm as a model of far-from-market project NPV. In particular, I note that the a as a much more versatile model than it is given credit for. -->
<!-- Secondly, there is confusion regarding the interpretation, in real options contexts, of the financial artifact known as "risk-neutral valuation". -->
<!-- (see, for example, Hayes and Garvin [@hayes1982managing], McGrath and MacMillan [@mcgrath2000assessing], Doctor, Newton, and Pearson [@doctor2001managing], and Newton, Paxson, and Widdicks [@newton2004real]), -->
<!-- [However, the question of where ... must be assessed on a case by case basis. is a matter of preference. In academic contexts, there is a premium on rigor and realism. Most real options settings, on the other hand, time, resources, patience, and attention-span are in relatively short supply ... there is a premium on transparency, expediency. Pennings and Lint use equation \ref{eq:rov} and find that the numerical method output differs by just x%. That is a lot of extra work for a negligible difference. Whether or not changes occur in every time step is a matter of judicious choice of time step. In most real options settings, changes might not occur every day or every week or even every month, but probably do occur at least once every quarter. Moreover, such meticulous realism quickly lands the practitioner in other problems. In most real options settings, the research, analysis, and reporting protocols by which new information affecting project NPV becomes available occur at predetermined, non-random intervals, whereas the CP model is only valid for events occurring at random intervals. The order of changes in NPV is irrelevant. It is the size distribution of changes that matters, not when they occur. The frequency domain is what matters, not the time evolution.] -->
<!-- # It's ok to be lognormal -->
<!-- When taking a real options approach to project evaluation, it becomes necessary to think carefully about the evolution of project NPV over the life of the project. -->
<!-- Many consider the assumption of lognormally distributed NPV unrealistic. This is to some degree rooted in the original financial context, where the assumption of lognormal security returns is widely viewed as naive... -->
<!-- Bibby and Sorensen [@bibby1996hyperbolic] -->
<!-- Pennings and Lint []. .  misconception [Tankov]. -->

# Formal derivation of multi-stage ROV in the AR4D context

With a studious avoidance of financial/corporate ROV foundations out of the way, we may commence with the formal derivation of a multi-stage ROV model on foundations suitable to the AR4D context.

Compared to the financial and corporate contexts, the foundations required in the AR4D context are few. The only assumption is that project NPV follows a gBm, which, as explained above, is tantamount to assuming that the evolution of project NPV is characterized by a small number of substantive changes interspersed by a large number of negligibly small changes.

The expected growth rate of project NPV follows from the definition of project NPV, and need not be assumed or derived from assumptions. That is to say, by definition, project NPV includes any expected changes in value, such that the expected growth rate is just the rate at which it is discounted back to the present.

...what other assumptions?...assumption that expected growth rate of ROV is also r? or is this definitional?

## Derivation of 1 stage ROV

<!-- # Method (Replacement of financial foundations with AR4D foundations) -->
<!-- Project NPV $x(t)$ is defined as all AR4D project net benefits discounted back to the present time $t$. Assuming $x(t)$ follows a gBm, then its evolution $\Delta x$ over a small time increment $\Delta t$ is described by -->
Project NPV $x(t)$ is defined as post-R&D project net benefits discounted back to the completion and release of the research product at time $T_0 > 0$, typically determined by ex-ante impact assessment. Time $t = 0$ is the time of the assessment. Assuming $x(t)$ follows a gBm, then its evolution $\Delta x$ over a small time increment $\Delta t$ is described by

\begin{equation}
\Delta x = x(t) m \Delta t + x(t) s \epsilon \sqrt{\Delta t} \:\:;\:\:\: \Delta x := x(t + \Delta t) - x(t)
\label{eq:gbmEq}
\end{equation}

Where $\epsilon$ is a normally distributed random variable with mean $0$ and variance $1$, such that $m$ and $s$ quantify the trend and volatility of the time evolution, respectively.

\begin{equation}
\begin{split}
m \Delta t &= E \left[\frac{\Delta x}{x} \right] \\
s^2 \Delta t &= Var \left[\frac{\Delta x}{x} \right]
\end{split}
\end{equation}

In other words, $m \Delta t$ and $s^2 \Delta t$ are the mean and variance of the instantaneous arithmetic return or growth rate. The expected value of project NPV at some future time $\tilde{t}$ ($t < \tilde{t}$) as evaluated at time $t$ is given by

\begin{equation}
E[x(\tilde{t})]\bigr|_{t < \tilde{t}} = e^{m \tau} x(t) \:\:;\:\:\: (\tau = \tilde{t} - t)
\label{eq:ExTt}
\end{equation}

And the mean and variance of the log return over any finite interval $\tau$ is given by

\begin{equation}
E \left[ \ln \left(\frac{x(\tilde{t})}{x(t)} \right) \right]\biggr|_{t < \tilde{t}}  = \left(m - \frac{s^2}{2} \right) \tau
\label{eq:meanLn}
\end{equation}

\begin{equation}
Var \left[ \ln \left(\frac{x(\tilde{t})}{x(t)} \right) \right]\bigrr|_{t < \tilde{t}} = s^2 \tau
\end{equation}

(See Hull [-@hull9thEdition] for details.)

Since the calculation of project NPV already accounts for all expected changes to NPV that might occur over the time horizon, then, by definition, the expected growth rate of project NPV is just the discount rate ($m = r$). Considering the definition in Equation \ref{eq:basic}, it follows immediately that the expected growth rate of ROV is also $r$.

The 1 stage ROV equation follows by evaluating Equation \ref{eq:basic} through straightforward integration.

In general, for a lognormally distributed random variable $q$ and a constant $C$,

\begin{equation}
E[\max(q - C, 0)] = E[q] \Phi \left(\frac{\ln \left( \frac{E[q]}{C} \right) + \frac{\omega^2}{2}}{\omega} \right) - C \Phi \left(-\frac{\ln \left( \frac{E[q]}{C} \right) - \frac{\omega^2}{2}}{\omega} \right)
\label{eq:genEq}
\end{equation}

(See Appendix for proof.)

In the case where $q = x(T_0)$, $C = K_0$, and multiplying through by the discount factor $e^{-t \tau_0}$, this becomes

\begin{equation}
e^{-r \tau} E[\max(x(\tilde{t}) - K_0, 0)]\bigr|_{t < T} = x(t) \Phi(\delta + s \sqrt{\tau}) - e^{-r \tau} K \Phi(\delta)
\label{eq:rov}
\end{equation}

Where

\begin{equation}
\delta = \frac{ \ln \left(\frac{x(\hat{t})}{K} \right) - \left(r - \frac{s^2}{2} \right) \tau} {s \sqrt{\tau}}
\end{equation}


## Relation to the Black-Scholes derivation

Geometric Brownian motion is a particular case of a broader category of stochastic processes known as Ito processes, defined as follows.

\begin{equation}
\Delta x = a(x, t) \Delta t + b(x, t) \epsilon \sqrt{\Delta t}
\end{equation}

Where $a$ and $b$ are functions of $x$ and $t$.
<!-- In the present case where $x(t)$ is project NPV, $a = x(t) r$ -->

Ito's lemma states that the evolution of a function $f(x, t)$ is also an Ito process, described as follows.

\begin{equation}
\Delta f = \left( x a \frac{\partial f}{\partial x} + \frac{\partial f}{\partial t} + \frac{b^2}{2} \frac{\partial^2 f}{\partial x^2} \right) \Delta t + \frac{\partial f}{\partial x} b \epsilon \sqrt{\Delta t}
\end{equation}

In the present case, where $x(t)$ is a gBm with $a = x r$, $b = x s$, Ito's lemma reduces to

\begin{equation}
\Delta f = \left( x r \frac{\partial f}{\partial x} + \frac{\partial f}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f}{\partial x^2} \right) \Delta t + \frac{\partial f}{\partial x} x s \epsilon \sqrt{\Delta t}
\label{eq:itoLem}
\end{equation}

It follows that the expected growth rate and growth rate variance of $f$ is

\begin{equation}
E\left[ \frac{\Delta f}{f} \right] = \frac{1}{f} \left( x r \frac{\partial f}{\partial x} + \frac{\partial f}{\partial t} + \frac{s^2}{2}  x^2 \frac{\partial^2 f}{\partial x^2} \right) \Delta t
\label{eq:Ef1}
\end{equation}

\begin{equation}
Var\left[ \frac{\Delta f}{f} \right] = \frac{\partial f}{\partial x} x s \Delta t
\end{equation}

(See Hull [-@hull9thEdition] for details.)

The function $f(x, t)$ we have in mind here is, of course, ROV. Black and Scholes [-@black1973valuation] famously noted that equations \ref{eq:gbmEq} and \ref{eq:itoLem} could be combined so as to eliminate the random term as follows.

\begin{equation}
\Delta f - \frac{\partial f}{\partial x} \Delta x = \left(\frac{\partial f}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f}{\partial x^2} \right) \Delta t
\label{eq:bsInsight}
\end{equation}

In the financial context, the left-hand side of this equation may be thought of as the instantaneous evolution over the increment $\Delta t$ of a portfolio long one share of the financial derivative $f$ and short a quantity $\partial f / \partial x$ of the underlying security $x(t)$. This is where Black and Scholes applied their no-arbitrage argument: Since the random---i.e. risky---term has been eliminated from equation \ref{eq:bsInsight}, then the profit or loss of this portfolio over the increment $\Delta t$ must be riskless. That is, it must change at the risk free rate $r$.

\begin{equation}
\Delta f - \frac{\partial f}{\partial x} \Delta x = \left( f - \frac{\partial f}{\partial x} x \right) r \Delta t
\label{eq:BSarb}
\end{equation}

Equating the right-hand side of this equation with the right-hand side of the previous equation, the $\Delta t$'s cancel, resulting in the Black-Scholes partial differentiation equation (PDE).

\begin{equation}
\left(f - \frac{\partial f}{\partial x} x \right) r = \frac{\partial f}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f}{\partial x^2}
\end{equation}

Or, rearranging,

\begin{equation}
fr = \frac{\partial f}{\partial x} x r + \frac{\partial f}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f}{\partial x^2}
\end{equation}

Black and Scholes then go on to solve this PDE for $f$ under the boundary condition $f(T) = \max(x(T) - K, 0)$, resulting in the same expression obtained above in Equation \ref{eq:rov}. (See Appendix for details.)

<!-- \begin{equation} -->
<!-- e^{-r\tau} E[\max(x(\tilde{t}) - K, 0)]\bigr|_{t = \hat{t}} = x(\hat{t}) \Phi(\delta + s \sqrt{\tau}) - e^{-r \tau} K \Phi(\delta) -->
<!-- \label{eq:BSov} -->
<!-- \end{equation} -->

<!-- Where -->

<!-- \begin{equation} -->
<!-- \delta = \frac{1}{s \sqrt{\tau}} \left(\ln \left(\frac{x(\hat{t})}{K} \right) - \left(r - \frac{s^2}{2} \right) \tau \right) -->
<!-- \end{equation} -->

<!-- Note the similarity between this and the AR4D ROV expression derived in Equation \ref{eq:rov}. The two expressions are equivalent when evaluated at $r = s^2 / 2$, which implies risk adjusted discounting. -->
<!-- <!-- This bears some emphasis: Risk adjusted discounting equalizes the financial and AR4D option value problems, implying that markets are irrelevant -->
<!-- The same PDE is obtained if the expected growth rates of $f$ and $x$ are both $r \Delta t$ (as is the case in the AR4D context, where $r$ is the discount rate). This is why the Black-Scholes no arbitrage argument implies risk neutral valuation in financial contexts, where $r$ is the risk-free rate of return. -->

The ROV expression may also be derived from Ito's lemma using logic that is suitable to the AR4D context. Instead of 

It is possible to obtain the Black-Scholes PDE by replacing the no-arbitrage logic behind Equation \ref{eq:BSarb} with logic that is suitable to the AR4D context. As mentioned in the previous section, in the AR4D context the expected growth rate of both project NPV ($x$) and ROV ($f$) is, by definition, $r \Delta t$. Making the relevant substitutions in Equation \ref{eq:Ef1} results in the Black-Scholes PDE.

In preparation for the extension to multi-stage projects, note that since the expected growth rate of ROV is $r\Delta t$, the evolution $\Delta f$ defined in Equation \ref{eq:itoLem} may be rewritten

\begin{equation}
\Delta f = f r \Delta t + f \eta_{1,0} s \epsilon \sqrt{\Delta t}
\end{equation}

Where the shorthand $\eta_{1,0} = \frac{x}{f} \frac{\partial f}{\partial x}$ has been introduced.

While the Ito calculus is not necessary for the derivation of the ROV functional form, it is instructive because it demonstrates that ROV itself follows an Ito process, and is thus lognormally distributed with log return mean and variance

\begin{equation}
E\left[\left( \frac{f(\tilde{t})}{f(t)} \right) \right]\bigr|_{t < \tilde{t}} = \left(r - \eta_{1,0}^2 \frac{s^2}{2} \right) \tau
\end{equation}

\begin{equation}
Var\left[\left( \frac{f(\tilde{t})}{f(t)} \right) \right]\bigr|_{t < \tilde{t}} = \eta_{1,0}^2 s^2 \tau
\end{equation}

Which is very useful when extending ROV to multi-stage projects.

## Extension to multi-stage ROV

Because $f$ is itself lognormally distributed, the same formula used to evaluate the ROV of $x(T_0)$ (Equation \ref{eq:genEq}) can be used to evaluate the ROV of $f(T_1)$, where $T_1 < T_0$ is the time when the investor must decide whether or not to invest in the last stage of research. That is to say, letting $g(f, t)$ denote the ROV of $f(T_1)$, then 

\begin{equation}
g(f, t) = e^{-r \tau_1} E[\max(f(T_1) - K_1, 0)]\bigr|_{t < T_1} = f(t) \Phi(\delta_1 + \eta_{1,0} s \sqrt{\tau_1}) - e^{-r \tau_1} K_1 \Phi(\delta_1)
\label{eq:rov2stage}
\end{equation}

Where $K_1$ is the research investment required at time $T_1$, $\tau_1 = T_1 - t$, and

\begin{equation}
\delta_1 = \frac{ \ln \left(\frac{f(t)}{K_1} \right) - \left(r - \eta_{1,0}^2 \frac{s^2}{2} \right) \tau_1} {\eta_{1,0} s \sqrt{\tau_1}}
\end{equation}

Moreover, because $f$ is an Ito process and $g$ is a function of $f$, then by Ito's lemma, $g$ is also an Ito process,

\begin{equation}
\Delta g = \left( x r \frac{\partial g}{\partial f} + \frac{\partial g}{\partial t} + \frac{s^2 f^2}{2} \frac{\partial^2 g}{\partial f^2} \right) \Delta t + \frac{\partial g}{\partial f} f \eta_{1,0} s \epsilon \sqrt{\Delta t}
\label{eq:itoLem}
\end{equation}

With expected growth rate and growth rate variance

\begin{equation}
E\left[ \frac{\Delta g}{g} \right] = \frac{1}{g} \left( f r \frac{\partial g}{\partial f} + \frac{\partial g}{\partial t} + \eta_{1,0}^2 \frac{s^2}{2} x^2 \frac{\partial^2 g}{\partial f^2} \right) \Delta t
\label{eq:Ef2}
\end{equation}

\begin{equation}
Var\left[ \frac{\Delta g}{g} \right] = \eta_{2,0}^2 s^2 \Delta t \:\:;\:\:\: \eta_{2,0} = \frac{f}{g} \frac{\partial g}{\partial f} \eta_{1, 0}
\end{equation}

Because the expected growth rate of $f$ is $r \Delta t$, then so must be the expected growth rate of $g$, such that Equation \ref{eq:Ef2} may be set equal to $r \Delta t$, resulting in a Black-Scholes PDE for $g$.

\begin{equation}
rg = f r \frac{\partial g}{\partial f} + \frac{\partial g}{\partial t} + \eta_{1,0}^2 \frac{s^2}{2} x^2 \frac{\partial^2 g}{\partial f^2}
\end{equation}

Which may then be solved for $g$ under the boundary condition $g(T_1) = \max(f(T_1) - K_1, 0)$ as another way of obtaining Equation \ref{eq:rov2stage}.

It follows, moreover, that $g$ is lognormally distributed with log return mean and variance

\begin{equation}
E\left[\left(\frac{g(\tilde{t})}{f(t)} \right) \right]\bigr|_{t < \tilde{t} \leq T_1} = \left(r - \eta_{2,0}^2 \frac{s^2}{2} \right) \tau_1
\end{equation}

\begin{equation}
Var\left[ \left( \frac{f(\tilde{t})}{f(t)} \right) \right]\bigr|_{t < \tilde{t} \leq T_1} = \eta_{2,0}^2 s^2 \tau_1
\end{equation}

Such that the same process can be repeated for a function $h(g, t)$ to obtain the ROV of $g(T_2)$, where $T_2$ is the time when the investor must decide whether or not to invest in the penultimate stage of research.
<!-- , and so on for functions $j(h, t)$, $k(j, t)$, ad infinitum. -->

Relabeling $x$ as $f_0$, $f$ as $f_1$, $g$ as $f_2$, $h$ as $f_3$, and so forth, a general formula for the ROV $f_i$ of research stage $f_{i-1}$ may be written as follows

\begin{equation}
f_i(f_{i - 1}, t) = e^{-r \tau_{i - 1}} E[\max(f(T_{i - 1}) - K_{i - 1}, 0)]\bigr|_{t < T_{i - 1}} = f_{i - 1}(t) \Phi(\delta_{i - 1} + \eta_{i - 1, 0} s \sqrt{\tau_{i - 1}}) - e^{-r \tau_{i - 1}} K_{i - 1} \Phi(\delta_{i - 1}) \:\:;\:\:\: i \in \mathbb{Z}
\label{eq:ROVi}
\end{equation}

Where $K_{i - 1}$ is the investment required at time $T_{i - 1}$, $\tau_i = T_{i - 1} - t$, and

\begin{equation}
\eta_{i,0} = \frac{f_{i - 1}}{f_i} \frac{\partial f_i}{\partial f_{i - 1}} \eta_{i -1, 0} \:\:;\:\:\: \eta_{0,0} = 1
\end{equation}

\begin{equation}
\delta_{i - 1} = \frac{ \ln \left(\frac{f_{i - 1}(t)}{K_{i - 1}} \right) - \left(r - \eta_{i - 1, 0}^2 \frac{s^2}{2} \right) \tau_{i - 1}} {\eta_{i - 1, 0} s \sqrt{\tau_{i - 1}}}
\end{equation}

For all $i$, the expected growth rate of $f_i$ is, by definition, $r \Delta t$. By Ito's lemma, the growth rate variance of $f_i$ is $\eta_{i, 0}^2 s^2 \Delta t$, and $f_i$ is lognormally distributed with log return mean and variance

\begin{equation}
E\left[\ln \left(\frac{g(\tilde{t})}{f(t)} \right) \right]\bigr|_{t < \tilde{t} \leq T_{i - 1}} = \left(r - \eta_{i,0}^2 \frac{s^2}{2} \right) \tau_{i - 1}
\end{equation}

\begin{equation}
Var\left[\left( \frac{f(\tilde{t})}{f(t)} \right) \right]\bigr|_{t < \tilde{t} \leq T_{i - 1}} = \eta_{i,0}^2 s^2 \tau_{i - 1}
\end{equation}

The quantity $\Phi(\delta_{i - 1})$ is instructive. It is the probability that $f_{i - 1}$ will equal or exceed $K_{i - 1}$ by time $T_{i - 1}$, thus triggering investment in the subsequent stage. In financial parlance, it is the probability that $f_i$ will finish "in the money".

The quantity $\eta_{i, 0}$ is also instructive. It is the elasticity of ROV $f_i$ with respect to project NPV $x$, and can thus be used as a measure of how senstitive the value of an investment in any stage of research is with respect to changes in the underlying project NPV. Calculation of $\eta_{i, 0}$ requires calculation of $\partial f_i / \partial f_{i - 1}$, which works out as follows.

\begin{equation}
\frac{\partial f_i}{ \partial f_{i - 1}} = \Phi( \delta_{i - 1} + \eta_{i - 1, 0} s \sqrt{\tau_{i - 1}}) + \frac{\partial \eta{i- 1, 0}}{ \partial f_{i - 1}} f_{i - 1} \phi(\delta_{i - 1} + \eta_{i - 1, 0} s \sqrt{\tau_{i - 1}})
\end{equation}

Where

\begin{equation}
\frac{\partial \eta{i- 1, 0}}{ \partial f_{i - 1}} =
\begin{cases} \frac{\partial}{\partial f_{i - 1} \left(1\right) = 0 &, i = 1 \\
\frac{\partial}{\partial f_{i - 1} \left(\frac{f_{i - 2}}{f_{i - 1}} \frac{\partial f_{i - 1}}{\partial f_{i - 2}} \right)} = f_{i - 2} \frac{\partial f_{i - 1}}{\partial f_{i - 2}} \frac{\partial}{\partial f_{i - 1} \left(\frac{1}{f_{i - 1}} \right)} = -\frac{\eta_{i - 1}}{f_{i - 1}} &, i > 1
\end{cases}
\end{equation}

The stage 1 ROV of an $n > 1$ stage project is recursively calculated, starting with $f_1$. 

# An illustrative example
<!-- of real option valuation of a multi-stage AR4D project -->

As an illustrative example, below we apply the formula developed above to calculate the ROV of a real multi-stage AR4D project currently in implementation. The aim of the project in question is to develop a transgenic potato variety with resistance to Late Blight disease (henceforth LBr potato), for release as a public good in two developing countries. Late Blight is the disease behind the infamous Irish Potato Famine of 1845-1849; and continues to pose a major threat to food security, especially in the developing world [@haverkort2008societal; @fry2008phytophthora]. Successful research and development of LBr potato varieties adapted to local environments is thus a potentially very high reward, disruptive proposition. It is also a high risk proposition, facing numerous research and non-research related challenges, not least of which is a strong "anti-GM" lobby in many of the target populations.

The LBr potato project is structured in four consecutive stages. These stages and their associated costs and time durations are summarized in Table x, based on figures documented by Schiek et al. [-@schiek2016demys]. All values are given in terms of current US dollars. This is a purely pedagogical exercise designed to illustrate the use of the multi-stage ROV model derived in the previous sections. While the exercise is based on real project stage costs and time horizons, the other parameter values are hypothetical. The resulting calculations should therefore not be interpreted as an authoritative valuation of LBr potato research.
<!-- structure described in section \ref{sec:resStages}. The costs and time duration associated with each stage are summarized in Table 1,  -->
<!-- Costs are assessed as the sum of staff costs, direct operating costs (including lab bench costs), indirect operating costs (overhead), external contract costs, and stewardship costs. -->

```{r, echo = FALSE}
# Define functions
#----------------------------------------------------------------------------
# Table formatting function
FitFlextableToPage <- function(ft, pgwidth = 6){
  
  ft_out <- ft %>% autofit()
  #these_colWidths <- dim(ft_out)$widths * pgwidth  / (flextable_dim(ft_out)$widths)
  these_colWidths <- dim(ft_out)$widths
  these_colWidths[5] <- these_colWidths[1] * 1.5
  #these_colWidths[6] <- these_colWidths[6] * 0.7
  these_colWidths <- these_colWidths * pgwidth  / (flextable_dim(ft_out)$widths)
  ft_out <- width(ft_out, width = these_colWidths)
  return(ft_out)
}

#============================================================================
#============================================================================
# End function definition
#============================================================================
#============================================================================
# Project stage time durations and costs
# (Values given in chronologically reverse order, starting with stage n.)
# Kvec[1] is the launch cost, Tvec[1] is the launch duration.
# Time durations given in years, multiplied by 4 to convert to quarters.
# MSU/cornell
# Tvec <- c(2, 3.5, 1, 2, 4) * 4
# Kvec <- c(300000, 200000, 400000, 400000, 530000)
Tvec <- c(2, 3, 0.85, 1.7, 3.4) * 4
Kvec <- c(250000, 181000, 312000, 336000, 530000)
# Kvec <- c(180541, 311974, 335530, 530250)
# CIP
# Kvec <- c(52000, 213000, 396000, 929000)
# Tvec <- c(1, 0.25, 2, 4.75) * 4
#----------------------------------------------------------------------------
# Create table summarizing stage costs, time durations, and descriptions
stage1desc <- "Basic replication and scaling up"
stage2desc <- "Multi-location/season testing"
stage3desc <- "Compilation of the regulatory dossier"
stage4desc <- "Deregulation"
launchDesc <- "Launch in 2 countries"
descVec <- c(stage1desc, stage2desc, stage3desc, stage4desc, launchDesc)

df_table <- data.frame(Stage = c(1:4, "Launch"),
                       Kn = rev(Kvec),
                       Duration = rev(Tvec),
                       DurationCum = cumsum(rev(Tvec)),
                       Description = descVec)

colnames(df_table)[2:4] <- c("Cost\n(USD)", "Duration\n(annual quarters)", "Cumulative\nduration")

#df_table <- regulartable(df_table)
#df_table
#df_table <- width(df_table, width = 0.7)
table_title <- "Project to research and develop Late Blight resistant potato for release as a public good in 2 developing countries."
table_caption <- "Stage 1-4 costs and durations based on figures reported by Schiek et al. (2016). The launch cost and duration is hypothetical."

#df_table <- FitFlextableToPage(df_table)
# df_table <- add_header_lines(df_table, table_title)
# df_table <- add_footer_lines(df_table, table_caption)
# modifiedColnames <- colnames(df_table)
# modifiedColnames[3] <- "Duration\n(annual quarters)"
df_table %>%
  knitr::kable(
    format = "latex",
    caption = table_title,
    align = "l",
    booktabs = T,
    #longtable = T,
    linesep = " ",
    escape = F
  ) %>%
  kableExtra::kable_styling(
    position = "left",
    latex_options = c("scale_down", "striped", "repeat"),
    full_width = F,
    stripe_color = "gray!15"
  ) %>%
  # kableExtra::column_spec(column = 3:4, width = "1.5in"
  # ) %>%
  kableExtra::footnote(
    general = table_caption)
# number = c("Footnote 1; ", "Footnote 2; "),
# alphabet = c("Footnote A; ", "Footnote B; "),
# symbol = c("Footnote Symbol 1; ", "Footnote Symbol 2"))

# print_this_table <- function(df_table){
# df_table <- regulartable(df_table)
# df_table <- width(df_table, width = 5.5)
# # df_table <- FitFlextableToPage(df_table)
# 
# df_table %>% #regulartable() %>% autofit() %>%
#   valign(valign = "top", part = "all") %>%
#   align(align = "left", part = "all") %>%
#   fontsize(i = NULL, j = NULL, size = 9, part = "body") %>%
#   fontsize(i = NULL, j = NULL, size = 10, part = "header")
#   
# }


```

The donor, USAID, originally awarded the LBr potato research contract to Cornell University in 2010, with planned release in India. However, stage 1 research and development at Cornell was unsuccessful. In 2015, USAID transferred the contract to Michigan State University (MSU), which proposed a different stage 1 research strategy, with planned release in Bangladesh and Indonesia instead of India. India was dropped as a target country partly because of the vigorous anti-GM lobby there, which made stage 4 success unlikely. MSU completed stage 1 successfully in 2019, and a couple years later USAID awarded them a new contract for stage 2 research and development.
<!-- and extended the list of countries targeted for release of LBr potato to include Kenya and Nigeria. The evolution of LBr project NPV may thus be characterized as a handful of substantive changes, due to unexpected shifts in research and non-research related factors, interspersed by a much larger number of negligibly small changes. At the time of writing, stage 2 research is successfully nearing completion [pers correspondence]. -->

In real options language, USAID bought an option on stage 2 LBr potato research when it awarded the original contract to Cornell; but this option expired out of the money at the end of stage 1. USAID then again bought an option on stage 2 research when it transferred the contract to MSU. This time, the option expired in the money, triggering investment in stage 2 research. The investment in stage 2 research is an option on stage 3.
<!-- , and is now approaching expiry in the money. -->

In the present exercise, we calculate the ROV of the USAID LBr potato contract awarded to MSU in 2015. This is the value of USAID's option, but not obligation, to fund stage 2 once stage 1 is complete. The exercise is conducted from the donor's perspective in the months prior to the "go/no-go" stage 1 investment decision.

```{r, fig.show = "hold", fig.width = 4, fig.height=3, fig.align="left", fig.cap="\\label{fig:netBens}", echo = FALSE}
# Define functions
get_di <- function(K_im1, f_im1, tau_i, m, s, eta_im10 = 1){
  d_i <- (log(f_im1 / K_im1) + (m - eta_im10^2 * s^2 / 2) * tau_i) / (s * eta_im10 * sqrt(tau_i))
  return(d_i)
}
ROVi <- function(K_im1, f_im1, tau_i, m, s, eta_im10 = 1){
  d_i <- get_di(K_im1, f_im1, tau_i, m, s, eta_im10)
  u <- d_i + eta_im10 * s * sqrt(tau_i)
  rov <- f_im1 * pnorm(u) - exp(-r * tau_i) * K_im1 * pnorm(d_i)
  probSuc <- pnorm(d_i)
  return(c(rov, probSuc))
}
get_dfidfim1 <- function(K_im1, f_im1, f_i, tau_i, m, s, eta_im10 = 1){
  d_i <- get_di(K_im1, f_im1, tau_i, m, s, eta_im10)
  u <- d_i + eta_im10 * s * sqrt(tau_i)
  if(eta_im10 == 1){dEtaim10dfim1 <- 0}else{dEtaim10dfim1 <- -eta_im10 / f_im1}
  dfidfim1 <- pnorm(u) + dEtaim10dfim1 * s * sqrt(tau_i) * f_im1 * dnorm(u)
  if(abs(dfidfim1) < 10^-10){dfidfim1 <- 0}
  return(dfidfim1)
}
ROVn <- function(X0, Kvec, tauVec, m, s){
  f_im1 <- X0; eta_im10 <- 1
  n <- length(Kvec)
  fiOut <- c(); etaOut <- c(); probSucVec <- c()
  for(i in 1:n){
    tau_i <- tauVec[i]; K_im1 <- Kvec[i]
    outROVi <- ROVi(K_im1, f_im1, tau_i, m, s, eta_im10)
    f_i  <- outROVi[1]; probSuc <- outROVi[2]
    dfidfim1 <- get_dfidfim1(K_im1, f_im1, f_i, tau_i, m, s, eta_im10)
    eta_i0 <- f_im1 / f_i * dfidfim1 * eta_im10
    fiOut[i] <- f_i; etaOut[i] <- eta_i0; probSucVec[i] <- probSuc
    f_im1 <- f_i; eta_im10 <- eta_i0
  }
  return(data.frame(f_i = fiOut, eta_i0 = etaOut, probSuc = probSucVec))
}
rootROVn <- function(X0, Kvec, tauVec, mm, s, stage1Invest){
  dfOut <- ROVn(X0, Kvec, tauVec, mm, s)
  f_n <- dfOut$f_i[nrow(dfOut)]
  slack <- f_n - stage1Invest
  return(slack)
}
#===============================================================================
#2013 potato VoP 2014-2016 constant USD
VoPIndonesia <- 0.8 #Indonesia: 0.8 billion
VoPBangladesh <- 1.6 #Bangladesh 1.6 billion
VoPKenya <- 0.8 #Kenya: 0.8 billion
VoPNigeria <- 0.5 #Nigeria: 0.5 billion
VoPvec <- c(VoPIndonesia, VoPBangladesh, VoPKenya, VoPNigeria)
# VoPtot <- sum(VoPvec)
# VoPpot <- VoPtot / 0.9
# yrlyLoss <- VoPpot - VoPtot
thisVoP <- VoPNigeria
VoPpot <- thisVoP / 0.9
yrlyLoss <- VoPpot - thisVoP
yrlyLoss
# yrlyLoss <- VoPpot * 0.15 #billion
#yrlyLoss <- VoPIndonesia / 0.9 *  #billion
#===============================================================================
# Define discount rate
rYrly_discrete <- 0.12 #0.035
rQrly_discrete <- (1 + rYrly_discrete)^(1 / 4) - 1
rYrly <- round(log(1 + rYrly_discrete), 3)
r <- round(log(1 + rQrly_discrete), 3)
#===============================================================================
# Stage time duration params
# Stage durations - last stage first
# periodDurations <- c(3, 4, 2, 3) * 4
# tauVec <- rev(cumsum(periodDurations))
TvecYrs <- c(4, 2, 4, 4); TvecQtrs <- TvecYrs * 4 # last first
#TvecYrs <- c(3, 1, 2, 4); TvecQtrs <- TvecYrs * 4 # last first
tauVecYrs <- rev(cumsum(TvecYrs)); tauVecQrs <- rev(cumsum(TvecQtrs))
stage1Invest <- 530000
Kvec <- c(500000, 181000, 312000, 336000) # Last stage first
#Kvec <- 1 * c(500000, 200000, 400000, 400000) # Last stage first
#===============================================================================
# Calculate project NPV(Tn) i.e. X0
yrHoriz <- 15; qtrHoriz <- yrHoriz * 4
t <- seq(0, qtrHoriz, length.out = qtrHoriz + 1)
alphaYrly_discrete <- 0.65
alphaQrly_discrete <- (1 + alphaYrly_discrete)^(1 / 4) - 1
alphaQrly <- round(log(1 + alphaQrly_discrete), 3)
dNVT0ref <- 0.15; tRef <- 8
dNVT0 <- dNVT0ref * (t / tRef)^alphaQrly
dNPVT0_discrete <- dNVT0 / (1 + rQrly_discrete)^t
#dNPVT0_discrete <- dNVT0 / (1 + rYrly_discrete)^t
dNPVT0_contin <- exp(-r * t) * dNVT0
#dNPVT0_contin <- exp(-rYrly * t) * dNVT0
library(expint)
A <- dNVT0ref * tRef^(-alphaQrly)
NPVT0 <- A / r^(1 + alphaQrly) * exp(r * tauVecQrs[1]) * (-gammainc(1 + alphaQrly, r * (tauVecQrs[1] + t)) + gammainc(1 + alphaQrly, tauVecQrs[1]))
NPVT0_discrete <- cumsum(dNPVT0_discrete)
NPV0_discrete <- exp(-r * tauVecQrs[1]) * NPVT0_discrete
NPV0 <- exp(-r * tauVecQrs[1]) * NPVT0
#NPV0 <- exp(-rYrly * tauVecYrs[1]) * NPVT0
# plot(t, dNVT0)
# plot(t, dNPVT0)
# plot(t, NPVTn)
#-------------------------------------------------------------------------------
nbCutoffYr <- 15 # Net benefit cutoff year
nbCutoffQtr <- nbCutoffYr * 4
X0 <- NPV0[nbCutoffQtr] * 10^6
#-------------------------------------------------------------------------------
# Plot dNV, dNPV, NPV
library(patchwork)
# Set graphic parameters
axisTitleSize <- 8
axisTextSize <- 7
legendKeySize <- 0.3
legendTextSize <- axisTextSize
facetTitleSize <- axisTextSize
plotTitleSize = axisTextSize
labelSize <- 2
# Organize plot data into data frames
dfdNVT0 <- data.frame(Quarter = t, `Undiscounted net benefits` = dNVT0)
dfdNPVT0 <- data.frame(Quarter = t,
                      `Annually discounted net benefits` = dNPVT0_discrete,
                      `Continuously discounted net benefits` = dNPVT0_contin)
dfNPVT0 <- data.frame(Quarter = t, NPV = NPVT0)
# Plot undiscounted net benefits
colnames(dfdNVT0)[2] <- "Undiscounted net benefits\n(million USD)"
gg <- ggplot(dfdNVT0, aes(x = Quarter, y = `Undiscounted net benefits\n(million USD)`))
gg <- gg + geom_bar(stat = "identity")
gg <- gg + scale_x_continuous(breaks = seq(0, qtrHoriz, 4),
                              labels = seq(0, yrHoriz, 1))
gg <- gg + labs(x = "Years from release", title = "(a)")
gg <- gg + theme_bw()
gg <- gg + theme(axis.text = element_text(size = axisTextSize),
                 axis.title = element_text(size = axisTitleSize),
                 plot.title = element_text(size = axisTitleSize))
gg1 <- gg
# Plot discounted net benefits
colnames(dfdNPVT0)[-1] <- c("Annually discounted net benefits\n(million USD)",
                           "Continuously discounted net benefits\n(million USD)")
gatherCols <- colnames(dfdNPVT0)[-1]
#dfdNPVT0 <- dfdNPVT0 %>% gather_("type", "val", gatherCols)
gg <- ggplot(dfdNPVT0, aes(x = Quarter, y = `Continuously discounted net benefits\n(million USD)`))
gg <- gg + geom_bar(stat = "identity")
gg <- gg + scale_x_continuous(breaks = seq(0, qtrHoriz, 4),
                              labels = seq(0, yrHoriz, 1))
gg <- gg + labs(x = "Years from release", title = "(b)")#, y = "Discounted net benefits\n(million USD)")
gg <- gg + theme_bw()
gg <- gg + theme(axis.text = element_text(size = axisTextSize),
                 axis.title = element_text(size = axisTitleSize),
                 plot.title = element_text(size = axisTitleSize))
gg2 <- gg
# Plot NPV
gg <- ggplot(dfNPVT0, aes(x = Quarter, y = NPV))
gg <- gg + geom_bar(stat = "identity")
gg <- gg + scale_x_continuous(breaks = seq(0, qtrHoriz, 4),
                              labels = seq(0, yrHoriz, 1))
gg <- gg + labs(x = "Years from release", y = "NPV\n(million USD)", title = "(c)")
gg <- gg + theme(axis.text = element_text(size = axisTextSize),
                 axis.title = element_text(size = axisTitleSize),
                 plot.title = element_text(size = axisTitleSize))
gg <- gg + theme_bw()
gg3 <- gg

(gg1 + gg2) / gg3
#===============================================================================
# Define project NPV volatility:
cv <- 1.5
s <- cv * r * sqrt(tauVecQrs[1])
# Calculate ROV of stage 1 research
m <- r
dfROVn <- ROVn(X0, Kvec, tauVecQrs, m, s)
f_n <- dfROVn$f_i[nrow(dfROVn)]
f_n - stage1Invest
# NPV
X0 - sum(exp(-r * tauVecQrs) * Kvec) - stage1Invest
#===============================================================================
# "Manual" check step by step
eta_00 <- 1; f0 <- X0
outROVi <- ROVi(Kvec[1], f0, tauVec[1], m, s, eta_00) # Value of option to launch
f1 <- outROVi[1]; probSuc1 <- outROVi[2]
df1df0 <- get_dfidfim1(Kvec[1], f0, f1, tauVec[1], m, s, eta_00)
#pnorm(get_di(Kvec[1], X0, tauVec[1], m, s, eta_00) + eta_00 * s * sqrt(tauVec[1]))
eta_10 <- f0 / f1 * df1df0 * eta_00
outROVi <- ROVi(Kvec[2], f1, tauVec[2], m, s, eta_10) # Value of option on stage 4 research
f2 <- outROVi[1]; probSuc2 <- outROVi[2]
df2df1 <- get_dfidfim1(Kvec[2], f1, f2, tauVec[2], m, s, eta_10)
eta_20 <- f1 / f2 * df2df1 * eta_10
outROVi <- ROVi(Kvec[3], f2, tauVec[3], m, s, eta_20) # Value of option on stage 3 research
f3 <- outROVi[1]; probSuc3 <- outROVi[2]
df3df2 <- get_dfidfim1(Kvec[3], f2, f3, tauVec[3], m, s, eta_20)
eta_30 <- f2 / f3 * df3df2 * eta_20
outROVi <- ROVi(Kvec[4], f3, tauVec[4], m, s, eta_30) # Value of option on stage 2 research
f4 <- outROVi[1]; probSuc4 <- outROVi[2]
df4df3 <- get_dfidfim1(Kvec[4], f3, f4, tauVec[4], m, s, eta_30)
eta_40 <- f3 / f4 * df4df3 * eta_30
#-------------------------------------------------------------------------------
dfROVnCheck <- data.frame(f_i = c(f1, f2, f3, f4), eta_i0 = c(eta_10, eta_20, eta_30, eta_40), probSuc = c(probSuc1, probSuc2, probSuc3, probSuc4))
dfROVn - dfROVnCheck
#===============================================================================
# Find breakeven project NPV
#rootROVn(X0 * 0.2, Kvec, tauVec, mm = r, s, stage1Invest)
thisInt <- c(10^5, 10^8)
outUniroot <- uniroot(rootROVn, interval = thisInt,
                                 #lower = min(thisInt), upper = max(thisInt),
                                 Kvec = Kvec, tauVec = tauVec,
                                 mm = r, s = s, stage1Invest)
X0min <- outUniroot$root
ROVn(X0min, Kvec, tauVec, m, s)



```
In order to make the calculation, we require the research stage and final launch costs $K_0, K_1, \dots, K_4$ and time horizons $T_0, T_1, \dots, T_4$ listed in Table x, as well as the project NPV, $x(0)$, the project NPV volatility $s$, and the quarterly discount rate $r$. USAID generally uses a high annual discount rate of $0.12$ in its cost-benefit analyses of agricultural development projects [@usaid2015cba]. A high discount rate is reasonable considering the long time horizon and high uncertainty surrounding project NPV, and considering that any alternative use of USAID funds would entail a similar level of elevated risk. We thus adopt USAID's annual (discrete) discount rate for the present exercise, which works out to a (continuous) quarterly discount rate of `r r` used in the calculation.

<!-- Ex-ante impact assessments of LBr potato in the target countries are underway, but have not yet been published at the time of writing [pers correspondence]. -->
For the pedagogical purposes of this exercise, we assume the net benefit projection in Figure \ref{fig:netBens} panel a. More specifically, we assume that annual net benefits ($y(t)$) increase by `alphaYrly_discrete * 100`$\%$ year on year due to increasing adoption in the target countries; and reach $\$$ `dNVT0ref * 10^6` in year `tRef / 4` after release. This may be expressed

\begin{equation}
y(t)\bigr|_{T_0 \geq t} = y(\hat{t}) \left( \frac{t}{\hat{t}} \right)^{\alpha}
\end{equation}

Where, for the quarterly time step in Figure \ref{fig:netBens}, $\hat{t} = 8$, $y(\hat{t}) =$ `dNVT0ref * 10^6`, and $\alpha = $ `alphaQrly`.

Net benefits continuously discounted back to $T_0$ ($e^{-r(t - T_0)} y(t)$) are presented in panel b of Figure \ref{fig:netBens}. Integration of the discounted net benefits with respect to $t$ over $[T_0, T_{-1}]$ gives project NPV at time of release ($x(T_0)$), presented in panel c of Figure \ref{fig:netBens}.

\begin{equation}
\begin{split}
x(T_0) &= \int_{T_0}^{T_{-1}} e^{-rt} y(t) \: dt \\
&= \frac{y(\hat{t})}{\hat{t}^{\alpha} r^{\alpha + 1}} ( -\Gamma(\alpha + 1, rT_{-1}) + \Gamma(\alpha + 1, rT_0) )
\end{split}
\end{equation}

The upper bound $T_{-1}$ is a net benefit cutoff set by the donor. Net benefits continue beyond $T_{-1}$, but the donor is only interested in net benefits up to $T_{-1}$. In this exercise, the donor sets $T_{-1}$ to `4 * nbCutoffYr` quarters (`nbCutoffYr` years) after release.









<!-- say that MSU and/or USAID internally conducted an ex-ante impact assessment indicating net benefits on the order of tens of millions of dollars per year, but that the long time horizon and high discounting results in an LBr project NPV of $x(0)=\$`r x0 * 10^-6`$ million. Moreover, the study reports a high degree of uncertainty ranging from `r 100 * yMinA` $\%$ to `r 100 * yMaxA`$\%$ of NPV. Based on these uncertainty bounds (and assuming project NPV follows a gBm), the project NPV volatility parameter $s$ is deduced as `r s` following the method explained in section \ref{sec:volEst}. -->
<!-- USAID-ABSP II program -->
<!-- The project occurred in 4 distinct stages: 1) Late Blight resistant (LBr) event production and selection, 2) Wide area testing, 3) Compilation of the regulatory dossier, and 4) Registration and regulatory affairs. -->
<!-- In stage 1, the lead gene construct was developed in a target potato variety, and a small number of transgenic events exhibiting high resistance to Late Blight, as well as a number of other qualities (absence of backbone vector sequences, minimum number copy number of R genes, etc.) were screened from a large number of explants. -->
<!-- In stage 2, the transgenic events selected in stage 1 were cultivated in three distinct locations and three distinct seasons to assess environmental effects on the LBr trait, and vice versa. Any impacts of LBr on other key traits such as yield, maturation time, taste, and so forth, were also assessed. --><!-- In stage 3, the regulatory dossier was compiled for submission to the National Competent Authority in the country where the LBr potato was to be released. The dossier included compositional and safety assessments, as well as the environmental assessments of the previous stage. -->
<!-- In stage 4, the regulatory dossier was defended and amended before the National Competent Authorty in the target country. This stage may involve a variety of activities, including public advocacy, lobbying, and submission of additional information. -->
<!-- For details see Schiek et al. [@]. -->
<!-- Others argue for a much lower rate when appraising these kinds of projects [@moore2004just; @caplin2004social; @harrison2010valuing]. Low discounting based on the opportunity cost of capital   In the present exercise, we err on the side of high discounting, reflecting the donor's mandate -->

























































USAID generally uses a high annual discount rate of $0.12$ in its cost-benefit analyses of agricultural development projects [@usaid2015cba]. However, there are good reasons for using a much lower rate when appraising these kinds of projects [@moore2004just; @caplin2004social; @harrison2010valuing]. As a compromise between the two extremes, an annual (discrete) discount rate of `r rYrly_discrete` is assumed in this exercise, which works out to a (continuous) quarterly discount rate of `r r` used in the calculation. Abandonment values are assumed to be zero for the time being.

At the time of writing, ex-ante impact assessments of LBr potato in Bangladesh and Indonesia have yet been published. For the pedagogical purposes of this exercise, say that MSU and/or USAID internally conducted an ex-ante impact assessment indicating net benefits on the order of tens of millions of dollars per year, but that the long time horizon and high discounting results in an LBr project NPV of $x(0)=\$`r x0 * 10^-6`$ million. Moreover, the study reports a high degree of uncertainty ranging from `r 100 * yMinA` $\%$ to `r 100 * yMaxA`$\%$ of NPV. Based on these uncertainty bounds (and assuming project NPV follows a gBm), the project NPV volatility parameter $s$ is deduced as `r s` following the method explained in section \ref{sec:volEst}.
<!-- $m = `r m`$ (or `r round(((1 + m)^4 - 1), 2)` annually) and -->

As a plausibility check, the project NPV growth rate coefficient of variation and log return are calculated based on the deduced value for $s$. The coefficient of variation works out to `r cv`. This might be considered high, but well within reason given the ambitious scope of the project, and given the wide range of research and non-research factors affecting its progress and eventual diffusion in the target populations and environments. The expected log return, meanwhile, works out to `r mu`, which works out to an expected arithmetic return of `r round(exp(mu) - 1, 2)`. This may or may not be plausible depending upon the details of the hypothetical NPV calculation. A high expected percentage change in NPV by the end of the project (i.e., a high arithmetic return) may make sense if there is reason to expect major improvements in potato value chain infrastructure within the target countries.
<!-- For public projects The annual discount rate is set equal to a social discount rate of $0.035$, following the recommendation of Moore et al. [@moore2004just], which implies a quarterly discount rate of $r = $`r r`.-->
<!-- (Alston and Norton acknowledged in 1995 that the treatment of risk in impact assessment models was "rudimentary and in need of further refinement" [@Alston1995]. Unfortunately, this remains true today.) If ex-ante risk assessments are not available, then they can be elicited in the survey of domain experts. Project risk might be crowdsourced, for example, by asking survey participants to estimate the maximum, minimum, and most probable impact of each given project. With these three inputs, it is then straightforward to compute standard deviation on the basis of an assumed project impact probability density. (For example, the minimum and maximum could be interpreted as the bounds of the 95% confidence interval of a lognormal probability density, and the "most probable impact" could be interpreted as its mode. From this it is then straightforward to derive the standard deviation.) -->

```{r, echo=FALSE}


df_table <- df[, c("Stage", "Fold (i)",
                   "i-fold ROV", "Value of underlying",
                   "Elasticity w.r.t. project NPV",
                   "Standard dev. of underlying",
                   "Probability of exercise")]
#df_tabwB <- df_wB[nrow(df_wB), c("OVn", "fnM10", "etaNm10", "sNm1", "Phi2")]
# colnames(df_table)[2:ncol(df_table)] <- c("ROV", "Value of\nunderlying", "Elasticity\nw.r.t. project NPV", "Standard dev.", "Phi 2")
df_table$`i-fold ROV` <- round(df_table$`i-fold ROV`)
df_table$`Value of underlying` <- round(df_table$`Value of underlying`)
these_cols <- c("Elasticity w.r.t. project NPV", "Standard dev. of underlying", "Probability of exercise")
df_table[, these_cols] <- round(df_table[, these_cols], 2)

# df_table <- regulartable(df_table)
# #df_table <- width(df_table, width = 0.7)
# df_table <- FitFlextableToPage(df_table)
# df_table

table_title <- "LBr potato project stage 1-4 ROVs"
modifiedColnames <- colnames(df_table)
modifiedColnames[2] <- "Fold $i$"
modifiedColnames[3] <- "$i$-fold ROV"
modifiedColnames[ncol(df_table)] <- "Prob. of exercise $\\Phi(\\delta_i)$"

df_table %>%
  knitr::kable(
    format = "latex",
    caption = table_title,
    align = "l",
    booktabs = T,
    #longtable = T,
    linesep = " ",
    col.names = modifiedColnames,
    escape = F
  ) %>%
  kableExtra::kable_styling(
    position = "left",
    latex_options = c("scale_down", "striped", "repeat"),
    full_width = F,
    stripe_color = "gray!15"
  ) %>%
  kableExtra::column_spec(column = 4:7, width = "1in")
# %>%
#   kableExtra::save_kable("Table 1.png")
# here("Table 1", "test")
# %>%
#   kableExtra::footnote(
#     general = table_caption)



```

Based on these parameter values, the 4-fold option value of the LBr potato project works out to $\$`r as.integer(ROV)`$, which exceeds the stage 1 implementation cost ($\$`r as.integer(K1)`$) by $\$`r as.integer(dif)`$. Hence the investment is justified under the parameter settings defined above. Conventional CBA appraisal (expression \ref{eq:npvIneqBN2}), by contrast, works out to $\$`r as.integer(conv)`$ million, which falls below the stage 1 cost by $\$`r -as.integer(dif_conv)`$. By the conventional CBA criterion, then, the LBr project would be rejected.
<!-- (equation \ref{eq:rovBn}) -->

The ROV approach provides additional output that may be of use in decision making. The probability of stage 1 research expiring in the money ($\Phi(\delta_4)$) is an encouraging `r Phi2`, while the elasticity of the 4-fold ROV with respect to project NPV is `r etaN0`, meaning that a $1\%$ change in project NPV results in a `r etaN0`$\%$ change in the 4-fold ROV. This indicates considerable sensitivity to changes in project NPV.

Since the 4-fold ROV is calculated recursively, the 3-fold, 2-fold, and 1-fold ROVs are also calculated in the process, along with their respective probabilities of expiring in the money and elasticities with respect to project NPV. These are reported together with the 4-fold ROV in Table 2. It may be of interest to note that the 3-fold, 2-fold, and 1-fold options are deep in the money with successively increasing probabilities of expiring in the money. This suggests that justification of the funding of each subsequent stage becomes easier if researchers can just manage to clear the stage 1 hurdle.
<!-- `r round(dif)` -->

```{r, echo=FALSE}

#--------------------------------------------------------------------------
# Define slack function for root finding function
slackfun <- function(x0, Kvec, Bvec, Tvec, s, r, thresh){
  
  df <- rovN(x0, Kvec, Bvec, Tvec, s, r)
  ROV <- df$`i-fold ROV`[nrow(df)]
  slack <- ROV - thresh
  return(slack)
  
}

# testFn <- function(x, a, b, thresh){
#   f <- a * x^2 - b
#   slack <- f - thresh
#   return(slack)
# }
# a <- 1
# b <- 2
# thresh <- 0
# xGuess <- sqrt(2)
# testFn(xGuess, a, b, thresh)
# thisInt <- c(0, 2)
# minInt <- min(thisInt)
# maxInt <- max(thisInt)
# testRoot <- rootSolve::uniroot.all(testFn,
#                                    thisInt,
#                                    minInt,
#                                    maxInt,
#                                    a = a,
#                                    b = b,
#                                    thresh = thresh)

#--------------------------------------------------------------------------
interval <- c(1, 2) * 10^6
out <- uniroot(slackfun,
               interval,
               Kvec = Kvec[-n - 1],
               Bvec = Bvec,
               Tvec = Tvec[-1],
               s = s,
               r = r,
               thresh = K1
)
x0bEven <- round(out[[1]] * 10^-6, 3) # millions
# x0guess <- 1.06 * 10^6 #x0
# slackfun(x0guess, Kvec[-n - 1], Bvec, Tvec[-1], s, m, r, thresh = K1)
# minInt <- min(interval)
# maxInt <- max(interval)
# mm <- m
# x0Root <- rootSolve::uniroot.all(slackfun,
#                        interval = interval,
#                        lower = minInt,
#                        upper = maxInt,
#                        trace = 2,
#                        Kvec = Kvec[-n - 1],
#                        Bvec = Bvec,
#                        Tvec = Tvec[-1],
#                        s = s,
#                        mm = mm,
#                        r = r,
#                        thresh = K1
#                        )
#--------------------------------------------------------------------------

```

<!-- The exercise so far assumes that abandonment value is zero. Now consider a stage 1 abandonment value of $\$`r as.integer(Bvec[n])`$, corresponding to the value of permanent upgrades to human and fixed capital at national agricultural research institutions in the target countries. Then the 4-fold ROV works out to $\$`r as.integer(ROV_wB)`$ USD, and the probability of expiring in the money at the end of stage 1 increases to `r Phi2wB`. -->
<!-- When there is considerable uncertainty or disagreement surrounding project NPV, as in the present example, a better question to ask may be: what is the minimum project NPV required to justify stage 1 funding? That is to say, instead of calculating the 4-fold ROV based on a dubious project NPV, it may be more useful to deduce the minimum project NPV required for the donor's investment to break even. This is achieved by solving the $n$-fold ROV model implicitly for $x_0$ such that $f_n - K_n = 0$. The audience can then draw its own conclusions about whether or not real project NPV is above or below this minimum threshold. In the present exercise, the break even project NPV works out to $\$`r x0bEven `$ million. -->
<!-- Point estimates such as this are of limited use when there is high uncertainty surrounding parameter settings. In such cases, it is better to report ROV in a map format spanning some relevant range of values of the most uncertain parameters. This allows decision makers to quickly discern ROV across a wide range of parameter values, as well as to develop a sense of how sharply ROV varies with these parameters. In other words, it combines ROV estimates and sensitivity analysis in a single reporting format. In the pedagogical example explored here, there is high uncertainty surrounding project NPV. A 3-fold ROV map spanning a range of combinations of upper and lower bounds on the 95% confidence interval is therefore provided in Figure \ref{fig:rovNmap}. -->
<!-- # ```{r, fig.show = "hold", fig.width = 4, fig.height=3, fig.align="left", fig.cap="\\label{fig:rovNmap}A map of 4-fold real option values across multiple combinations of project NPV minimum and maximum bounds.", echo = FALSE} -->
<!-- # ROV Map -->
<!-- nRes <- 20 -->
<!-- #----- -->
<!-- this_r <- 0.04 -->
<!-- #----- -->
<!-- # X0vec <- seq(0.5, 1.5, length.out = nRes) -->
<!-- # cvVec <- seq(2, 15, length.out = nRes) -->
<!-- yMaxVec <- seq(0.1, 3.5, length.out = nRes) -->
<!-- yMinVec <- seq(-0.9, -0.1, length.out = nRes) -->
<!-- #---- -->
<!-- difmat <- matrix(NA, nRes, nRes) -->
<!-- difNPVmat <- matrix(NA, nRes, nRes) -->
<!-- phi2mat <- matrix(NA, nRes, nRes) -->
<!-- x0starMat <- matrix(NA, nRes, nRes) -->
<!-- for(i in 1:nRes){ -->
<!--     #x0 <- X0vec[i] * 10^6 -->
<!--     yMin <- yMinVec[i] -->
<!--   for(j in 1:nRes){ -->
<!--     #cv <- cvVec[j] -->
<!--     #s <- m * cv -->
<!--     yMax <- yMaxVec[j] -->
<!-- # Back out s and m -->
<!-- s <- (yMax - yMin) / (2 * zBound * sqrt(Tn)) -->
<!-- mu <- (yMax + yMin) / 2 -->
<!-- m <- (mu / Tn + s^2 / 2) -->
<!-- #-------------------------------------------------------------------------- -->
<!-- # Compare to conventional appraisal -->
<!-- #NPV <- exp(-r * sum(Tvec)) * (X0 - sum(Kvec)) -->
<!-- conv <- exp((m - r) * Tn) * x0 - sum(exp(-r * rev(cumsum(rev(Tvec[-1])))) * (Kvec[-(n + 1)] - Bvec)) -->
<!-- dif_conv <- conv - K1 -->
<!-- #-------------------------------------------------------------------------- -->
<!-- # Calculate n-fold ROV with no abandonment value -->
<!-- df <- rovN(x0, Kvec[-n - 1], Bvec, Tvec[-1], s, m, r) -->
<!-- ROV <- df$OVn[nrow(df)] -->
<!-- dif <- ROV - K1 -->
<!-- Phi2 <- df$Phi2[n] #round(df$Phi2[n], 2) -->
<!-- etaNm10 <- round(df$etaNm10[n], 2) -->
<!-- #-------------------------------------------------------------------------- -->
<!-- interval <- c(.4, 10) * 10^6 -->
<!-- out <- uniroot(slackfun, -->
<!--         interval, -->
<!--         Kvec = Kvec[-n - 1], -->
<!--         Bvec = Bvec, -->
<!--         Tvec = Tvec[-1], -->
<!--         s = s, -->
<!--         m = m, -->
<!--         r = r, -->
<!--         thresh = K1 -->
<!--         ) -->
<!-- x0star <- out[[1]] -->
<!-- #-------------------------------------------------------------------------- -->
<!--   difmat[i, j] <- dif -->
<!--   phi2mat[i, j] <- Phi2 -->
<!--   difNPVmat[i, j] <- dif_conv -->
<!--   x0starMat[i, j] <- x0star -->
<!--     } -->
<!-- } -->
<!-- #-------------------------------------- -->
<!-- colnames(difmat) <- as.character(yMaxVec) -->
<!-- row.names(difmat) <- as.character(X0vec) -->
<!-- df_plot <- reshape2::melt(difmat) -->
<!-- colnames(df_plot) <- c("Project NPV at t = 0 (million USD)", "y max", "ROV net benefit\n(100 thousand USD)") -->
<!-- colnames(phi2mat) <- as.character(yMaxVec) -->
<!-- row.names(phi2mat) <- as.character(X0vec) -->
<!-- df_plotPhi2 <- reshape2::melt(phi2mat) -->
<!-- colnames(df_plotPhi2) <- c("Project NPV at t = 0 (million USD)", "y max", "Probability of success") -->
<!-- #, "NPV net benefit", ) -->

<!-- #--- -->
<!-- gg <- ggplot(df_plot, aes(x = `y max`, -->
<!--                           y = `Project NPV at t = 0 (million USD)`, -->
<!--                           fill = `ROV net benefit\n(100 thousand USD)`)) -->
<!--                           #fill = `Probability of success`)) -->
<!-- gg <- gg + geom_tile() -->
<!-- gg <- gg + scale_fill_gradient2(high = "green", -->
<!--                                 mid = "yellow", -->
<!--                                 low = "red", -->
<!--                                 midpoint = 0) -->
<!-- gg <- gg + theme_bw() -->
<!-- gg <- gg + theme(legend.position = "top", -->
<!--                  axis.title.y = element_text(size = axisTitle_size), -->
<!--                  axis.text.y = element_text(size = axisText_size), -->
<!--                  axis.title.x = element_text(size = axisTitle_size), -->
<!--                  axis.text.x = element_text(size = axisText_size), -->
<!--                  legend.text = element_text(size = legendText_size), -->
<!--                  legend.title = element_text(size = axisTitle_size)) -->
<!-- gg_rovMap <- gg -->
<!-- #--------------------------------------------------------------------------- -->
<!-- gg <- ggplot(df_plotPhi2, aes(x = `y max`, -->
<!--                           y = `Project NPV at t = 0 (million USD)`, -->
<!--                           fill = `Probability of success`)) -->
<!-- gg <- gg + geom_tile() -->
<!-- gg <- gg + scale_fill_gradient(high = "green", -->
<!--                                 #mid = "yellow", -->
<!--                                 low = "red")#, -->
<!--                                 #midpoint = 0.5) -->
<!-- gg <- gg + theme_bw() -->
<!-- gg <- gg + theme(legend.position = "top", -->
<!--                  axis.title.y = element_blank(), -->
<!--                  axis.text.y = element_blank(), -->
<!--                  axis.title.x = element_text(size = axisTitle_size), -->
<!--                  axis.text.x = element_text(size = axisText_size), -->
<!--                  legend.text = element_text(size = legendText_size), -->
<!--                  legend.title = element_text(size = axisTitle_size)) -->
<!-- gg_probMap <- gg -->
<!-- #--------------------------------------------------------------------------- -->
<!-- gg_rovMap + gg_probMap + plot_layout(ncol = 2) -->

# Discussion and conclusion

<!-- As for the relation between project NPV and the outscaling investment, we refer to the marginally diminishing relationship that typically exists between AR4D project NPV and the size of the investment in the outscaling of the finished technology. That is to say, beyond a certain minimum level of investment required to release and support the diffusion and uptake of the project's research product on a pilot level, further increments in the outscaling investment have the effect of broadening the scope of impact---i.e. the size and number of target populations and environments where the research product is released and has an impact. Existing ROV methods tacitly assume that project NPV and the outscaling investment are independent, or that only one outscaling investment scenario is of interest. The adjustment introduced here facilitates examination of all outscaling investment scenarios, and even makes it possible to solve for the ROV-maximizing outscaling investment. -->

abstract from the messiness... in particular deadline extensions, staggered finishing (Kenya) and release
Assessment of $s$...
potential use as insurance...


In this article, I have developed an $n$-fold ROV model to evaluate the real option value of multistage AR4D projects. The model effectively prices in the research donor's option to discontinue funding of a project at the end of well defined research stages, thereby facilitating donor commitment to the long time horizons of agricultural research. In other words, the model formalizes the de facto structure of most AR4D project funding arrangements. The model also accounts for the wide uncertainty that usually surrounds AR4D project NPV, thereby reducing the pressure on researchers to put an exact monetary value on impacts that may be decades in the future. I have also extended the model to include abandonment value.

The proposed model is particularly appropriate for the valuation of high risk, deep-in-the-money (i.e. high expected reward) projects. The higher a project's moneyness (i.e. the higher the expected reward), the higher must be its volatility for there to be a meaningful difference between the ROV and conventional CBA approaches. In the case of LBr potato examined above, for example, a small increase in the hypothetical NPV and/or decrease in the confidence interval given by $\bar{\ell}$, $\underline{\ell}$ (and hence a decrease in the volatility $s$) results in an ROV that is virtually the same as the NPV, in which case there is no point in evaluating the $n$-fold ROV.

The proposed model rests on the assumption that project NPV follows a gBm, and is thus subject to criticism insofar as this assumption is unrealistic. In response to critics who reject the gBm assumption on the basis that the time evolution of project NPV fails to resemble that of gBm, I have argued that 1) the time domain discrepancy is largely spurious, attributable to one's theory of how/when new information affects project NPV, and to one's choice of time step $\Delta t$. And, more importantly, I have argued that 2) it is not the time domain, but the frequency domain that is relevant when it comes to far-from-market ROV calculation. That is to say, the calculation of ROV hinges upon the size distribution of changes in NPV, regardless of when or in what order the changes occur. Assuming that project NPV follows a gBm is tantamount to assuming that percentage changes in project NPV are normally distributed. Insofar as this assumption is valid, then, the proposed model is valid. Practitioners are forewarned that rejection of this assumption tends to lead to the sort of black box complexity that has so far inhibited wider adoption of the ROV approach.

Note that project NPV usually scales with the launch and scaling up cost $K_n$. That is to say, beyond a certain minimum level of funding required to generate, release, and support the diffusion and uptake of the project's research product on a pilot level, further increments in the investment $K_n$ have the effect of broadening the scope of impact---i.e. extending the size and number of target populations and environments where the research product is released and has an impact. In future work, then, it might be worthwhile to explore the ROV implications of explicitly modeling project NPV as a function of the scaling up investment $K_n$. For example, $x(0)$ could be defined

\begin{equation}
x(0) = \tilde{x}(0) \left(\frac{K_n}{\bar{K}_n}\right)^{\alpha}
\end{equation}

Where the parameter $\bar{K}_n$ is a reference value---perhaps the minimum or maximum possible scale up investment, for example---$\tilde{x}(0)$ is the project NPV if scaling up funding equals the reference value, and the exponent $\alpha$ is restricted to fall between 0 and 1, reflecting decreasing returns to scale. It may then be interesting to analyze ROV response to successively higher scale up investments $K_n$, corresponding to successively broader geographical scopes of impact.

For purposes of exposition, I have focused here on the valuation of transgenic projects; but the $n$-fold ROV model derived in this article is of course not limited to such ventures. It applies just as well to the valuation of conventional crop and livestock breeding projects, as well as to multistage AR4D projects not necessarily built around the objective of genetic gain. This includes, for example, projects involving digital agriculture, value chain integration, social capital formation, agricultural biodiversity, environmental services, climate smart agriculture, agroecology, etc., and combinations thereof. The proposed model can also be applied at more aggregate levels of accounting---to valuate, for example, a multistage program consisting of several projects in various stages of implementation. While AR4D is the motivating context of the present work, the model presented here is generally applicable to the valuation of any far-from-market, multistage venture.




<!-- \begin{equation} -->
<!-- \left( x m \frac{\partial f}{\partial x} + \frac{\partial f}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f}{\partial x^2} \right) \Delta t \\ -->
<!-- = r \Delta t -->
<!-- \end{equation} -->

<!-- Since the random element has been removed in Equation \ref{eq:bsInsight}, then, by Equations \ref{eq:ar4dRate} and \ref{eq:gbmEq}, the $\Delta x$ appearing in Equation \ref{eq:bsInsight} must reduce to $s^2 / 2 x \Delta t$. Likewise, the $\Delta f$ appearing in Equation \ref{eq:bsInsight} must reduce to $r f \Delta t$. That is to say, by definition, in the absence of random shocks, AR4D ROV appreciates at the discount rate $r$. Hence, instead of Equation \ref{eq:BSarb}, we have, in the AR4D context, -->

<!-- \begin{equation} -->
<!-- \Delta f - \frac{\partial f}{\partial x} \Delta x = \left( r f - \frac{\partial f}{\partial x} \frac{s^2}{2} x \right) \Delta t -->
<!-- \label{eq:ar4dInsight} -->
<!-- \end{equation} -->

<!-- Equating the right-hand side of this equation with the right-hand side of Equation \ref{eq:bsInsight}, the $\Delta t$'s cancel, resulting in the following PDE. -->

<!-- \begin{equation} -->
<!-- rf - \frac{s^2}{2} \frac{\partial f}{\partial x} x = \frac{\partial f}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f}{\partial x^2} -->
<!-- \end{equation} -->

<!-- Noting that -->

<!-- \begin{equation} -->
<!-- x^2 \frac{\partial^2 f}{\partial x^2} = \frac{\partial f}{\partial \ln(x)} - \frac{\partial^2 f}{\partial \ln(x)^2} -->
<!-- \end{equation} -->

<!-- The previous equation reduces to -->

<!-- \begin{equation} -->
<!-- \end{equation} -->


<!-- \begin{equation} -->
<!-- \left( x m \frac{\partial f}{\partial x} + \frac{\partial f}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f}{\partial x^2} \right) \Delta t -->
<!-- \end{equation} -->

<!-- respectively. Moreover, the rate at which real option value $f$ appreciates over a small time increment $\Delta t$ is, by definition, just the discount rate $r$. Therefore,  -->

<!-- $m x \Delta t$. Likewise, $\Delta f$ must reduce to $r f\Delta t$, where   such that Equation , -->

<!-- Note also the disparity in assumptions underpinning the two results. The Black-Scholes derivation requires that $x(t)$ both follow a gBm and be interpretable as a traded security in an efficient market. Equation \ref{eq:rov}, on the other hand, requires only that $x(t)$ follow a gBm. The requirement $m = $ -->

<!-- In the AR4D context, the risk free rate and no-arbitrage rule are replaced by the discount rate (also denoted by $r$), and the definition of NPV, which requires that the value of the riskless portfolio on the left-hand side of equation \ref{eq:bsInsight1} must change at the rate of $r$. -->

<!-- By definition, then, $x(t)$ is expected to appreciate at the discount rate. That is, the expected value of $x(t)$ at some future time $\tilde{t} > t$ is just the presently assessed value of project NPV times the inverse discount factor. This can be expressed -->

<!-- \begin{equation} -->
<!-- $E[x(\tilde{t})]_{t} = e^{r \tau} x(t)$. -->
<!-- \end{equation} -->
<!-- <!-- date of release ($T$) of the research product. The time $t < T$ is the time at which project NPV is evaluated. By definition, $E[y(T)]\bigr|_{t} = y(t)$. Or, for any intermediate time $t < \tilde{t} < T$, $E[y(\tilde{t})]\bigr|_{t} = x(t)$. -->
<!-- <!-- Now we introduce another variable $x(t)$ to stand for the present value of project NPV at the time of evaluation. That is to say, $x(t) = e^{-r \tau} y(t)$, where $r$ is the discount rate and $\tau = T - t$. -->

<!-- Where $r$ is the instantaneous discount rate and $\tau = \tilde{t} - t$ is the number of time steps between now ($t$) and the future time $\tilde{t}$. -->

<!-- In the financial context, Black and Scholes [] derived the following closed form expression for equation \ref{eq:basic}. -->

<!-- \begin{equation} -->
<!-- e^{-r\tau} E[\max(x(T) - K, 0)]\bigr|_{t = \hat{t}} = x(\hat{t}) \Phi(\delta + s \sqrt{\tau}) - e^{-r \tau} K \Phi(\delta) -->
<!-- \label{eq:eov} -->
<!-- \end{equation} -->

<!-- Where $\hat{t}$ is the time at which the equation is evaluated, $\tau = T - \hat{t}$, and -->

<!-- \begin{equation} -->
<!-- \delta = \frac{\ln \left(\frac{x(\hat{t})}{K} \right) + \left(r - \frac{s^2}{2} \right) \tau}{s \sqrt{\tau}} -->
<!-- \end{equation} -->

<!-- They reached this form assuming that prices follow a geometric Brownian movement (gBm) plus a financial train of logic involving short selling and the efficient market hypothesis (the no arbitrage rule), which further implies as a corollary that the investor is willing to take on any level of risk for a given expected rate of return (risk-neutral valuation). Because none of this financial reasoning has any clear application in the AR4D context, it is helpful, for present purposes, to keep in mind that the same functional form can be derived without recourse to Black and Scholes' financial argument, based only on the assumption that project NPV follows a gBm. See Appendix for details. -->

<!-- ...the simple observation that, in AR4D contexts, ex-ante impact assessments of project NPV are not expected to change over time. That is to say, mathematically,  -->

<!-- \begin{equation} -->
<!-- E\left[ \ln\left(\frac{x(T)}{x(\hat{t})} \right) \right] = 0 -->
<!-- \end{equation} -->

<!-- Given the assumption that $x(t)$ follows a gBm, this implies that $m = s^2 / 2$; and the ROV expression (Equation \ref{eq:rovRaw}) for AR4D contexts must then reduce to -->
















\appendix
\renewcommand{\thesection}{A}

# Appendix {-}

## Proof of equation \ref{eq:genEq} through straightforward integration {-}

<!-- Lemma: -->

<!-- If $v(t)$ follows a geometric Brownian motion; that is to say, if the instantaneous evolution of $v(t)$ over time can be expressed -->

<!-- \begin{equation} -->
<!-- \Delta v = \alpha v \Delta t + \beta v \epsilon \sqrt{\Delta t} \:\:;\:\:\: \Delta v = v(t + \Delta t) - v(t) -->
<!-- \label{eq:deltaV} -->
<!-- \end{equation} -->

<!-- Where $\epsilon$ is a normally distributed random variable with mean $0$ and variance $1$, and $\alpha$ and $\beta$ are constant with respect to the instantaneous time increment $\Delta t$, such that -->

<!-- \begin{equation} -->
<!-- \frac{\Delta v}{v} ~ \phi(\alpha \Delta t, \beta^2 \Delta t) -->
<!-- \end{equation} -->

<!-- Where $\phi()$ is the standard normal probability density function; and hence -->

<!-- \begin{equation} -->
<!-- v(T) = v(\hat{t}) e^{(\alpha - \beta^2 / 2) \tau + \beta \epsilon \sqrt{\tau}} -->
<!-- \label{eq:defVt} -->
<!-- \end{equation} -->

<!-- Where $T$ is some future time step, $\hat{t} < T$ is the time step at which $v(T)$ is evaluated, and $\tau = T - \hat{t}$. (See Hull [@hull9thEdition] for details.) Then, for a constant C, -->
<!-- <!-- , such that --> 
<!-- <!-- \begin{equation} --> 
<!-- <!-- \ln \left(\frac{v(T)}{v(\hat{t})} \right) ~ \phi \left(\left(\alpha - \frac{\beta^2}{2} \right) \tau, \beta^2 \tau \right) -->
<!-- <!-- \end{equation} -->

<!-- \begin{equation} -->
<!-- E[max(v(T) - C, 0)]\bigr|_{t = \hat{t}} = e^{\alpha \tau} v(\hat{t}) \Phi(\delta + \beta \sqrt{\tau}) - C \Phi(\delta) -->
<!-- \end{equation} -->

<!-- Where $\Phi()$ is the standard normal cumulative distribution function, and -->

<!-- \begin{equation} -->
<!-- \delta = \frac{\ln(v(\hat{t}) / C) + (\alpha - \beta^2 / 2) \tau}{\beta \sqrt{\tau}} -->
<!-- \end{equation} -->

<!-- Proof: -->

(The proof below closely follows that of Hull in the appendix to chapter 13 of his book [-@hull9thEdition]. It is presented here solely for the reader's convenience, with no claim to originality.)
<!-- _Part 1_ -->

By definition, for a random variable $q$ and a constant $C$,

\begin{equation}
E[\max(q - C, 0)] = \int_{C}^{\infty} (q - C) p(q) \: dq
\label{eq:def}
\end{equation}

Where $p(q)$ is the probability density function of the random variable $q$. If $\ln(q)$ is normally distributed with mean $\nu$ and variance $\omega^2$, then

\begin{equation}
E[q] = e^{\nu + \frac{\omega^2}{2}}
\label{eq:muXT}
\end{equation}

and

\begin{equation}
p(q) = \frac{1}{q \omega} \phi \left(\frac{\ln(q) - \nu}{\omega} \right)
\end{equation}

Where $\phi()$ is the standard normal probability density function.

Now, introducing a change of variables,

\begin{equation}
u = \frac{\ln(q) - \nu}{\omega}
\label{eq:subThis1}
\end{equation}

Such that

\begin{equation}
\frac{du}{d q} = \frac{1}{q \omega}\: \rightarrow \: d q = q \omega du
\label{eq:subThis2}
\end{equation}

The definition in equation \ref{eq:def} can be rewritten as follows.

\begin{equation}
\begin{split}
E[\max(q - C, 0)] &= \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} (e^{u \omega + \nu} - C) \phi(u) \: du \\
&= \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} e^{u \omega + \nu} \phi(u) \: du - C \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} \phi(u) \: du \\
&= \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} e^{u \omega + \nu} \phi(u) \: du - C \Phi \left(-\frac{\ln(C) - \nu}{\omega} \right)
\end{split}
\end{equation}

The remaining integral on the right-hand side of the definition resolves as follows.

\begin{equation}
\begin{split}
\int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} e^{u \omega + \nu} \phi(u) \: du &= \frac{1}{\sqrt{2 \pi}} \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} e^{u \omega + \nu -\frac{u^2}{2}} \: du \\
&= \frac{1}{\sqrt{2 \pi}} \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} e^{-1 / 2 (u^2 - 2 u \omega - 2 \nu)} \: du \\
&= \frac{1}{\sqrt{2 \pi}} \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} e^{-\frac{(u - \omega)^2}{2} + \nu + \frac{\omega^2}{2}} \: du \\
&= \frac{1}{\sqrt{2 \pi}} \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} e^{-\frac{(u - \omega)^2}{2}} e^{\nu + \frac{\omega^2}{2}} \: du \\
&= e^{\nu + \frac{\omega^2}{2}} \frac{1}{\sqrt{2 \pi}} \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} e^{-\frac{(u - \omega)^2}{2}} \: du \\
&= \frac{E[q]}{\sqrt{2 \pi}} \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} e^{-\frac{(u - \omega)^2}{2}} \: du \\
&= \frac{E[q]} \int_{\frac{\ln(C) - \nu}{\omega}}^{\infty} \phi(u - \omega) \: du \\
&= \frac{E[q]} \Phi \left(- \frac{\ln(C) - \nu}{\omega} + \omega \right)
\end{split}
\end{equation}

The definition may now be rewritten as follows.

\begin{equation}
E[\max(q - C, 0)] = E[q] \Phi \left(- \frac{\ln(C) - \nu}{\omega} + \omega \right) - C \Phi \left(-\frac{\ln(C) - \nu}{\omega} \right)
\end{equation}

Note that \ref{eq:muXT} can be rearranged into an expression for $\nu$.

\begin{equation}
\nu = \ln(E[q]) - \omega^2 / 2
\end{equation}

Substituting this for $\nu$ in the definition gives

\begin{equation}
E[\max(q - C, 0)] = E[q] \Phi \left(\frac{\ln \left( \frac{E[q]}{C} \right) + \frac{\omega^2}{2}}{\omega} \right) - C \Phi \left(-\frac{\ln \left( \frac{E[q]}{C} \right) - \frac{\omega^2}{2}}{\omega} \right)
\end{equation}

$\blacksquare$

## Derivation of Equation \ref{eq:rov} from the Black-Scholes PDE {-}

Starting from the Black-Scholes PDE,

\begin{equation}
fr = \frac{\partial f}{\partial x} x r + \frac{\partial f}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f}{\partial x^2}
\end{equation}

Note that

\begin{equation}
x^2 \frac{\partial^2 f}{\partial x^2} = \frac{\partial^2f}{\partial \ln(x)^2} - \frac{\partial f}{\partial \ln(x)}
\end{equation}

Such that the PDE may be rewritten

\begin{equation}
fr = \frac{\partial f}{\partial \ln(x)} \left(r - \frac{s^2}{2} \right) + \frac{\partial f}{\partial t} + \frac{s^2}{2} \frac{\partial^2f}{\partial \ln(x)^2}
\end{equation}

Defining $f = e^{-r \tau} y$ and substituting this in for $f$,

\begin{equation}
0 = \frac{\partial y}{\partial \ln(x)} \left(r - \frac{s^2}{2} \right) + \frac{\partial y}{\partial t} + \frac{s^2}{2} \frac{\partial^2 y}{\partial \ln(x)^2}
\end{equation}

Substituting $T - \tau$ for $t$ and expressing the equation in terms of a new function $v(u, \tau)$, where $u = \ln(x) + (r - s^2 / 2) \tau$,

\begin{equation}
0 = \frac{s^2}{2} \frac{\partial^2 v}{\partial u^2} - \frac{\partial v}{\partial t}
\end{equation}

This is the one dimensional heat equation, with fundamental solution

\begin{equation}
v(u, \tau) = \frac{1}{\sqrt{2 \pi s^2 \tau}} \int_{-\infty}^{\infty} v(\ell, 0) e^{-\frac{(u - \ell)^2}{2 s^2}} \:d \ell
\end{equation}

The boundary condition in this case is $f(x, T) = \max(X(T) - K, 0)$, which in terms of $v(u, \tau)$ is $v(u, 0) = \max(e^u - K, 0)$.

\begin{equation}
\begin{split}
v(u, \tau) &= \frac{1}{s \sqrt{2 \pi \tau}} \int_{\ln(K)}^{\infty} (e^{\ell} - K) e^{-\frac{(u - \ell)^2}{2 s^2}} \: d \ell \\
&= \frac{1}{s \sqrt{2 \pi \tau}} \int_{\ln(K)}^{\infty} e^{\ell - \frac{(u - \ell)^2}{2 s^2}} \:d \ell - \frac{K}{s \sqrt{2 \pi \tau}} \int_{\ln(K)}^{\infty} e^{-\frac{(u - \ell)^2}{2 s^2 \tau}} \:d \ell
\end{split}
\end{equation}

Introducing the substitution

\begin{equation}
\begin{split}
z &= \frac{\ell - u}{s\sqrt{\tau}} \\
&\rightarrow \: s\sqrt{\tau} dz = d \ell
\end{equation}

The integral simplifies to

\begin{equation}
\begin{split}
v(u, \tau) &= \frac{1}{\sqrt{2 \pi}} \int_{\frac{\ln(K) - u}{s \sqrt{\tau}}}^{\infty} e^{z s \sqrt{\tau} + u - \frac{z^2}{2}} \:dz - \frac{K}{\sqrt{2 \pi}} \int_{\frac{\ln(K) - u}{s \sqrt{\tau}}}^{\infty} e^{-\frac{z^2}{2}} \:d z \\
&= \frac{1}{\sqrt{2 \pi}} \int_{\frac{\ln(K) - u}{s \sqrt{\tau}}}^{\infty} e^{- \frac{-(z - s \sqrt{\tau})^2}{2} + u + \frac{s^2 \tau}{2}} \:d z - \Phi \left(- \frac{\ln(K) - u}{s \sqrt{\tau}} \right) \\
&= e^{u + \frac{s^2 \tau}{2}} \frac{1}{\sqrt{2 \pi}} \int_{\frac{\ln(K) - u}{s \sqrt{\tau}}}^{\infty}  e^{- \frac{-(z - s \sqrt{\tau})^2}{2}} \: dz - \Phi \left(- \frac{\ln(K) - u}{s \sqrt{\tau}} \right) \\
&= e^{u + \frac{s^2 \tau}{2}} \Phi \left( \frac{-\ln(K) - u}{s \sqrt{\tau}} + s \sqrt{\tau} \right)
\end{split}
\end{equation}

Expressing everything once more in terms of $y(x, \tau)$, this reduces to

\begin{equation}
y(x, \tau) = x(t) e^{r \tau} \Phi(\delta + s \sqrt{\tau}) - K \Phi(\delta)
\end{equation}

Where

\begin{equation}
\delta = \frac{\ln \left( \frac{X(t)}{K} \right) + \left(r - \frac{s^2}{2} \right) \tau}{s \sqrt{\tau}}
\end{equation}

And multiplying through by the discount factor gives the expression for $f(x, \tau)$.

\begin{equation}
f(x, \tau) = x(t) \Phi(\delta + s \sqrt{\tau}) -  e^{-r \tau} K \Phi(\delta)
\end{equation}

$\blacksquare$



























To avoid confusion it is important to keep the following differences in mind:

+The ROV approach developed here is squarely founded upon the notion of the European call option defined in Equation \ref{eq:basic}. The optimal delay approach, on the other hand, is conceptually more akin to a different kind of financial option known as the American call option---which allows for exercise at any time before the end of the (potentially infinite) period $T$ [Hull]---and is, moreover, conflated with notions of "quasi-option value" developed in the environmental economics literature [].

+The optimal delay approach implicitly or explicitly adopts all of the corporate ROV assumptions enumerated above, and is thus suited to agricultural R&D products of a corporate or near market nature, but not to AR4D.

+The optimal delay approach limits its focus to R&D projects with uncertain externalities---typically, transgenic R&D with uncertain environmental impact. The ROV method developed here is applicable to both transgenic and conventional breeding projects.

+The optimal delay approach considers value from a social planner perspective, whereas the ROV approach pursued here considers value from the donor's perspective.

+The optimal delay approach implies that project ROV is generally lower than NPV, whereas the ROV appraisal method developed here implies the opposite.
<!-- +The ROV approach pursued here implies that the project NPV threshold above which investment in the project is justified, is lower than the threshold as computed in a conventional cost-benefit analysis (CBA). The optimal delay approach, on the other hand, implies that the investment-justifying NPV threshold is higher than the conventional CBA threshold. -->

These differences are formally demonstrated in the development of the ROV method below. After the main 


















<!-- Each stage in the series is contingent upon successful completion of the previous stage, such that investment in any single stage may be viewed as the purchase of an option on the subsequent stage. -->
<!-- Both Geske and Cassimon et al. derive their models from the Black-Scholes partial differentiation equation [@black1973valuation]. Here we present an alternative derivation and formulation of the multistage, or "$n$-fold", real option value model based on straightforward integration, which some may find more intuitive and instructive---especially if they are unfamiliar with the financial origins of Geske's model. -->



<!-- ## Real option value basics -->

<!-- <!-- ### What is real option value? -->

<!-- In the motivating context of the present work, NPV refers to the net present value of future project impacts, starting from the anticipated date of release of the new technology. That is to say, it is the present value of the expected future benefits of the finished research product, minus the expected costs of its release and distribution, and any other cost required to support the uptake and outscaling of the finished research product. It is assumed that the cost and duration of each research stage are known. -->

# ```{r Fig2, fig.show = "hold", fig.width = 5, fig.height=2, fig.align="center", fig.cap="\\label{fig:NPVbasic}Investment timeline of Late Blight Potato research.", echo = FALSE}

<!-- #Tvec <- c(2, 3, 0.85, 1.7, 3.4) * 4 -->
<!-- r <- 0.12 -->
<!-- Tvec <- c(2, 3, 3, 4) -->
<!-- Kvec <- c(250000, 181000, 336000, 530000) -->
<!-- t0 <- 1; tT <- 40 -->
<!-- df <- data.frame(t = seq(t0, tT, 1), Val = NA) -->
<!-- indInv <- cumsum(Tvec) -->
<!-- tRelease <- 13 -->
<!-- indImpact <- c(tRelease:tT); tImpact <- 1:length(indImpact) -->
<!-- a <- 0.15; b <- 5 * 10^5 -->
<!-- df$Val[indInv] <- -Kvec -->
<!-- df$Val[indImpact] <- b * tImpact^a -->
<!-- df$type <- "Undiscounted" -->
<!-- dfDisc <- df %>% mutate(type = "Discounted") %>% mutate(Val = Val / (1 + r)^t) -->
<!-- df <- as.data.frame(rbind(df, dfDisc)) -->
<!-- # df$Val[indInv] <- -Kvec / (1 + r)^df$t -->
<!-- # impactVec <- exp(-r * df$t[indImpact]) * b * tImpact^a -->
<!-- # df$NPV[indImpact] <- impactVec -->
<!-- # df$type <- "NPV" -->
<!-- # df2 <- df; df2$type <- "Value"; df <- as.data.frame(rbind(df, df2));rm(df2) -->

<!-- gg <- ggplot(df, aes(x = t, y = Val, fill = type)) -->
<!-- gg <- gg + geom_bar(stat = "identity", position = "dodge") -->
<!-- gg <- gg + geom_hline(yintercept = 0, color = "red") -->
<!-- gg <- gg + geom_vline(xintercept = tRelease, color = "green") -->
<!-- gg <- gg + theme_bw() -->
<!-- gg -->

<!-- # Kvec <- c(180541, 311974, 335530, 530250) -->
<!-- # CIP -->
<!-- # Kvec <- c(52000, 213000, 396000, 929000) -->
<!-- # Tvec <- c(1, 0.25, 2, 4.75) * 4 -->
<!-- #------------------------------------------------------------------------ -->
<!-- # Crude project NPV estimate loosely based on expected adoption rates, time horizons, etc. -->
<!-- # rYrly_discrete <- 0.08 #0.035 -->
<!-- # rQrly_discrete <- (1 + rYrly_discrete)^(1 / 4) - 1 -->
<!-- # Tadopt <- 20 * 4 -->
<!-- # Timpact <- 10 * 4 -->
<!-- # yrlyBen <- 1 * 10^6 # (Assuming very low adoption) -->
<!-- # x0 <- sum(yrlyBen / (1 + rQrly_discrete)^(Tn + Tadopt + 1:Timpact)) -->
<!-- # # (Override) -->
<!-- # x0 <- 1.23 * 10^6 -->
<!-- #------------------------------------------------------------------------ -->
<!-- # Create table summarizing stage costs, time durations, and descriptions -->
<!-- stage1desc <- "Basic replication and scaling up" -->
<!-- stage2desc <- "Multi-location/season testing" -->
<!-- stage3desc <- "Compilation of the regulatory dossier" -->
<!-- stage4desc <- "Deregulation" -->
<!-- launchDesc <- "Launch in 2 countries" -->
<!-- descVec <- c(stage1desc, stage2desc, stage3desc, stage4desc, launchDesc) -->

<!-- df_table <- data.frame(Stage = c(1:4, "Launch"), -->
<!--                        Kn = rev(Kvec), -->
<!--                        Duration = rev(Tvec), -->
<!--                        DurationCum = cumsum(rev(Tvec)), -->
<!--                        Description = descVec) -->

<!-- colnames(df_table)[2:4] <- c("Cost\n(USD)", "Duration\n(annual quarters)", "Cumulative\nduration") -->

<!-- #df_table <- regulartable(df_table) -->
<!-- #df_table -->
<!-- #df_table <- width(df_table, width = 0.7) -->
<!-- table_title <- "Project to research and develop Late Blight resistant potato for release as a public good in 2 developing countries." -->
<!-- table_caption <- "Stage 1-4 costs and durations based on figures reported by Schiek et al. (2016). The launch cost and duration is hypothetical." -->
<!-- ``` -->



<!-- Letting $x(\hat{t})$ stand for project NPV evaluated at time $\hat{t}$, this is often expressed in discrete form as follows. -->

<!-- \begin{equation} -->
<!-- x(\hat{t}) = \sum_{\tau = \hat{t}} \frac{E[R(T)]\bigr|_{\hat{t}} -E[C(T)]\bigr|_{\hat{t}}{(1 + r)^T} -->
<!-- \end{equation} -->

<!-- Where $E[R(T)]\bigr|_{\hat{t}}$ and is the expected benefit in time step $T$ as evaluated at time $\hat{t}$  where r is the discrete annual discount rate. In the AR4D context,...It follows, moreover, that the same challenges faced in the estimation of project NPV---such as non-market valuation of "intangible" costs and benefits (environmental and public health outcomes, for example), or the estimation of technology adoption rates, and so forth---are faced in the estimation of ROV. To avoid raising false hopes, the reader is advised up front that the many important open problems in the field of NPV estimation fall outside the scope of the present work.... The infinite upper bound can be replaced by some arbitrary limit, but if it is necessary to do so then this is a sign that the discount rate is implausibly low. Here we have the continuous version in mind...continuous discount rate r -->

<!-- \begin{equation} -->
<!-- x(\hat{t}) = \int_{\hat{t}}^{\infty} e^{-rt} t^a \: dt -->
<!-- \end{equation} -->

<!-- The precise details of how NPV is calculated are immaterial for present purposes, it could just be a guess. -->

<!-- It does not include the main research investments which are required to generate the finished product in the first place. -->



<!-- Note that ROV is partly a function of NPV. In the ROV literature, ROV is sometimes characterized as an alternative to the "NPV approach". This is misleading insofar as it suggests that ROV is an alternative to ex-ante impact assessment. On the contrary, ROV requires ex-ante impact assessment.... the formal exposition so far demonstrates that ROV is a function of NPV, and thus involves its estimation (and this becomes clearer as the formal exposition continues, below). For this reason, the conventional or default approach to project funding decisions characterized in Inequality \ref{eq:convCBA}, against which the ROV approach is distinguished, is henceforth referred to as the "conventional CBA criterion"---and not the "NPV approach". -->




<!-- In the default approach to project funding decisions, project NPV is compared against the investment required to implement the project. If project NPV is less than the investment, then the project proposal is rejected. In other words, letting $x(0)$ represent project NPV as evaluated at time $t = 0$ (the start of the project) and $I$ the required investment, -->

<!-- \begin{equation} -->
<!-- x(0) < I \:\: \rightarrow \:\: \text{reject project} -->
<!-- \label{eq:convCBA} -->
<!-- \end{equation} -->

<!-- However, oftentimes the investment $I$ can be decomposed into an upfront sunk cost $S$ required to initiate and sustain project activities, and a subsequent outlay $K$ required a considerable time later, after certain intermediate project goals have been met. The cost-benefit analysis (CBA) criterion can thus be formulated more realistically as follows. -->

<!-- \begin{equation} -->
<!-- e^{-rT} (E[x(T)] - K) < S \:\: \rightarrow \:\: \text{reject project} -->
<!-- \label{eq:npvIneq1} -->
<!-- \end{equation} -->

<!-- Where $r$ is the discount rate, and $T$ the time at which the subsequent outlay $K$ is required (usually the same as the project time horizon). -->


<!-- And the CBA criterion (inequality \ref{eq:npvIneq1}) simplifies as follows. -->

<!-- \begin{equation} -->
<!-- e^{(m - r) T} x(0) - e^{-rT} K < S \:\: \rightarrow \:\: \text{reject project} -->
<!-- \label{eq:npvIneq2} -->
<!-- \end{equation} -->

<!-- Moreover, project managers and stakeholders usually have the option to cancel the subsequent outlay $K$ if critical intermediate project goals are not met. More specifically, they can choose to cancel the outlay if the project NPV evaluated at time $T$ is less than the outlay $K$. The decision criterion may thus be expressed even more realistically as follows. -->

<!-- \begin{equation} -->
<!-- e^{-rT} E[\max(x(T) - K, 0)] < S \:\: \rightarrow \:\: \text{reject project} -->
<!-- \label{eq:rovRaw} -->
<!-- \end{equation} -->

<!-- The left hand side of this inequality is the project ROV. -->
<!-- <!-- what authors, starting with Myers [-@myers1977determinants], refer to as the "real option value"--- because it is analogous to the value of a European call option in financial markets. -->
<!-- <!-- Since the term was first coined, the real options literature has become vast. See, for example, Trigeorgis [-@trigeorgis1993real], Hayes and Garvin [-@hayes1982managing], McGrath and MacMillan [-@mcgrath2000assessing], and references for introductions to, extensions of, and variations on the subject. For a special focus on research projects as real options, see Doctor, Newton, and Pearson [-@doctor2001managing], and Newton, Paxson, and Widdicks [-@newton2004real]. K{\"o}ppl-Turyna and K{\"o}ppl [-@koppl2013real] survey the relatively scant literature on ROV approaches to agricultural investments. -->
<!-- <!-- Omitted from this survey is an exploratory assessment of the potential usefulness of an ROV approach to agricultural venture capital decisions by Wang and Tang [-@wang2010research]. IF of 0.5 so don't mention it-->
<!-- <!-- In this literature, the real option value (ROV) approach to project valuation (Inequality \ref{eq:rovRaw}) is often construed as an alternative to the "NPV approach".  -->

<!-- Inequality \ref{eq:rovRaw} describes the ROV approach for a 1-stage project. One of the main objectives of the present article is the extension of this approach to multistage projects. The first step in this task is to develop the closed form expression for 1-stage ROV. -->
<!-- <!-- mention low uptake of ROV here? -->
<!-- <!-- So, what does the present article focus on?...As mentioned in the Introduction, ...1-stage. and no focus on AR4D -->
<!-- <!-- # Method --> 

<!-- Now, by definition, the log change in $x(t)$ over any finite time interval $\tau$ is expected to be zero. -->

<!-- \begin{equation} -->
<!-- E \left[ \ln \left(\frac{x(\tilde{t})}{x(t)} \right) \right]\biggr|_t  = 0 -->
<!-- \end{equation} -->

<!-- In other words, any expected changes are already, by definition, included in the ex-ante impact assessment. This is true even if one knows there is a good chance that future assessments will differ from the present assessment as more information becomes available after key test points in the research. (The "good chance" of future assessments differing from the present assessment is captured in the volatility parameter $s$.) By Equation \ref{eq:meanLn}, then, it follows that -->
<!-- <!-- $m = r$ and $E[x(\tilde{t})]\bigr|_t = e^{r\tau} x(t)$.  Since all expected changes in project NPV are included in the ex-ante assessment of NPV, then the expected instantaneous arithmetic rate of change of project NPV is, by definition, just the discount rate $r$. -->

<!-- \begin{equation} -->
<!-- m = \frac{s^2}{2} -->
<!-- \label{eq:ar4dRate} -->
<!-- \end{equation} -->

<!-- And so, by Equation \ref{eq:ExTt}, the expected value of project NPV at the future time $\tilde{t}$, as evaluated at the present ($t$), is -->

<!-- \begin{equation} -->
<!-- E[x(\tilde{t})]\bigr|_{t} = e^{\frac{s^2}{2} \tau} x(t) -->
<!-- \end{equation} -->

<!-- And the present value of $E[x(T)]\bigr|_{t = 0}$ is just the same multiplied by the discount factor $e^{-r\tau}$. -->
<!-- The present value of t $x(t)$ discounted back to the time of evaluation is $e^{-r \tau} x(t)$ -->
<!-- Let $y(t) = e^{-r \tau} x(t)$. Then $E[y(T)]\bigr|_t = e^{-(r - s^2/2) \tau} x(t)$ -->
<!-- This may be interpreted as risk adjusted discounting. -->


## Risk non-neutrality and the NPV growth rate in far-from-market real options contexts

<!-- Another major source of complexity resulting in low adoption of ROV thinking regards the confused interpretation, in real options contexts, of the financial artifact known as "risk-neutral valuation". -->
The derivation of equation \ref{eq:rov} in the Appendix via the method of straightforward integration is atypical of the ROV literature. Most authors instead cite the Black-Scholes partial differentiation equation [@black1973valuation] as the source of the ROV formula. The method of straightforward integration is followed here because it is a considerably simpler method, and is stripped of financial trappings. In financial contexts, the Black-Scholes approach is advantageous because it generates a whole class of functional forms known as the "financial derivatives", of which the European call option formula (the financial analogue to equation \ref{eq:rov}) is just one.

More importantly, the Black-Scholes approach reveals, as a by-product, the deep result known as the principle of risk-neutral valuation: If it is not possible to make risk-free profits above the risk-free rate of return (the "no-arbitrage" rule), then investors are risk-neutral, i.e. "investors do not increase the expected return they require from an investment in order to compensate for increased risk" [@hull9thEdition]. Mathematically, this means that $m = r$ (where $r$, in financial contexts, refers to the risk-free rate of return).

The principle of risk-neutral valuation rests squarely upon the no-arbitrage rule, which is enforced through the market. This is fine in the financial context. However, in real options contexts, there is no clear theoretical or empirical basis for the no-arbitrage rule. Real project NPV is not a traded good, and there is no clear mechanism that might serve as a market analogue. On the contrary, most ROV contexts, especially research contexts, may be characterized as far-from-market---or even market failures, which the underlying project is supposed to redress. As a matter of simple observation, moreover, most project donors and managers do not seem to be risk-neutral; i.e., they seem to require an increase in expected project NPV to justify funding for a project with increased risk.

Critics note that the ROV literature is silent and/or conflicted on this point [@borison2005real; @block2007real]; and this has surely contributed to the complexity resulting in low adoption of ROV in real world decision making. It is not uncommon for ROV studies and surveys to assume risk-neutral valuation without any justification (see, for example, Trigeorgis [-@trigeorgis1993real], Majd and Pindyck [-@majd1987time], or Kemna [-@kemna1993case]). Some studies acknowledge the invalidity of the no-arbitrage argument in ROV contexts, but instead invoke "complete markets" to justify risk-neutral valuation (see, for example, Pennings and Lint [-@pennings1997option]). However, the complete markets assumption implies that 1) project NPV can be simulated by a portfolio of traded securities, and hence project risk can be hedged away by buying and/or selling these traded securities; and 2) project managers actually engage in the buying and selling of securities necessary to achieve this hedge. One may say without controversy that neither (1) nor (2) are common features of AR4D project management landscapes.

Nonetheless, a very simple, straightforward reason exists for setting $m = r$ in far-from-market settings: By the very definition of NPV as the discounted value of future impacts, NPV is effectively expected to appreciate at the discount rate $r$.
<!-- Conversely put, an expected NPV growth rate different from $r$ implies that the program NPV is inaccurately estimated. In the AR4D context, then, setting $m = r$ is tantamount to assuming that project NPV is accurately estimated. (This is a very strong, but nonetheless de facto, assumption implicit in any NPV estimate.) -->
<!-- Mathematically, the absence of any empirical or theoretical premise for risk-neutral valuation in far-from-market real options contexts means that there is no reason to set $m$ equal to $r$. -->
<!-- ## The far-from-market Black-Scholes PDE -->
<!-- But Black and Scholes' insight can be decomposed into two consecutive insights. The first insight is that, by eliminating the random terms in equation \ref{eq:bsInsight1}, the resulting expression is deterministic. And it equates a composite evolution in terms of $\Delta f$ and $\Delta x$ on the left-hand side to a time evolution $\Delta t$ on the right-hand side. Regardless of the no-arbitrage rule, it follows trivially that -->
<!-- \begin{equation} -->
<!-- \Delta f - \frac{\partial f}{\partial x} \Delta x = \left( f - \frac{\partial f}{\partial x} x \right) \kappa \Delta t -->
<!-- \end{equation} -->
<!-- <!-- So long as -->
<!-- <!-- \begin{equation} -->
<!-- <!-- \kappa = \frac{\frac{\partial f}{\partial t} + \frac{1}{2} \frac{\partial^2 f}{\partial x^2} s^2 x^2}{f - \frac{\partial f}{\partial x} x} -->
<!-- <!-- \end{equation} -->
<!-- <!-- holds. -->
<!-- Where $\kappa$ is constant with respect to the interval $\Delta t$. -->
<!-- The second insight is about resolving the value of $\kappa$. In financial markets, the no-arbitrage rule requires that $\kappa = r$. In the absence of the no-arbitrage rule, however, the $r$ in the Black-Scholes PDE must be replaced by $\kappa$. Solving this non-market version of the Black-Scholes PDE at the boundary condition $f(T) = \max(x(T) - K, 0)$ and comparing it to equation \ref{eq:EmaxTK}, which is obtained through straightforward integration, reveals that $\kappa$ must default to $m$. In the absence of the no-arbitrage rule, or any other overriding mechanism, then, the Black-Scholes PDE must default to -->
<!-- \begin{equation} -->
<!-- \left( f - \frac{\partial f}{\partial x} x \right) m = \frac{\partial f}{\partial t} + \frac{1}{2} \frac{\partial^2 f}{\partial x^2} s^2 x^2 -->
<!-- \label{eq:ffmBSpde} -->
<!-- \end{equation} -->
<!-- This is the far-from-market Black-Scholes PDE. -->
<!-- the now deterministic equation means that the evolution in terms of $\Delta f$ and $\Delta x$ on the left-hand side of equation \ref{eq:bsInsight1} may be rewritten in terms of a time evolution $\Delta t$. That is, we have an equation of the following form. -->
<!-- the evolution of the left-hand side must be constant over the interval $\Delta t$. This means -->
<!-- \begin{equation} -->
<!-- a \Delta f - b \Delta x = c \Delta t -->
<!-- \end{equation} -->
<!-- [Where $a$ ...] -->
<!-- Regardless of the no-arbitrage argument, it follows trivially that -->
<!-- \begin{equation} -->
<!-- \begin{split} -->
<!-- a f \kappa \Delta t - b x \kappa \Delta t  &= c \Delta t \\ -->
<!-- (a f - b x) \kappa \Delta t  &= c \Delta t -->
<!-- \end{split} -->
<!-- \end{equation} -->
<!-- And hence, trivially, -->
<!-- \begin{equation} -->
<!-- \begin{split} -->
<!-- a f \kappa \Delta t - b x \kappa \Delta t  &= c \Delta t \\ -->
<!-- (a f - b x) \kappa \Delta t  &= c \Delta t -->
<!-- \end{split} -->
<!-- \end{equation} -->





























### Closed form expression for 1-stage real option value

For a constant $C$ and a lognormally distributed random variable $q$ such that $\ln(q)$ is normally distributed with variance $\omega^2$, it can be shown through straightforward integration that

\begin{equation}
E[\max(q - C, 0)] = E[q] \Phi \left(\frac{\ln \left(\frac{E[q]}{C}\right) + \frac{\omega^2}{2}}{\omega} \right) - C \Phi \left(-\frac{\ln \left(\frac{E[q]}{C}\right) - \frac{\omega^2}{2}}{\omega} \right)
\label{eq:part1}
\end{equation}

Where $\Phi(\zeta)$ is the standard normal cumulative distribution function.

\begin{equation}
\Phi(\zeta) = \frac{1}{\sqrt{2 \pi}} \int^{\zeta}_{-\infty} e^{-\frac{\zeta^2}{2}}
\end{equation}

See Appendix for proof.

If $x(t)$ is the gBm described above, then it is lognormally distributed. More specifically, $\ln(x(t))$ is normally distributed with mean $\ln(x(\hat{t})) + (m - s^2 / 2 ) \tau$ and variance $s^2 \tau$, where $\hat{t}$ is the time at which the evaluation is made and $\tau = T - \hat{t}$. Hence, by equation \ref{eq:part1},

\begin{equation}
E[\max(x(T) - K, 0)]\bigr|_{t = \hat{t}} = e^{m \tau} x(\hat{t}) \Phi \left(\frac{\ln \left(\frac{x(\hat{t})}{K} \right) + \left(m + \frac{s^2}{2} \right) \tau}{s \sqrt{\tau}} \right) - K \Phi \left(\frac{\ln \left( \frac{x(\hat{t})}{K} \right) + \left(m - \frac{s^2}{2} \right) \tau}{s \sqrt{\tau}} \right)
\end{equation}

Or, more compactly,

\begin{equation}
E[\max(x(T) - K, 0)] \bigr|_{t = \hat{t}} = e^{m \tau} x(\hat{t}) \Phi(\delta + s \sqrt{\tau}) - K \Phi(\delta)
\label{eq:EmaxTK}
\end{equation}

Where

\begin{equation}
\delta = \frac{\ln \left(\frac{x(\hat{t})}{K} \right) + \left(m - \frac{s^2}{2} \right) \tau}{s \sqrt{\tau}}
\end{equation}
<!-- \begin{equation} -->
<!-- E[v(T)] \bigr|_{t = \hat{t}} = v(\hat{t}) e^{\alpha \tau} -->
<!-- \end{equation} -->
<!-- \begin{equation} -->
<!-- Var[\ln(v(T))] \bigr|_{t = \hat{t}} = \beta^2 \tau -->
<!-- \end{equation} -->
<!-- Where $\alpha = 1 / \tau \: E[\Delta v / v]$, and $\beta^2 = 1 / \tau \:Var[\Delta v / v]$. -->
<!-- (See Hull [@hull9thEdition] for details.) -->
<!-- Substituting $v(T)$ for $q$, $E[v(T)]\bigr|_{t = \hat{t}}$ for $E[q]$, and $Var[\ln(v(T))] \bigr|_{t = \hat{t}}$ for $\omega$, -->

Multiplying this through by the discount factor then gives the following closed form expression for ROV, evaluated at some time $t = \hat{t}$.

\begin{equation}
\begin{split}
ROV &= e^{-r\tau} E[\max(x(T) - K, 0)]\bigr|_{t = \hat{t}} \\
&= e^{(m - r) \tau} x(\hat{t}) \Phi(\delta + s \sqrt{\tau}) - e^{-r \tau} K \Phi(\delta)
\end{split}
\end{equation}

By the definition of NPV, the expected growth rate $m$ must equal the discount rate $r$; and so the ROV expression reduces to
<!-- In the ROV literature, $m$ is usually set equal to $r$ due to an artifact inherited from the financial context called "risk neutral valuation". Farther below, I demonstrate that there is no theoretical premise for the assumption of risk neutral valuation in the AR4D context. Nonetheless, $m$ may be set equal to $r$ on the basis that project NPV must, by definition, be expected to appreciate at the rate of $r$. -->
<!-- Setting $m$ to a value other than $r$ implies that project NPV is inaccurately estimated. Assuming project NPV is accurately estimated, then, it must be that $m = r$, and the ROV expression simplifies to -->

\begin{equation}
\begin{split}
ROV &= e^{-r\tau} E[\max(x(T) - K, 0)]\bigr|_{t = \hat{t}} \\
&= x(\hat{t}) \Phi(\delta + s \sqrt{\tau}) - e^{-r \tau} K \Phi(\delta)
\end{split}
\label{eq:rov}
\end{equation}

Where

\begin{equation}
\delta = \frac{\ln \left(\frac{x(\hat{t})}{K} \right) + \left(r - \frac{s^2}{2} \right) \tau}{s \sqrt{\tau}}
\end{equation}

### Developing real options intuition in the AR4D context

To build intuition, it is instructive to compare graphs of ROV (equation \ref{eq:rov}) and NPV (left-hand side of inequality \ref{eq:npvIneq2}) with respect to the NPV-to-cost ratio $x(0)/K$. In the financial context, this ratio is known as the "moneyness". The option is said to be "in the money" if the ratio is greater than one, "out of the money" if the ratio is less than one, and "at the money" if the ratio equals one. Options with a moneyness ratio well in excess of one are said to be "deep in the money". A generic example is given in the top panel of Figure \ref{fig:rovIllust}. Note that the difference between ROV and NPV shrinks as moneyness is higher. And note that deep in the money ROV does not differ significantly from NPV unless project risk, reflected in the volatility parameter $s$, is sufficiently high.

It is also instructive to keep an eye on the term $\Phi(\delta)$, plotted in the lower panel of Figure \ref{fig:rovIllust}. This is the probability that an out of the money option will expire in the money, thereby triggering exercise of the option. It therefore makes perfect sense that $\Phi(\delta)$ approaches one as the moneyness is higher; but note that it approaches one more slowly as project risk is higher.

```{r Fig1, fig.show = "hold", fig.width = 4, fig.height=4, fig.align="center", fig.cap="\\label{fig:rovIllust}A hypothetical project's real option value and net present value plotted together over a range of moneyness values. The black line marks 0, while the dotted red line marks the sunk cost $S$ beneath which the project is rejected. The multiple ROV plots correspond to different levels of project volatilitty ($s$). The higher the volatility, the greater the difference between ROV and NPV.", echo = FALSE}


OVfun <- function(X0, K, tau, mm, s, r, output = "OV"){
  
  d2 <- (log(X0 / K) + (mm - s^2 / 2) * tau) / (s * sqrt(tau))
  d1 <- d2 + s * sqrt(tau)
  N1 <- pnorm(d1)
  N2 <- pnorm(d2)
  
  OV <- exp((mm - r) * tau) * X0 * N1 - exp(-r * tau) * K * N2
  
  if(output == "OV"){
    out <- OV
  }
  
  if(output == "N2"){
    out <- N2
  }
  
  if(output == "N1"){
    out <- N1
  }
  
  return(out)
}
#===========================================================================
mm <- 0.035
r <- mm
tau <- 35
cv <- seq(0.5, 2, length.out = 3)
cvTxt <- c("low", "medium", "high")
s <- round(cv * mm * sqrt(tau), 2)
X0 <- 10
XoK <- seq(0.2, 3, length.out = 50)
#K <- seq(0.1, 3, length.out = 20) * X0
K <- X0 / XoK
NPV <- X0 - exp(-r * tau) * K
ns <- length(cv)
list_df <- list()
for(i in 1:ns){
  this_s <- s[i]
  ROV <- OVfun(X0, K, tau, mm, this_s, r, output = "OV")
  Phi2 <- OVfun(X0, K, tau, mm, this_s, r, output = "N2")
  df <- data.frame(xx = X0 / K, Type = paste("ROV", cvTxt[i], "risk"), Phi2, Value = ROV)
  list_df[[i]] <- df
}
df_npv <- data.frame(xx = X0 / K, Type = "NPV", Phi2 = NA, Value = NPV)
list_df[[ ns + 1]] <- df_npv

df_plot <- as.data.frame(do.call(rbind, list_df))
colnames(df_plot)[1] <- "x(0)/K"
# df_plot1 <- subset(df_plot, cv == cv[ns])
# df_plot1$cv <- NULL
# df_plot1 <- df_plot1 %>% gather(type, Value, ROV:NPV)
# df_plot2 <- subset(df_plot, cv != cv[ns])

#n <- length(unique(df_plot1$type))
n <- ns + 1
bag_of_colors <- randomcoloR::distinctColorPalette(k = 2 * n)
color_vec <- sample(bag_of_colors, n)

# gg <- ggplot()
# gg <- gg + geom_line(data = df_plot2, aes(x = `x(0)/K`, y = ROV,
#                                          group = cv),
#                      color = color_vec[2], lwd = 1)
# gg <- gg + geom_line(data = df_plot1, aes(x = `x(0)/K`, y = Value,
#                                           group = type, color = type),
#                      lwd = 1)
#----------------------------------------------------------------------------
# ROV vs. NPV plot
gg <- ggplot(df_plot, aes(x = `x(0)/K`, y = Value,
                          group = Type, color = Type))
gg <- gg + geom_line(lwd = 1)
gg <- gg + scale_color_manual(values = color_vec)
#gg <- gg + labs(y = "Value")
gg <- gg + geom_hline(yintercept = 2, color = "red", linetype = "dashed")
gg <- gg + geom_hline(yintercept = 0)
gg <- gg + theme_bw()
gg <- gg + theme(axis.text = element_blank(),
                 axis.title.y = element_text(size = axisTitle_size),
                 axis.title.x = element_blank(),
                 legend.title = element_blank(),
                 legend.position = "top",
                 legend.text = element_text(size = legendText_size))
gg <- gg + guides(color = guide_legend(nrow = 2, byrow = T))
gg1 <- gg
#----------------------------------------------------------------------------
# Phi2 plot
df_plot <- subset(df_plot, Type != "NPV")
gg <- ggplot(df_plot, aes(x = `x(0)/K`, y = Phi2,
                          group = Type, color = Type))
gg <- gg + geom_line(lwd = 1)
gg <- gg + scale_color_manual(values = color_vec[-1])
gg <- gg + labs(y = "Phi 2")
gg <- gg + theme_bw()
gg <- gg + theme(
  axis.text = element_text(size = axisText_size),
  axis.title = element_text(size = axisTitle_size),
  legend.title = element_blank(),
  legend.position = "none",
  legend.text = element_text(size = legendText_size))
gg2 <- gg
#----------------------------------------------------------------------------
gg1 + gg2 + plot_layout(ncol = 1, heights = c(1, 1 / 2))

```

The cost $K$ is commonly referred to as the "exercise cost", because it is incurred only in the event that the investor decides to exercise the option. The random variable $x(t)$ is commonly referred to as the "underlying". The term $\Phi(\delta + s \sqrt{\tau})$ is equal to the partial derivative $\partial ROV / \partial x$, and thus provides insight into ROV sensitivity to movements in the underlying. Although not graphed here, it is easy to see that $\Phi(\delta + s \sqrt{\tau})$ will also approach one as the moneyness is higher. This also makes perfect sense. It simply means that, as the probability of exercise grows and ROV becomes indistinguishable from NPV, so likewise do changes in ROV become indistinguishable from changes in the underlying NPV.

Figure \ref{fig:rovIllust} illustrates the importance of risk and reward when deciding whether or not to take an ROV approach to project appraisal. The ROV approach is suitable in the AR4D context because AR4D projects tend to be both high reward (i.e., deep in the money) and high risk. If AR4D projects were only high reward, with little risk, then there would be no point in calculating ROV, as it would not differ significantly from NPV.

### Real options with adandonment value \label{sec:abandVal}

It is easy and worthwhile to extend the ROV formula in equation \ref{eq:rov} to the slightly more general case where the project generates a guaranteed minimum benefit regardless of whether or not the project is successful. In the AR4D context, this guaranteed minimum benefit might correspond to the value of new or upgraded labs and testing facilities, and/or improved human capital through training. Let this guaranteed minimum benefit, also known as the project's abandonment value, be denoted $B$. Then the default CBA criterion (inequality \ref{eq:npvIneq2}) can be generalized to accommodate such cases as follows.

\begin{equation}
x(0) - e^{-rT} (K - B) < S \:\: \rightarrow \:\: \text{reject project}
\label{eq:npvIneqB}
\end{equation}

The ROV formula, meanwhile, can likewise be generalized as follows.

\begin{equation}
ROV = e^{-r T} E[\max(x(T) - K, B)] \:\:;\:\:\: B \geq 0
\label{eq:rovBraw}
\end{equation}

Such that the ROV decision criterion becomes

\begin{equation}
e^{-r T} E[\max(x(T) - K, B)] < S \:\: \rightarrow \:\: \text{reject project}
\label{eq:rovBrawCond}
\end{equation}

But note that, by the general formula for $\max(a, b)$, i.e.,

\begin{equation}
\max(a, b) = \frac{1}{2} (a + b - \left| a - b \right|)
\end{equation}

Equation \ref{eq:rovBraw} can be rewritten

\begin{equation}
ROV = e^{-r T} (E[\max(x(T) - K + B, 0)] + B)
\end{equation}

And hence, by equation \ref{eq:part1},

\begin{equation}
\begin{split}
ROV &= x(\hat{t}) \Phi(\delta + s \sqrt{\tau}) - e^{-r \tau} (K - B) \Phi(\delta) + B \\
&= x(\hat{t}) \Phi(\delta + s \sqrt{\tau}) - e^{-r \tau} K \Phi(\delta) +  e^{-r \tau} B( 1 + \Phi(\delta))
\end{split}
\label{eq:rovB}
\end{equation}

Where

\begin{equation}
\delta = \frac{\ln \left(\frac{x(\hat{t})}{K - B} \right) + \left(m - \frac{s^2}{2} \right) \tau}{s \sqrt{\tau}}
\end{equation}

And where it is easy to see that this reduces to equation \ref{eq:rov} when $B = 0$.

### Real options that scale with investment

Another way real options differ significantly from financial options is that the NPV $x(0)$ is usually a function of the investment $K$.

### Quantifying project NPV volatility \label{sec:volEst}

<!-- As noted above, AR4D projects are characterized by high, potentially disruptive, expected net benefits, but also by extreme uncertainty surrounding these expected net benefits. Expected project impacts are vulnerable to a host of both research and non-research related factors (to be discussed in more detail farther below), such that they can easily double or halve over the life of the project. Project appraisals that do not price in, or at least provide some treatment of, this vast uncertainty are thus of limited use to prospective donors. -->
<!-- given new additions to or subtractions from the list of countries targeted for release of the new technology. -->
One of the key advantages of ROV is that it provides a mechanism by which to factor uncertainty into project appraisals; and this is achieved through adjustments to the volatility parameter $s$. However, there remains the question of how to calculate or deduce a plausible value for $s$. In the financial context, a direct calculation is possible based on easily accessible historical price time series. In the real options context, direct calculation is generally not possible, since analogous historical project NPV time series data usually do not exist.

In practice, applied ROV studies generally make an educated guess at the volatility parameter, and then conduct sensitivity analysis around the guess (as, for example, in Majd and Pindyck [-@majd1987time] or Kemna [-@kemna1993case]). While this approach is, in some sense, pragmatic, it is also problematic, because it is difficult to build intuition about what constitutes a plausible value of $s$ for a given project. Sensitivity analysis is one way of building such intuition, but it is a blunt, laborious instrument; and the intuition gained as a result generally does not transfer to other projects. In an alternative, novel approach, Pennings and Lint [-@pennings1997option] directly calculate the volatility parameter based on a painstakingly assembled project NPV time series. While clearly more rigorous than the former approach, this is less expedient and probably not possible under most AR4D time, resource, and data constraints.

To find an intermediate point on the rigor-pragmatism spectrum, consider: While it is true that research managers (and/or stakeholders and/or the foresight economists conducting the project appraisal) generally do not have an intuitive grasp of the project NPV volatility parameter $s$ itself, they do generally have some idea of the uncertainty surrounding project NPV estimates, such that they can be asked to quantify minimum and maximum bounds on project NPV, in addition to the NPV estimation itself. For example, they can say that NPV is $x(\hat{t})$, but that it might be six times that amount, or half that amount. (Or they may give the same information in terms of magnitude, which is then easily transformed into percentage terms.)

These upper and lower percentage errors may then be interpreted as the upper and lower bounds on the $95\%$ confidence interval about the expected percentage change in project NPV between the start and end of the project. Another phrase for "percentage change" is "arithmetic return" (call this $\mathcal{R}$), which may then be converted to a log return ($\ell = \ln(x(T) / x(\hat{t}))$) by the formula $\ell = \ln(\mathcal{R} + 1)$. Now, recall that since $x(t)$ follows a gBm with $m = r$, then $\ell$ is normally distributed with mean $\mu$ and variance $\sigma^2$ given by

\begin{equation}
\begin{split}
\mu = E[\ell] \bigr|_{t = \hat{t}} &= \left(r - \frac{s^2}{2} \right) \tau \\
\sigma^2 = Var[\ell] \bigr|_{t = \hat{t}} &= s^2 \tau
\end{split}
\end{equation}

And the upper and lower log returns, $\bar{\ell}$ and $\underline{\ell}$, may be expressed as follows.

\begin{equation}
\begin{split}
\bar{\ell} &= \mu + z \sigma \\
\underline{\ell} &= \mu - z \sigma
\end{split}
\end{equation}

Where $z = 1.96$ is the standard score corresponding to the $95\%$ confidence interval of a normally distributed random variable. (The standard score can of course be adjusted to match the practitioner's idea of a suitable confidence interval defined by the bounds $\bar{\ell}$ and $\underline{\ell}$.) Subtracting the second equation from the first and rearranging then gives an expression for the volatility parameter $s$ in terms of known parameters.
<!-- This system of equations then yields three expressions for the volatility parameter $s$ in terms of known parameters (i.e. in terms of the upper and lower log returns $\bar{\ell}, \underline{\ell}$, the discount rate $r$, the project time horizon $T$, and the standard score $z$). -->
<!-- \begin{equation} -->
<!-- \begin{split} -->
<!-- s &= \frac{z \pm \sqrt{z^2 - 1 / 2 (\bar{\ell} - r \tau)}}{ \sqrt{\tau}} \\ -->
<!-- &= \frac{-z \pm \sqrt{z^2 - 1 / 2 (\underline{\ell} - r \tau)}}{ \sqrt{\tau}} \\ -->
<!-- &= \sqrt{ r - \frac{\bar{\ell} + \underline{\ell}}{2 \tau}} -->
<!-- \end{split} -->
<!-- \end{equation} -->

\begin{equation}
s = \frac{1}{2 \sqrt{\tau} z} (\bar{\ell} - \underline{\ell})
\end{equation}
<!-- yMax <- 1.1 -->
<!-- yMin <- -0.6 -->
<!-- # Define confidence interval of interest, usually 95% -->
<!-- zBound <- 2#1.96 -->
<!-- # Back out s and m -->
<!-- s <- (yMax - yMin) / (2 * zBound * sqrt(tauN)) -->
<!-- mu <- (yMax + yMin) / 2 -->
<!-- m <- (mu / tauN + s^2 / 2) -->
<!-- m <- 1 / (2 * tauN) * (yMax + yMin + (yMax - yMin)^2 / (4 * zBound^2)) -->

Once $s$ is deduced, the growth rate coefficient of variation $\frac{s}{r \sqrt{\tau}}$ can be calculated, which serves as a plausibility check on the parameter values, project NPV estimates, and project NPV upper and lower bounds. The growth rate coefficient of variation is a handy, normalized measure of project NPV volatility over time. One should not be surprised to see high coefficients of variation in the AR4D context. A low coefficient of variation may indicate that ROV will not differ significantly from NPV, and that there is thus no point in calculating ROV. Note that expected project NPV log return $\mu$ can also be calculated using the deduced value for $s$, which may serve as an additional plausibility check.
<!-- and that the expected project NPV at future times may be calculated by equation \ref{eq:ExT}. These calculations -->
<!-- Note that the system of equations above can still be solved for $m$ and $s$ in the absence of an estimate for one of the bounds $\bar{\ell}$ or $\underline{\ell}$, if an estimate for the expected log return $\mu$ can be obtained. -->

## Formalizing the $n$-fold real option value of multistage AR4D projects \label{sec:resStages}

<!-- [@mitchell1988managing] -->
AR4D projects usually unfold in a series of stages, the precise structure of which can vary considerably from one project to another. For the purpose of exposition, the focus here is on transgenic projects. Transgenic projects tend to follow the generic four stage process defined below, regardless of crop, technology, and institution. For completeness, a pre-project and post-project stage are also defined, although these typically fall outside of the donor's funding horizon.
<!--The staging of conventional breeding projects must be assessed on a project by project basis, as this varies considerably across crops, technology, and research institution. The emergence of marker assisted breeding further complicates any effort to impose a generic structure on such projects. -->

* Pre-project: A discovery or "blue skies research" stage, during which new technologies are "discovered" through a careful exploration and extension of existing research---in which serendipity plays a key role---in conjunction with a careful prioritization of research demand. The output of this stage is a new technology proof-of-concept, usually in the form of a novel genotype expressing a set of desired traits, together with a set of recommended farm management practices.

1) A basic replication or scaling up stage, whereby a technology proof-of-concept generated in the discovery phase is reproduced in greenhouse and/or confined field trials, in conjunction with a more refined assessment and prioritization of research demand, especially target populations and ecologies, and the relevant socioeconomic enabling environments (particularly seed systems, government policies, institutions, and markets).

2) A multi-location, multi-season testing stage, whereby successful specimens generated in the preceding stage are taken for further confined field trials under distinct agronomic conditions over multiple cropping seasons.

3) A regulatory dossier stage, wherein detailed agronomic, environmental, and toxicological data, mostly generated during the preceding stages, is compiled into dossier(s) for submission to the National Competent Authorities (NCAs) in the countries targeted for release of the new technology.

4) A deregulation stage, during which the regulatory dossier(s) generated during the previous stage is/are submitted to the NCA(s), which may request further clarification and testing of certain aspects of the proposed technology.

* Post-project: A release and uptake stage, during which the new technology is made available for distribution in the target populations and environments. This stage depends critically on the quality of the socioeconomic enabling environment in the target countries, in conjunction with stewardship from the research institution to ensure correct provision and application of the improved germplasm at the farm level. The holistic "Agricultural Innovation System" view of AR4D considers this stage to be an integral part of AR4D projects [@klerkx2010adaptive].

<!-- The duration of project stages varies depending on technology, crop, and research institution; but, as a general rule, transgenic projects (stages 1-4) tend to last 9-11 years. -->
<!-- development of the plant, and the trait assessment, are all known. Thus, none of the costs  -->
<!-- associated with research and development of the gene constructs or of testing them in  -->
<!-- transgenic  events  are  included  (cloning  and  testing  different  R  genes,  testing  the  -->
<!-- durability  of  LB  resistance,  evaluating  different  strategies  for  deployment,  socio- -->
<!-- economic  targeting  studies,  communicating  the  results  to  stakeholders,  and  building  -->
<!-- biotechnology  and  biosafety  facilities).  Also  excluded  are  the  costs  of  building  the  -->
<!-- capacity  of  partners,  scientific  publications,  and  participation  in  scientific  conferences  -->
<!-- apart from any such activities strictly needed for the LBr product development. The costs  -->
<!-- of  obtaining  freedom-to-operate  and/or  intellectual  property  rights  over  the  relevant  -->
<!-- technology are also excluded. It is assumed that these issues and costs have been dealt  -->
<!-- with  at  the  previous  stage  of  the  proof-of-concept  and  has  defined  which  technology  -->
<!-- element will be eventually used for product development. -->
Before formalizing the extension of real option value to AR4D projects of four, or any number $n$, stages, note that the default CBA approach in expression \ref{eq:npvIneqB} can be extended to $n$-stage projects as follows.
<!-- the decision criterion for a  may be formalized as follows. -->
<!-- \begin{equation} -->
<!-- e^{- r \tau_n} E[x(T_n)] \bigr|_{t = 0} - \Sigma_{i = 1}^{n - 1} e^{-r \tau_i} (K_i - B_i) < K_n \:\: \rightarrow \:\: \text{reject project} -->
<!-- \label{eq:npvIneqBN} -->
<!-- \end{equation} -->

\begin{equation}
x(0) - \Sigma_{i = 1}^{n - 1} e^{-r T_i} (K_i - B_i) < K_n \:\: \rightarrow \:\: \text{reject project}
\label{eq:npvIneqBN2}
\end{equation}

Where $T_i$, $K_i$, and $B_i$ are the time horizon, exercise cost, and abandonment value, respectively, of the $i^{th}$ stage.

To formalize the $n$-fold real option value of AR4D projects, it is helpful to first do some relabeling. Let the real option value of a single stage project (equation \ref{eq:rovBraw}) evaluated at some time $\hat{t}$ henceforth be relabeled $f_1(\hat{t})$, with time horizon $T_1$, exercise cost $K_0$, and abandonment value $B_0$. And let $f_0(t) = x(t)$. Then equation \ref{eq:rovBraw} can be written

\begin{equation}
f_1(\hat{t}) = e^{-r \tau_1} E[\max(f_0(T_1) - K_0, B_0)] \bigr|_{t = \hat{t}}
\end{equation}

(Where $\tau_i = T_i - \hat{t}$.)

As explained above, this is the value of the option, but not the obligation, to disburse the funds required to cover final launch and scaling up costs $K_0$ less abandonment value $B_0$, once the research project is finished. Now consider the real option value of a 2-stage project $f_2(\hat{t})$.

\begin{equation}
f_2(\hat{t}) = e^{- r \tau_2} E[\max(f_1(T_2) - K_1, B_1)] \bigr|_{t = \hat{t}}
\end{equation}

This is the value of the option, but not the obligation, to disburse the funds $K_1$ required to implement the second stage of the 2-stage project, once the first stage is finished. Note that $K_1$ corresponds to the sunk cost $S$ in equation \ref{eq:rovBrawCond}. The time horizon $T_2$ refers to the duration of stage 1, and $B_1$ is the abandonment value, if any, generated by the end of stage 1.

Likewise, for a 3-stage project,

\begin{equation}
f_3(\hat{t}) = e^{- r \tau_3} E[\max(f_2(T_3) - K_2, B_2)] \bigr|_{t = \hat{t}}
\end{equation}

Where $T_3$ is the duration of the first stage, $B_2$ is any abandonment value associated with this stage, and $K_2$ the cost of implementing the second stage, of the 3-stage project.

And so on, for any $n$-stage project, the $n$-fold option value $f_n(\hat{t})$ may be defined

\begin{equation}
f_n(\hat{t}) = e^{- r \tau_n} E[\max(f_{n - 1}(T_n) - K_{n - 1}, B_{n - 1})] \bigr|_{t = \hat{t}} \:\:;\:\:\: B_{n - 1} \geq 0
\label{eq:rovNraw}
\end{equation}

In other words, $n$-fold option value is the present value of the option to continue with stage 2 of the project, the value of which is itself the present value of the option to continue with stage 3 of the project, and so forth, up until the present value of the option to continue with stage $n$ of the project, which is itself the present value of the option to implement the new technology---which is itself the project NPV $x(t)$.

The ROV of each stage has as its underlying the ROV of the subsequent stage, which has as its underlying the ROV of the subsequent stage, and so forth, up until the stage 1 ROV, which has as its underlying the project NPV itself. The exercise cost of a given stage is the cost of implementing the subsequent stage.

The formal 1-stage ROV funding decision criterion (inequality \ref{eq:rovBrawCond}) may thus be generalized to $n$-stage projects as follows.

\begin{equation}
e^{-rT_n} E[\max(f_{n - 1}(T_n) - K_{n - 1}, B_{n - 1})] < K_n \:\: \rightarrow \:\: \text{reject project}
\end{equation}

Or, more compactly,

\begin{equation}
f_n < K_n \:\: \rightarrow \:\: \text{reject project}
\label{eq:rovNcond}
\end{equation}

Farther below, I demonstrate that, if $x(t)$ is lognormally distributed, then so is $f_n(t)$. Equation \ref{eq:part1} may therefore be invoked to establish a closed form expression for $f_n(\hat{t})$, if $x(t)$ is lognormally distributed. Before getting to this main result, however, it is first necessary to defend the assumption of lognormal $x(t)$, and to extract far-from-market real options from the thicket of "risk neutral valuation".

## Derivation of a closed form expression for $n$-fold real option value

<!-- ...it is now time to derive the $n$-fold real option value formula. To begin, consider the far-from-market Black-Scholes PDE (equation \ref{eq:ffmBSpde}) for the 1-fold real option value function $f_1$, rearranged as an expression for $r f_1$. -->
<!-- The derivation consists of two steps. First we show that the $n$-fold real option value $f_n$ is lognormally distributed if project NPV $x(t)$ is lognormally distributed. Then, we show A closed form expression for $f_n$ then follows from equation \ref{eq:part1}. -->
If $x(t)$ is a gBm, then, by Ito's lemma, the evolution of a function $f(x, t)$ is described as follows.

\begin{equation}
\Delta f = \left( x m \frac{\partial f}{\partial x} + \frac{\partial f}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f}{\partial x^2} \right) \Delta t + \frac{\partial f}{\partial x} x s \epsilon \sqrt{\Delta t}
\label{eq:itoLem}
\end{equation}

(See Hull [-@hull9thEdition] for details.)

Black and Scholes [-@black1973valuation] famously noted that equations \ref{eq:gbmEq} and \ref{eq:itoLem} could be combined so as to eliminate the random term as follows.

\begin{equation}
\Delta f - \frac{\partial f}{\partial x} \Delta x = \left(\frac{\partial f}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f}{\partial x^2} \right) \Delta t
\label{eq:bsInsight1}
\end{equation}

In the financial context, the left-hand side of this equation may be thought of as the instantaneous evolution over the increment $\Delta t$ of a portfolio long one share of the financial derivative $f$ and short a quantity $\partial f / \partial x$ of the underlying security $x(t)$. This is where Black and Scholes applied their no-arbitrage argument: Since the random---i.e. risky---term has been eliminated from equation \ref{eq:bsInsight1}, then the profit or loss of this portfolio over the increment $\Delta t$ must be riskless. That is, it must change at the risk free rate $r$.

\begin{equation}
\Delta f - \frac{\partial f}{\partial x} \Delta x = \left( f - \frac{\partial f}{\partial x} x \right) r \Delta t
\end{equation}

In the AR4D context, the risk free rate and no-arbitrage rule are replaced by the discount rate (also denoted by $r$), and the definition of NPV, which requires that the value of the riskless portfolio on the left-hand side of equation \ref{eq:bsInsight1} must change at the rate of $r$.

Equating the right-hand side of this equation with the right-hand side of the previous equation, the $\Delta t$'s cancel, resulting in the Black-Scholes partial differentiation equation (PDE).

\begin{equation}
\left( f - \frac{\partial f}{\partial x} x \right) r = \frac{\partial f}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f}{\partial x^2}
\end{equation}

(Black and Scholes went on to solve this PDE under the boundary condition $f(T) = \max(x(T) - K, 0)$, resulting in an expression for $f$ identical to the one derived in equation \ref{eq:rov} by straightforward integration.)

Now, letting $f = f_1$ and rearranging the Black-Scholes PDE as an expression for $r f_1$,

\begin{equation}
r f_1 = r x \frac{\partial f_1}{\partial x} + \frac{\partial f_1}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f_1}{\partial x^2}
\end{equation}

And considering Ito's lemma for $f_1$,

\begin{equation}
\Delta f_1 = \left( r x \frac{\partial f_1}{\partial x} + \frac{\partial f_1}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f_1}{\partial x^2} \right) \Delta t + \frac{\partial f_1}{\partial x} x s \epsilon \sqrt{\Delta t}
\end{equation}

Note that the right-hand side of the previous expression is equal to the first term in parentheses on the right-hand side of Ito's lemma for $f_1$. Ito's lemma for $f_1$ may thus be rewritten as follows.

\begin{equation}
\Delta f_1 = r f_1 \Delta t + x \frac{\partial f_1}{\partial x} s \epsilon \sqrt{\Delta t}
\label{eq:itoLemf1}
\end{equation}

And note that the second term on the right-hand side can be rewritten in terms of an elasticity.

\begin{equation}
x \frac{\partial f_1}{\partial x} s \epsilon \sqrt{\Delta t} = f_1 \eta_{1, 0} s \epsilon \sqrt{\Delta t}
\end{equation}

Where $\eta_{1, 0}$ is the elasticity of $f_1$ with respect to the project NPV $x$. That is, defining $f_0 = x$,

\begin{equation}
\begin{split}
\eta_{i, 0} &= \frac{f_0}{f_i} \frac{\partial f_i}{\partial f_0} = \frac{\partial \ln(f_i)}{\partial \ln(f_0)} \\
&= \frac{1}{100} \frac{\% \Delta f_i}{\% \Delta f_0}
\end{split}
\end{equation}

Equation \ref{eq:itoLemf1} can be rewritten

\begin{equation}
\Delta f_1 = r f_1 \Delta t + f_1 \eta_{1, 0} s \epsilon \sqrt{\Delta t}
\label{eq:gbmf1}
\end{equation}

By which it follows that $\Delta f_1 / f_1$ is normally distributed with mean $r \Delta t$ and variance $s^2 \eta_{1, 0}^2 \Delta t$. In other words, $f_1$ is a gBm, such that $\ln(f_1)$ is normally distributed with mean $\ln(f_1(\hat{t})) + \left(r - s^2 \eta_{1, 0}^2 / 2 \right) \tau_1$ and variance $s^2 \eta_{1, 0}^2 \tau_1$.

It follows, moreover, that a 2-fold real option value function $f_2(f_1, t)$ also has a Black-Scholes PDE.

\begin{equation}
r f_2 = \frac{\partial f_2}{\partial f_1} f_1 + \frac{\partial f_2}{\partial t} + \frac{\eta_{1, 0}^2 s^2 f_1^2}{2} \frac{\partial^2 f_2}{\partial f_1^2}
\end{equation}

With corresponding Ito's lemma

\begin{equation}
\Delta f_2 = \left( r f_1 \frac{\partial f_2}{\partial f_1} + \frac{\partial f_2}{\partial t} + \frac{\eta_{1, 0}^2 s^2 f_1^2}{2} \frac{\partial^2 f_2}{\partial f_1^2} \right) \Delta t + \frac{\partial f_2}{\partial f_1} f_1 \eta_{1, 0} s \epsilon \sqrt{\Delta t}
\end{equation}

Such that

\begin{equation}
\begin{split}
\Delta f_2 &= r f_2 \Delta t + f_1 \eta_{1, 0}  \frac{\partial f_2}{\partial f_1} s \epsilon \sqrt{\Delta t} \\
&= r f_2 \Delta t + f_2 \eta_{2, 0} s \epsilon \sqrt{\Delta t}
\end{split}
\label{eq:gbmf2}
\end{equation}

By which it follows that $\Delta f_2 / f_2$ is normally distributed with mean $r \Delta t$ and variance $s^2 \eta_{2, 0}^2 \Delta t$; and that $\ln(f_2)$ is normally distributed with mean $\ln(f_2(\hat{t})) + \left(r - s^2 \eta_{2, 0}^2 / 2 \right) \tau_2$ and variance $s^2 \eta_{2, 0}^2 \tau_2$. That is, $f_2$ is also a gBm.

And so on for $f_3$, $f_4$, $\dots$, $f_n$, there exists a Black-Scholes PDE

\begin{equation}
\left( f_n - \frac{\partial f_n}{\partial f_{n - 1}} f_{n - 1} \right) r = \frac{\partial f_n}{\partial t} + \frac{\eta_{n - 1, 0}^2 s^2 f_{n - 1}^2}{2} \frac{\partial^2 f_n}{\partial f_{n - 1}^2}
\end{equation}

Which, when combined with the corresponding Ito's lemma, results in an expression for $\Delta f_n$ as a gBm.

\begin{equation}
\Delta f_n = r f_n \Delta t + f_n \eta_{n, 0} s \epsilon \sqrt{\Delta t}
\label{eq:gbmfn}
\end{equation}

Such that the growth rate $\Delta f_n / f_n$ is normally distributed with the same constant mean as that of $\Delta f_0 / f_0$---i.e. $r \Delta t$---and variance $s^2 \eta_{n, 0}^2 \Delta t$, which differs from that of $\Delta f_0 / f_0$ by a factor of $\eta_{n, 0}^2$; and such that $\ln(f_n)$ is normally distributed with mean $\ln(f_n(\hat{t})) + \left(r - s^2 \eta_{n, 0}^2 / 2 \right) \tau_n$ and variance $s^2 \eta_{n, 0}^2 \tau_n$.

By equation \ref{eq:part1}, then,

\begin{equation}
f_n = f_{n - 1}(\hat{t}) \Phi(\delta_n + s \eta_{n - 1, 0} \sqrt{\tau_n}) - e^{-r \tau_n} K_n \Phi(\delta_n)
\label{eq:rovN}
\end{equation}

Where

\begin{equation}
\delta_n = \frac{\ln \left(\frac{f_{n - 1}(\hat{t})}{K_n} \right) + \left(r - \frac{s^2 \eta_{n - 1, 0}^2}{2} \right) \tau_n}{s \eta_{n - 1, 0} \sqrt{\tau_n}}
\end{equation}

Which may be generalized to include abandonment value $B_n$ by following the steps in section \ref{sec:abandVal}.
<!-- equation \ref{eq:rovB}, -->

\begin{equation}
f_n = f_{n - 1}(\hat{t}) \Phi(\delta_n + s \eta_{n - 1, 0} \sqrt{\tau_n}) - e^{-r \tau_n} (K_n \Phi(\delta_n) - B_n ( 1 + \Phi(\delta_n)))
\label{eq:rovBn}
\end{equation}

Where

\begin{equation}
\delta_n = \frac{\ln \left(\frac{f_{n - 1}(\hat{t})}{K_n - B_n} \right) + \left(r - \frac{s^2 \eta_{n - 1, 0}^2}{2} \right) \tau_n}{s \eta_{n - 1, 0} \sqrt{\tau_n}}
\end{equation}

In the case where $n = 1$, it is easy to see that this reduces to the 1-fold real option value formula in equation \ref{eq:rovB}. For multistage projects ($n > 1$), equation \ref{eq:rovBn} must be evaluated recursively, as follows:

For $i = 1$ to $i = n$,

1) Using $f_{i - 1}$ and $\eta_{i - 1, 0}$, evaluate $f_i$;

2) Using $f_i$, $f_{i - 1}$, and $\eta_{i - 1, 0}$, evaluate $\eta_{i, i - 1}$;

3) Evaluate $\eta_{i, 0} = \eta_{i, i - 1} \eta_{i - 1, 0}$;

(Remember that $f_0 = x$.)

The equation for the elasticity $\eta_{i, i - 1}$ evaluated in step 2 works out to

\begin{equation}
\begin{split}
\eta_{i, i - 1} &= \frac{f_{i - 1}}{f_i} (\Phi(\delta_i + s \sqrt{\tau_i}) + f_{i - 1} \frac{\partial \eta_{i - 1, 0}}{\partial f_{i - 1}} \phi(\delta_i + s \sqrt{\tau_i})) \\
&= \frac{f_{i - 1}}{f_i} (\Phi(\delta_i + s \sqrt{\tau_i}) + (1 - \eta_{i - 1, 0}) \phi(\delta_i + s \sqrt{\tau_i}))
\end{split}
\end{equation}

When $i = 1$, note that this reduces to

\begin{equation}
\begin{split}
\eta_{i, i - 1} &= \frac{f_0}{f_1} \Phi(\delta_1 + s \sqrt{\tau_1}) \\
&= \frac{x(\hat{t})}{f_1} \Phi(\delta_1 + s \sqrt{\tau_1})
\end{split}
\end{equation}

The algorithm thus begins by calculating the ROV of the last ($n^{th}$) research stage, $f_1$. This ROV is then the underlying of the ROV of the second to last stage, $f_2$, which is then the underlying of $f_3$, and so forth, up to $f_n$, which is the ROV of stage 1 research.

An R script of the algorithm is included in the Appendix.
<!-- Remarkably, then, the mean fractional change in $n$-fold option value is equal to that of project NPV, $m \Delta t$. The variance of percentage changes in $n$-fold option value similarly has the parameter $s$ in common with the variance of percentage changes in project NPV, but differs from the latter by a factor of $\eta_{n,0}^2$, which changes in each time step. -->
<!-- And -->
<!-- \begin{equation} -->
<!-- \begin{split} -->
<!-- \eta_{n - 1, 0} &= \frac{\partial \ln(f_n)}{\partial \ln(f_{n - 1})} = \frac{f_{n - 1}}{f_n} \frac{\partial f_n}{\partial f_{n - 1}} \\ -->
<!-- &= e^{(m - r) T_n} \frac{f_{n - 1}}{f_n} \left( \Phi_{n, 1} + f_{n - 1} \phi_{n, 1} \frac{\partial \eta_{n - 1, 0}}{\partial f_{n - 1}} s \sqrt{T_n} \right) \\ -->
<!-- &= \begin{cases} -->
<!-- 1, & n = 1 \\ -->
<!-- e^{(m - r) T_n} \frac{f_{n - 1}}{f_n} \left( \Phi_{n, 1} + f_{n - 1} \phi_{n, 1} \frac{\partial \eta_{n - 1, 0}}{\partial f_{n - 1}} s \sqrt{T_n} \right), & n > 1 -->
<!-- \end{cases} -->
<!-- \end{split} -->
<!-- \end{equation} -->
<!-- equations \ref{eq:gBmN} and \ref{eq:bsPDEn} imply that a function $f_{n + 1}$ of an underlying geometric Brownian motion $f_n$  -->
<!-- \begin{equation} -->
<!-- mf_{n + 1} = \frac{\partial f_n}{\partial f_{n - 1}} f_{n - 1} m + \frac{\partial f_n}{\partial t} + \frac{s^2 f_{n - 1}^2 \eta_{n - 1, 0}^2}{2} \frac{\partial^2 f_n}{\partial f_{n - 1}^2} -->
<!-- \label{eq:bsPDEn} -->
<!-- \end{equation} -->
<!-- note that by equation \ref{eq:bsPDEn},  -->


<!-- https://stackoverflow.com/questions/58187514/r-markdown-place-an-appendix-after-the-references-section -->
<!-- # References {-} -->
<!-- <div id="refs"></div> -->
<!-- <div id="refs"></div> -->
<!-- \printbibliography[heading=none] -->
<!-- \def\printbibliography{} -->

<!-- \pagebreak -->
<!-- https://tex.stackexchange.com/questions/520480/how-make-appendix-of-paper-number-equations-in-there -->
<!-- In YAML: -->
<!-- \usepackage{etoolbox} -->
<!-- \appto\appendix{\counterwithin{equation}{section}} -->


<!-- \label{eq:part1} -->

<!-- _Part 2_ -->

<!-- Let $q$ equal the geometric Brownian motion $v(t)$ defined in equation \ref{eq:defVt}, and note that -->

<!-- \begin{equation} -->
<!-- E[v(T)] \bigr|_{t = \hat{t}} = v(\hat{t}) e^{\alpha \tau} -->
<!-- \end{equation} -->

<!-- \begin{equation} -->
<!-- Var[\ln(v(T))] \bigr|_{t = \hat{t}} = \beta^2 \tau -->
<!-- \end{equation} -->
<!-- <!-- Where $\alpha = 1 / \tau \: E[\Delta v / v]$, and $\beta^2 = 1 / \tau \:Var[\Delta v / v]$. -->

<!-- (See Hull [@hull9thEdition] for details.) -->
<!-- <!-- Substituting $v(T)$ for $q$, $E[v(T)]\bigr|_{t = \hat{t}}$ for $E[q]$, and $Var[\ln(v(T))] \bigr|_{t = \hat{t}}$ for $\omega$, -->

<!-- Then equation \ref{eq:part1} can be rewritten as follows. -->

<!-- \begin{equation} -->
<!-- E[max(v(T) - C, 0)]\bigr|_{t = \hat{t}} = v(\hat{t}) e^{\alpha \tau} \Phi \left(\frac{\ln(v(\hat{t}) / C) + (\alpha + \beta^2 / 2) \tau}{\beta \sqrt{\tau}} \right) - C \Phi \left(\frac{\ln(v(\hat{t}) / C) + (\alpha - \beta^2 / 2) \tau}{\beta \sqrt{\tau}} \right) -->
<!-- \end{equation} -->

<!-- Or, more compactly, -->

<!-- \begin{equation} -->
<!-- E[max(v(T) - C, 0)]\bigr|_{t = \hat{t}} = v(\hat{t}) e^{\alpha \tau} \Phi(\delta + s \sqrt{\tau}) - C \Phi(\delta) -->
<!-- \end{equation} -->

<!-- Where -->

<!-- \begin{equation} -->
<!-- \delta = \frac{\ln(v(\hat{t}) / C) + (\alpha - \beta^2 / 2) \tau}{\beta \sqrt{\tau}} -->
<!-- \end{equation} -->

<!-- Multiplying this by the discount factor then gives -->
<!-- \begin{equation} -->
<!-- e^{-r \tau} E[max(v(T) - C, 0)]\bigr|_{t = \hat{t}} = v(\hat{t}) e^{(\alpha - r) \tau} \Phi(\delta + \beta \sqrt{\tau}) - e^{-r \tau} C \Phi(\delta) -->
<!-- \end{equation} -->

<!-- This is the ROV formula in equation \ref{eq:rov}. -->

## R script of the $n$-fold real option value model, with abandonment value {-}

This R script is written for clarity, not for efficiency.

````markdown

rovN <- function(X0, Kvec, Bvec = NULL, Tvec, s, r){
N <- length(Kvec)
if(is.null(Bvec)){Bvec <- rep(0, N)}
fNm1 <- X0
etaNm10 <- 1
etaVec <- c()
fnVec <- c()
sNm1vec <- c()
Phi2vec <- c()
Phi1vec <- c()
for(i in 1:N){
Kn <- Kvec[i]
Bn <- Bvec[i]
Tn <- rev(cumsum(rev(Tvec)))[i]
dn <- (log(fNm1 / (Kn - Bn)) + (r - s^2 * etaNm10^2 / 2) * Tn) / (s * etaNm10 * sqrt(Tn))
Phi1 <- pnorm(dn + s * etaNm10 * sqrt(Tn))
Phi2 <- pnorm(dn)
fn <- fNm1 * Phi1 - exp(-r * Tn) * Kn * Phi2 + exp(-r * Tn) * Bn * (1 + Phi2)
fnVec[i] <- fn
sNm1vec[i] <- s * etaNm10
Phi2vec[i] <- Phi2
Phi1vec[i] <- Phi1
phi1 <- dnorm(dn + s * etaNm10 * sqrt(Tn))
dfndfNm1 <- (Phi1 + phi1 * (1 - etaNm10) * s * sqrt(Tn))
etaNnM1 <- fNm1 / fn * dfndfNm1
etaNm10 <- etaNnM1 * etaNm10
fNm1 <- fn
etaVec[i] <- etaNm10
}
underVec <- c(X0, fnVec[-N])
df_out <- data.frame(Stage = rev(1:N), Fold = 1:N,
OVn = fnVec, fnM10 = underVec,
KnM1 = Kvec, etaN0 = etaVec,
sNm1 = sNm1vec, Phi2 = Phi2vec)
colnames(df_out)[-1] <- c("Fold (i)",
"i-fold ROV", "Value of underlying",
"Exercise cost", "Elasticity w.r.t. project NPV",
"Standard dev. of underlying",
"Probability of exercise")
return(df_out)

}

````

<!-- >"[The proven LB resistance] technology is applied to the target [potato] variety in order to obtain a reduced number of candidate...transgenic events. Once the lead gene construct has been developed, a relatively large number of explants is screened by successive procedures in order to identify transgenic events from among the explants, remove the transgenic events with backbone vector sequences, select the transgenic events exhibiting high resistance to LB in confined field trials [CFTs], and select the transgenic events with the minimum copy number of R genes. The output of this process is a small number of candidate pre-commercial transgenic events selected for wide area testing, as well as molecular characterisation data to be used in the compilation of the regulatory dossier later on" []. -->

<!-- Stage 2: Wide area testing -->

<!-- >"The candidate...transgenic events are evaluated under normal and/or managed field conditions for resistance to LB. Depending on the diversity of the environment where the potato variety is grown in the target country, CFTs are conducted in multiple locations to assess any environmental effect on the trait performance. At the same time, the agronomic performance of the candidate pre-commercial transgenic events are assessed and compared to the non-transformed counterpart. This may include testing the number and kinds of fungicide spray needed to prevent productivity losses under exceptionally heavy disease pressure. These field trials also test for any negative impact of the trait on key performance attributes, yield or tuber quality, or potential negative environmental interactions. At the end of this process, one ...transgenic event is identified" []. -->

<!-- Stage 3: Compilation of the regulatory dossier -->

<!-- >"In this process, the best pre-commercial transgenic event (selected under [Stage] 2) is examined to ensure compliance with all regulatory requirements established by the National Competent Authority (NCA), and the corresponding regulatory dossier is compiled for submission to the NCA. Much of the data required for this examination have already been generated and collected under previous...[stages]. Therefore the respective costs assessed ...[here] are only those incurred in the processing, filing, and redaction of the results of the laboratory and the field observations for the regulatory dossier. Only the compositional assessment data and the safety assessment data (protein production and characterisation data for allergenicity and toxicity assessments) are generated and collected under Process 3. At the end of this process, a regulatory dossier is ready for submission to the NCA" []. -->

<!-- sub-processes: molecular characterisation data are generated under sub-process 1.5; while the environmental impact and phenotypic/agronomic data are generated under sub-processes 2.1 and 2.2. -->
<!-- Stage 4: Registration and regulatory affairs -->
<!-- >"Once the regulatory dossier has been submitted it must be defended, amended, and completed before the NCA authorises commercial production. This process may involve a variety of activities, including public advocacy, lobbying, and submission of additional information not included in the original dossier. In this study, it is assumed that any requests made by the NCA will concern existing information and data that were not included in the regulatory dossier, or data included in the regulatory dossier but not analysed using the methodology favored by the examiners, or not discussed at the level of details desired by the examiners. Hence, participating institutions assessed the cost and duration of this process assuming that the NCA makes its requests and decisions solely on scientific bases directly related to the regulatory dossier, and that it does not request further regulatory trials. The end product of this process is the authorization of commercial production of one transgenic LBr potato variety in one of the target  -->
<!-- countries" []. -->

<!-- The far-from-market Black-Scholes PDE can be rearranged into an expression for $fm$ as follows. -->


<!-- And, repeating the steps in equations \ref...\ref, -->

<!-- \begin{equation} -->
<!-- \ln \left(\frac{f}{f\bigr|_{t = 0}}  \right) ~ \phi \left(\left(m - \frac{s^2 \eta_{f, x}^2}{2} \right) T, s^2 \eta_{f, x}^2 T \right) -->
<!-- \end{equation} -->

<!-- The function $f$ of the geometric Brownian motion $x$ is thus itself a geometric Brownian motion. That is to say, the log returns of $f$ are normally distributed with mean $\left(m - \frac{s^2 \eta_{f, x}^2}{2} \right) T$ and variance $s^2 \eta_{f, x}^2 T$. -->

<!-- Now consider a function $g$ which represents the option value of the option value $f$. That is, -->

<!-- \begin{equation} -->
<!-- g = e^{-r T_g} E[\max(f(T_g) - K_f, 0)] -->
<!-- \end{equation} -->

<!-- Where $T_g$ is the time from the present moment ($t = 0$) until maturity of $g$ (the start of the subsequent real option $f$, if exercised), and $K_f$ is the cost of the stage associated with $f$ that is triggered if $f(T_g) > K_f$. -->

<!-- By Ito's Lemma, the evolution of $g$ may be expressed -->

<!-- \begin{equation} -->
<!-- \Delta g = \left( \frac{\partial g}{\partial f} f m + \frac{\partial g}{\partial t} + \frac{s^2 f^2 \eta_{f, x}^2}{2} \frac{\partial^2 g}{\partial f^2} \right) \Delta t + s f \varespsilon_{f, x} \frac{\partial g}{\partial f} \epsilon \sqrt{\Delta t} -->
<!-- \end{equation} -->

<!-- Subtracting $\partial g/\partial f \Delta f$ from $\Delta g$ and applying Black-Scholes insight #2 results in the following non-market Black-Scholes PDE for $g$. -->

<!-- \begin{equation} -->
<!-- mg = \frac{\partial g}{\partial f} f m + \frac{\partial g}{\partial t} + \frac{s^2 f^2 \eta_{f, x}^2}{2} \frac{\partial^2 g}{\partial f^2} -->
<!-- \label{eq:bsPDEg} -->
<!-- \end{equation} -->

<!-- So that $mg$ may be substituted for the first term on the right-hand side of the previous equation, giving -->

<!-- \begin{equation} -->
<!-- \Delta g = m g \Delta t + s f \varespsilon_{f, x} \frac{\partial g}{\partial f} \epsilon \sqrt{\Delta t} -->
<!-- \end{equation} -->

<!-- And the second term may also be rewritten as follows. -->

<!-- \begin{equation} -->
<!-- \begin{split} -->
<!-- \Delta g &= m g \Delta t + s g \varespsilon_{g, f} \varespsilon_{f, x} \epsilon \sqrt{\Delta t} \\ -->
<!-- &= m g \Delta t + s g \varespsilon_{g, x} \epsilon \sqrt{\Delta t} -->
<!-- \end{split} -->
<!-- \label{eq:gbmg} -->
<!-- \end{equation} -->

<!-- By which it follows that -->

<!-- \begin{equation} -->
<!-- \frac{\Delta g}{g} ~ \phi(m \Delta t, s^2 \eta_{g, x}^2 \Delta t) -->
<!-- \end{equation} -->

<!-- And -->

<!-- \begin{equation} -->
<!-- \ln \left(\frac{g}{g \bigr|_{t = 0}}  \right) ~ \phi \left(\left(m - \frac{s^2 \eta_{g, x}^2}{2} \right) T, s^2 \eta_{g, x}^2 T \right) -->
<!-- \end{equation} -->

<!-- The option on the option, or "compound option", $g$ is thus also a geometric Brownian motion. -->

<!-- By now, the astute reader will have noticed a pattern, such that the geometric Brownian motions in equations \ref..., \ref{eq:gbmf}, and \ref{eq:gbmg} may be consolidated into a single equation, as follows. Letting $f_0 = x$, $f_1 = f$, and $f_2 = g$, -->

<!-- \begin{equation} -->
<!-- \Delta f_n = m f_n \Delta t + s \eta_{n, 0} \epsilon \sqrt{\Delta t} -->
<!-- \label{eq:gBmN} -->
<!-- \end{equation} -->

<!-- For $n = 0, 1, 2$. (Where, to be clear, $\eta_{n, 0} = \frac{\partial \ln(f_n)}{\partial \ln(f_0)}$.) -->

<!-- And the non-market Black-Scholes PDEs in equations \ref..., \ref{eq:bsPDEf}, and \ref{eq:bsPDEg} can likewise be consolidated as follows. -->

<!-- \begin{equation} -->
<!-- mf_n = \frac{\partial f_n}{\partial f_{n - 1}} f_{n - 1} m + \frac{\partial f_n}{\partial t} + \frac{s^2 f_{n - 1}^2 \eta_{n - 1, 0}^2}{2} \frac{\partial^2 f_n}{\partial f_{n - 1}^2} -->
<!-- \label{eq:bsPDEn} -->
<!-- \end{equation} -->

<!-- For $n = 1, 2$. To extend equations \ref{eq:gBmN} and {eq:bsPDEn} to $n > 2$, note that, since $f_n$ is a geometric Brownian motion, then, by Ito's Lemma, the evolution of a function $f_{n + 1}$ of $f_n$ can be expressed -->

<!-- \begin{equation} -->
<!-- \Delta f_{n + 1} = \left( \frac{\partial f_{n + 1}}{\partial f_n} f_n m + \frac{\partial f_{n + 1}}{\partial t} + \frac{s^2 f_n^2 \eta_{n, 0}^2}{2} \frac{\partial^2 f_{n + 1}}{\partial f_n^2} \right) \Delta t + s f_n \varespsilon_{n, 0} \frac{\partial f_{n + 1}}{\partial f_n} \epsilon \sqrt{\Delta t} -->
<!-- \label{eq:gbmNproof1} -->
<!-- \end{equation} -->

<!-- Subtracting $\partial f_{n + 1} / \partial f_n \Delta f_n$ from $\Delta f_{n + 1}$ and applying Black-Scholes insight #2 in the non-market context results in the non-market Black-Scholes PDE for $f_{n + 1}$. -->

<!-- \begin{equation} -->
<!-- mf_{n + 1} = \frac{\partial f_{n + 1}}{\partial f_n} f_n m + \frac{\partial f_{n + 1}}{\partial t} + \frac{s^2 f_n^2 \eta_{n, 0}^2}{2} \frac{\partial^2 f_{n + 1}}{\partial f_n^2} -->
<!-- \end{equation} -->

<!-- By which the previous equation reduces to -->

<!-- \begin{equation} -->
<!-- \begin{split} -->
<!-- \Delta f_{n + 1} &= m f_{n + 1} \Delta t + s f_n \varespsilon_{n, 0} \frac{\partial f_{n + 1}}{\partial f_n} \epsilon \sqrt{\Delta t} \\ -->
<!-- &= m f_{n + 1} \Delta t + s f_{n + 1} \varespsilon_{n, 0} \varespsilon_{n + 1, n} \epsilon \sqrt{\Delta t} \\ -->
<!-- &= m f_{n + 1} \Delta t + s f_{n + 1} \varespsilon_{n + 1, 0} \epsilon \sqrt{\Delta t} -->
<!-- \end{split} -->
<!-- \label{eq:gbmNproof3} -->
<!-- \end{equation} -->

<!-- By which it follows that -->

<!-- \begin{equation} -->
<!-- \frac{\Delta f_{n + 1}}{f_n} ~ \phi(m \Delta t, s^2 \eta_{f_{n + 1}, f_n}^2 \Delta t) -->
<!-- \label{eq:gBmNp1} -->
<!-- \end{equation} -->

<!-- And -->

<!-- \begin{equation} -->
<!-- \ln \left(\frac{f_{n + 1}}{f_{n + 1} \bigr|_{t = 0}}  \right) ~ \phi \left(\left(m - \frac{s^2 \eta_{n + 1, 0}^2}{2} \right) T_{n + 1}, s^2 \eta_{n + 1, 0}^2 T_{n + 1} \right) -->
<!-- \end{equation} -->

<!-- That is, $f_{n + 1}$ is a geometric Brownian motion. Since $f_{n + 1}$ is a geometric Brownian motion, then the same steps in equations \ref{eq:gbmNproof1} to \ref{eq:gbmNproof3} may be followed to show that a function $f_{n + 2}$ of $f_{n + 1}$ is also a geometric Brownian motion, and so on for a function $f_{n + 3}$ of $f_{n + 2}$, ad infinitum. Equations \ref{eq:gBmN} and \ref{eq:bsPDEn} therefore extend to $n > 2$. -->

<!-- Since $f_n$ is a geometric Brownian motion, then substituting $f_n$ for $q$ in equation \ref{eq:rovRaw} gives the following formula for the N-fold real option value, i.e., the option value of an underlying option value (which may itself be the option value of an option value). -->

<!-- \begin{equation} -->
<!-- f_n = e^{(m - r) T_n} (f_{n - 1} \Phi(\delta_n + \eta_{n - 1, 0} s \sqrt{T_n}) - e^{-r T_n} K_n) -->
<!-- \end{equation} -->

<!-- Where -->

<!-- \begin{equation} -->
<!-- \delta_n = \frac{\ln \left( \frac{f_{n - 1}}{K_n} \right) + \left( m - \frac{s^2 \eta_{n - 1, 0}^2}{2} \right) T_n}{s \eta_{n - 1, 0} \sqrt{T_n}} -->
<!-- \end{equation} -->

<!-- And -->

<!-- \begin{equation} -->
<!-- \begin{split} -->
<!-- \eta_{n - 1, 0} &= \frac{\partial \ln(f_{n - 1})}{\partial \ln(f_0)} = \frac{f_0}{f_{n - 1}} \frac{\partial f_{n - 1}}{\partial f_0} \\ -->
<!-- &= e^{(m - r) T_{n - 1}} \frac{f_0}{f_{n - 1}} \Phi_{{n - 1}, 1} -->
<!-- \end{split} -->
<!-- \end{equation} -->

<!-- By Ito's Lemma, the evolution of an $n$-fold option may be expressed -->

<!-- \begin{equation} -->
<!-- \Delta f_n = \left( \frac{\partial f_n}{\partial x} m x + \frac{\partial f_n}{\partial t} + \frac{1}{2} \frac{\partial^2 f_n}{\partial x^2} s^2 x^2 \right) \Delta t + \frac{\partial f_n}{\partial x} s x \epsilon \sqrt{\Delta t} -->
<!-- \label{eq:itoLemN} -->
<!-- \end{equation} -->

<!-- As in the previous section, the random term in this expression may be eliminated by subtracting $\partial f_n / \partial x \Delta x$ from $\Delta f_n$. That is, -->

<!-- \begin{equation} -->
<!-- \Delta f_n - \frac{\partial f_n}{\partial x} \Delta x = \left(\frac{\partial f_n}{\partial t} + \frac{1}{2} \frac{\partial^2 f_n}{\partial x^2} s^2 x^2 \right) \Delta t -->
<!-- \end{equation} -->

<!-- Which, as above, trivially implies -->

<!-- \begin{equation} -->
<!-- \Delta f_n - \frac{\partial f_n}{\partial x} \Delta x = \left( f_n - \frac{\partial f_n}{\partial x} x \right) \kappa \Delta t -->
<!-- \end{equation} -->

<!-- Substituting the right-hand side of this equation for the left-hand side of the previous equation then yields the following expression. -->

<!-- \begin{equation} -->
<!-- \kappa f_n - \frac{\partial f_n}{\partial x} x \kappa = \frac{\partial f_n}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f_n}{\partial x^2} -->
<!-- \label{eq:bsPDEfn} -->
<!-- \end{equation} -->

<!-- Isolating $\kappa f_n$ and letting $\kappa = m$, -->

<!-- \begin{equation} -->
<!-- m f_n = \frac{\partial f_n}{\partial x} x m + \frac{\partial f_n}{\partial t} + \frac{s^2 x^2}{2} \frac{\partial^2 f_n}{\partial x^2} -->
<!-- \label{eq:bsPDEfn} -->
<!-- \end{equation} -->

<!-- But note that the right-hand side of this expression is equal to the first term in parenthesis on the right-hand side of equation \ref{eq:itoLemN}. Therefore, -->

<!-- \begin{equation} -->
<!-- \Delta f_n = m f_n \Delta t + s x \frac{\partial f_n}{\partial x} \epsilon \sqrt{\Delta t} -->
<!-- \label{eq:itoLemN2} -->
<!-- \end{equation} -->

<!-- The second term on the right-hand side can also be reduced as follows. -->

<!-- \begin{equation} -->
<!-- s x \frac{\partial f_n}{\partial x} \epsilon \sqrt{\Delta t} = s f_n \eta_{f, x} \epsilon \sqrt{\Delta t} -->
<!-- \end{equation} -->

<!-- Where $\eta_{n, 0}$ is the elasticity of $f_n$ with respect to the project NPV $x$. That is, -->

<!-- \begin{equation} -->
<!-- \begin{split} -->
<!-- \eta_{n, 0} &= \frac{x}{f_n} \frac{\partial f_n}{\partial x} = \frac{\partial \ln(f_n)}{\partial \ln(x)} \\ -->
<!-- &= \frac{1}{100} \frac{%\Delta f_n}{%\Delta x} -->
<!-- \end{split} -->
<!-- \end{equation} -->

<!-- Equation \ref{eq:itoLemN2} can thus be rewritten -->

<!-- \begin{equation} -->
<!-- \Delta f_n = m f_n \Delta t + s f_n \eta_{n, 0} \epsilon \sqrt{\Delta t} -->
<!-- \label{eq:gbmf} -->
<!-- \end{equation} -->

<!-- By which it follows that $\Delta f_n / f_n$ is normally distributed with mean $m \Delta t$ and variance $s^2 \eta_{n, 0}^2 \Delta t$. From this, it follows that $f_n$ is a geometric Brownian movement, such that $\ln(f_n)$ is normally distributed with mean $\ln(f_n(\hat{t})) + \left(m - \frac{s^2 \eta_{n, 0}^2}{2} \right) \tau_n$ and variance $s^2 \eta_{n, 0}^2 \tau_n$. -->

<!-- \begin{equation} -->
<!-- \ln \left(\frac{f}{f\bigr|_{t = 0}}  \right) ~ \phi \left(\left(m - \frac{s^2 \eta_{f, x}^2}{2} \right) T, s^2 \eta_{f, x}^2 T \right) -->
<!-- \end{equation} -->
<!-- The function $f$ of the geometric Brownian motion $x$ is thus itself a geometric Brownian motion. That is to say, the log returns of $f$ are normally distributed with mean $\left(m - \frac{s^2 \eta_{f, x}^2}{2} \right) T$ and variance $s^2 \eta_{f, x}^2 T$. -->

# Disclosure/Conflict-of-Interest Statement {-}

The author declares that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.

# Author Contributions {-}

Benjamin Schiek is the sole author of this article, responsible for all aspects of its conception, content, drafting, and revision.
<!--When determining authorship the following criteria should be observed:
- Substantial contributions to the conception or design of the work; or the
acquisition, analysis, or interpretation of data for the work; AND
- Drafting the work or revising it critically for important intellectual
content; AND
- Final approval of the version to be published ; AND
- Agreement to be accountable for all aspects of the work in ensuring that
questions related to the accuracy or integrity of any part of the work are
appropriately investigated and resolved.
Contributors who meet fewer than all 4 of the above criteria for authorship
should not be listed as authors, but they should be acknowledged.
(http://www.icmje.org/roles_a.html)-->
<!-- The statement about the authors and contributors can be up to several sentences -->
<!-- long, describing the tasks of individual authors referred to by their initials -->
<!-- and should be included at the end of the manuscript before the References -->
<!-- section. -->

# Acknowledgments {-}

Funding: The Foresight and Metrics Initiative

# References {-}

::: {#refs}
:::

# Figures {-}

<!-- # ```{r, Figure-1, ref.label = "graph", results = "hide", echo = FALSE, message = FALSE, fig.height=4, fig.width=4, fig.align='center', fig.cap='Figure caption', out.width = "85mm", out.height = "85mm"} -->
<!-- # You can also refer to code chunks from above to place figures at the bottom. -->
<!-- ``` -->





<!-- # Define functions -->
<!-- #------------------------------------------------------------------------ -->
<!-- # N-fold ROV w/abandonment value function -->
<!-- rovN <- function(X0, Kvec, Bvec = NULL, Tvec, s, r){ -->
<!--   #---------------------------------------------------------------- -->
<!--   # Definition of input parameters: -->
<!--   # X0 - Project NPV as of today -->
<!--   # Kvec - Vector of launch costs associated with each project stage, starting with the last stage -->
<!--   # Bvec - Vector of abandonment values associated with each project stage, starting with the last stage. Default setting is 0 for each stage (NULL). -->
<!--   # Tvec - Vector of time horizons for each stage, starting with the last stage -->
<!--   # s - NPV volatility -->
<!--   # r - Discount rate -->
<!--   #---------------------------------------------------------------- -->
<!--   # Recursive calculation of the ROV of each project stage, starting with the last stage first  -->
<!--   N <- length(Kvec) # Get number of project stages -->
<!--   if(is.null(Bvec)){Bvec <- rep(0, N)} -->
<!--   # f_0 <- X0 -->
<!--   # etaNm10 <- 1 -->
<!--   eta_0 <- 1 -->
<!--   etaVec <- c() -->
<!--   fiVec <- c() -->
<!--   s_im1Vec <- c() -->
<!--   Phi2vec <- c() -->
<!--   Phi1vec <- c() -->
<!--   for(i in 1:N){ -->
<!--     # 1) Using f_{i-1} and eta_{i-1,0}, evaluate f_{i} -->
<!--     # (Note f_0 = X0 and eta_{0,0} = 1) -->
<!--     if(i == 1){ -->
<!--       f_im1 <- X0 -->
<!--       eta_im10 <- 1 -->
<!--     }else{ -->
<!--       f_im1 <- f_i -->
<!--       eta_im10 <- eta_i0 -->
<!--     } -->
<!--     Ki <- Kvec[i] -->
<!--     Bi <- Bvec[i] -->
<!--     Ti <- rev(cumsum(rev(Tvec)))[i] -->
<!--     di <- (log(f_im1 / (Ki - Bi)) + (r - s^2 * eta_im10^2 / 2) * Ti) / (s * eta_im10 * sqrt(Ti)) -->
<!--     Phi1 <- pnorm(di + s * eta_im10 * sqrt(Ti)) -->
<!--     Phi2 <- pnorm(di) -->
<!--     f_i <- f_im1 * Phi1 - exp(-r * Ti) * Ki * Phi2 + exp(-r * Ti) * Bi * (1 + Phi2) -->
<!--     # 2) Using f_{i}, f_{i-1}, and eta_{i-1,0}, evaluate eta_{i,i-1}. -->
<!--     fiVec[i] <- f_i -->
<!--     s_im1Vec[i] <- s * eta_im10 -->
<!--     Phi2vec[i] <- Phi2 -->
<!--     Phi1vec[i] <- Phi1 -->
<!--     phi1 <- dnorm(di + s * eta_im10 * sqrt(Ti)) -->
<!--     eta_iim1 <- f_im1 / f_i * (Phi1 + phi1 * (1 - eta_im10))# * s * sqrt(Ti)) -->
<!--      # <- f_im1 / f_i * dfnd_im1 -->
<!--     # dfndf_im1 <- ((Phi1 + phi1 * (1 - eta_im10) * s * sqrt(Ti)) -->
<!--     # eta_im10 <- f_im1 / f_i * dfnd_im1 -->
<!--     #etaNnM1 <- fNm1 / fn * dfndfNm1 # Elasticity of ROV of stage n with respect to ROV of stage n-1 -->
<!--     # 3) Evaluate eta_{i,0} = eta_{i,i-1} * eta_{i-1,0} -->
<!--     eta_i0 <- eta_iim1 * eta_im10 # Elasticity of ROV of stage n-1 with respect to project NPV -->
<!--     etaVec[i] <- eta_i0 -->
<!--   } -->
<!--   underVec <- c(X0, fiVec[-N]) -->
<!--   df_out <- data.frame(Stage = rev(1:N), Fold = 1:N, -->
<!--                        OVn = fiVec, valUnder = underVec, -->
<!--                        Kvec, etaVec, -->
<!--                        s_im1Vec, Phi2vec) -->
<!--   colnames(df_out)[-1] <- c("Fold (i)", -->
<!--                             "i-fold ROV", "Value of underlying", -->
<!--                             "Exercise cost", "Elasticity w.r.t. project NPV", -->
<!--                             "Standard dev. of underlying", -->
<!--                             "Probability of exercise") -->
<!--   return(df_out) -->

<!-- } -->
<!-- #============================================================================ -->
<!-- #============================================================================ -->
<!-- # End function definition -->
<!-- #============================================================================ -->
<!-- #============================================================================ -->
<!-- # Define parameters -->
<!-- #--------------------------------------------------------------------------- -->
<!-- # Set abandonment value to 0 for starters -->
<!-- # Separate out the stage 4 cost and total time horizon less launch time -->
<!-- Bvec <- c(0, 0, 0, 0) -->
<!-- n <- length(Kvec) - 1 -->
<!-- K1 <- Kvec[n + 1] -->
<!-- Tn <- sum(Tvec[-1]) -->
<!-- #--------------------------------------------------------------------------- -->
<!-- # Crude project NPV estimate loosely based on expected adoption rates, time horizons, etc. -->
<!-- rYrly_discrete <- 0.08 #0.035 -->
<!-- rQrly_discrete <- (1 + rYrly_discrete)^(1 / 4) - 1 -->
<!-- Tadopt <- 20 * 4 -->
<!-- Timpact <- 10 * 4 -->
<!-- yrlyBen <- 1 * 10^6 # (Assuming very low adoption) -->
<!-- x0 <- sum(yrlyBen / (1 + rQrly_discrete)^(Tn + Tadopt + 1:Timpact)) -->
<!-- # (Override) -->
<!-- x0 <- 1.23 * 10^6 -->
<!-- #--------------------------------------------------------------------------- -->
<!-- # Convert discrete discount rate to continuous discount rate -->
<!-- r <- round(log(1 + rQrly_discrete), 3) -->
<!-- #---------------------------------------------------------------------------- -->
<!-- # Derive s and m -->
<!-- # Define confidence interval of interest, usually 95% (z = 1.96) -->
<!-- zBound <- 1.96 -->
<!-- # Max and min log return elicited from experts/stakeholders -->
<!-- # 1) Elicit upper and lower pctg error in project NPV -->
<!-- # 2) Interpret as upper and lower bounds on 95% conf interval of arithmetic return -->
<!-- # 3) Convert arithmetic return to log return by formula log ret = log(1 + arith ret) -->
<!-- yMaxA <- 7.15#1.85 -->
<!-- yMinA <- -0.8#-0.45 -->
<!-- yMax <- log(1 + yMaxA) -->
<!-- yMin <- log(1 + yMinA) -->
<!-- # bTerm <- -(2 * yMin + 8 / 3 * zBound^2) -->
<!-- # yMax <- 1 / 2 * (-bTerm - sqrt(bTerm^2 + 4)) -->
<!-- # Back out s and m -->
<!-- s <- (yMax - yMin) / (2 * zBound * sqrt(Tn)) -->
<!-- # m <- 1 / (2 * Tn) * (yMax + yMin + (yMax - yMin)^2 / (4 * zBound^2)) -->
<!-- # \begin{split} -->
<!-- # s &= \frac{z \pm \sqrt{z^2 - 1 / 2 (\bar{\ell} - r \tau)}}{ \sqrt{\tau}} \\ -->
<!-- # &= \frac{-z \pm \sqrt{z^2 - 1 / 2 (\underline{\ell} - r \tau)}}{ \sqrt{\tau}} \\ -->
<!-- # &= \sqrt{ r - \frac{\bar{\ell} + \underline{\ell}}{2 \tau}} -->
<!-- # \end{split} -->
<!-- # \end{equation} -->

<!-- s <- round(s, 3) -->
<!-- #m <- round(m, 3) -->
<!-- #m - r -->
<!-- # Make sure m > r -->
<!-- #---------------------------------------------------------------------------- -->
<!-- # Plausibility check: -->
<!-- # Coefficient of variation -->
<!-- cv <- round(s / (r * sqrt(Tn)), 2) -->
<!-- #cv -->
<!-- # CV graph -->
<!-- # yMaxVec <- seq(0.1, 2.5, length.out = 35) -->
<!-- # sVec <- (yMaxVec - yMin) / (2 * zBound * sqrt(Tn)) -->
<!-- # mVec <- 1 / (2 * Tn) * (yMaxVec + yMin + (yMaxVec - yMin)^2 / (4 * zBound^2)) -->
<!-- # cvVec <- sVec / (mVec * sqrt(Tn)) -->
<!-- # plot(yMaxVec, cvVec) -->
<!-- # cvVec <- 1 / (4 * zBound * Tn^2) * (yMaxVec^2 - yMin^2 + (yMaxVec - yMin)^3 / (4 * zBound^2)) -->
<!-- # E[x(T)]|t=0 -->
<!-- # ExT <- round(exp(m * Tn) * x0 * 10^-6, 3) # millions -->
<!-- # ExTdisc <- round(exp(-r * Tn) * ExT, 3) # millions -->
<!-- # Expected log return -->
<!-- #mu <- round((yMax + yMin) / 2, 2) -->
<!-- mu <- round((r - s^2 / 2) * Tn, 2) -->
<!-- #mu -->
<!-- #m <- (mu / Tn + s^2 / 2) -->
<!-- #-------------------------------------------------------------------------- -->
<!-- # Compare to conventional appraisal -->
<!-- #NPV <- exp(-r * sum(Tvec)) * (X0 - sum(Kvec)) -->
<!-- conv <- x0 - sum(exp(-r * rev(cumsum(rev(Tvec[-1])))) * (Kvec[-(n + 1)] - Bvec)) -->
<!-- conv <- round(conv) -->
<!-- dif_conv <- round(conv - K1) -->
<!-- #------------------------------------------------------------------------ -->
<!-- # Calculate n-fold ROV, at first with no abandonment value -->
<!-- df <- rovN(x0, Kvec[-n - 1], Bvec, Tvec[-1], s, r) -->
<!-- ROV <- round(df$`i-fold ROV`[nrow(df)]) -->
<!-- dif <- round(ROV - K1) -->
<!-- Phi2 <- round(df$`Probability of exercise`[n], 2) -->
<!-- etaN0 <- round(df$`Elasticity w.r.t. project NPV`[n], 2) -->
<!-- #------------------------------------------------------------------------ -->
<!-- # Calculate n-fold ROV, now with abandonment value -->
<!-- Bvec <- c(0, 0, 0, 20000) -->
<!-- df_wB <- rovN(x0, Kvec[-n - 1], Bvec, Tvec[-1], s, r) -->
<!-- ROV_wB <- round(df_wB$`i-fold ROV`[nrow(df_wB)]) -->
<!-- dif_wB <- round(ROV_wB - K1) -->
<!-- Phi2wB <- round(df_wB$`Probability of exercise`[n], 2) -->
<!-- etaN0_wB <- round(df_wB$`Elasticity w.r.t. project NPV`[n], 2) -->
<!-- #------------------------------------------------------------------------ -->
<!-- # Compare to conventional appraisal with abandonment value -->
<!-- #NPV <- exp(-r * sum(Tvec)) * (X0 - sum(Kvec)) -->
<!-- conv_wB <- x0 - sum(exp(-r * rev(cumsum(rev(Tvec[-1])))) * (Kvec[-(n + 1)] - Bvec)) -->
<!-- conv_wB <- round(conv_wB) -->
<!-- dif_conv_wB <- conv_wB - K1 -->
